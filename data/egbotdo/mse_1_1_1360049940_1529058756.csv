,accepted_answer_id,answer_count,answers,body_markdown,body_markdown_answers,closed_date,closed_details.description,closed_details.on_hold,closed_details.reason,closed_reason,comment_count,comments,creation_date,down_vote_count,favorite_count,is_answered,last_activity_date,last_edit_date,link,owner.accept_rate,owner.badge_counts.bronze,owner.badge_counts.gold,owner.badge_counts.silver,owner.display_name,owner.link,owner.reputation,owner.user_id,owner.user_type,protected_date,question_id,score,share_link,tags,title,up_vote_count,view_count
0,2790443.0,2,"[{u'up_vote_count': 1, u'title': u'Conditional expectation counterexamples', u'question_id': 2790416, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1526929629, u'creation_date': 1526928278, u'comment_count': 0, u'score': 1, u'link': u'https://math.stackexchange.com/questions/2790416/conditional-expectation-counterexamples/2790443#2790443', u'body_markdown': u'Let $X$ be any random variable (possibly one that can take negative values) and let $A = \{\omega : X(\omega) &gt;0\}$. You can indeed conclude $E[X|\mathcal{G}]&gt;0$ for all $\omega \in A$ except possibly a set of probability measure 0 (note that I have replaced your &quot;almost all&quot; with &quot;except for a set of probability measure 0&quot;). 

Suppose $B \subseteq A$, $P[B]&gt;0$, and $E[X|\mathcal{G}]\leq 0$ for all $\omega \in B$. We want to reach a contradiction.  Note that $B \cap\{\omega : X(\omega)&gt;1/n\} \nearrow B$. So there is a positive integer $m$ such that $$P[B \cap \{\omega : X(\omega)&gt;1/m\}] &gt;0 \quad (Eq. *)$$  
So
\begin{align}
0&amp;\overset{(a)}{\geq}\int_B E[X|\mathcal{G}]dP \\
&amp;\overset{(b)}{=} \int_B X dP \\
&amp;\overset{(c)}{\geq} \int_B (1/m)1_{\{X&gt;1/m\}}dP \\
&amp;= (1/m)P[B \cap \{\omega : X(\omega)&gt;1/m\}] \\
&amp;\overset{(d)}{&gt;}0
\end{align}
where (a) holds because $E[X|\mathcal{G}]\leq 0$ for all $\omega \in B$; (b) holds by definition of conditional expectation; (c) holds because $X(\omega) \geq (1/m)1_{\{X&gt;1/m\}}$ for all $\omega \in B \subseteq A$; (d) holds by (Eq. *). The conclusion $0&gt;0$ is the desired contradiction. $\Box$

***
However, a &quot;counter-example&quot; that relates to expectation is that it is not always the case:
$$ E[X+Y]=E[X]+E[Y]$$
This equation is true whenever the right-hand-side does not lead to an undefined case of $\infty - \infty$. It fails, for example, if $E[X]=\infty$ and $Y=1-X$.   ', u'owner': {u'user_id': 155065, u'user_type': u'registered', u'reputation': 11879, u'link': u'https://math.stackexchange.com/users/155065/michael', u'display_name': u'Michael', u'badge_counts': {u'bronze': 23, u'silver': 11, u'gold': 0}}, u'is_accepted': True, u'last_edit_date': 1526929629, u'share_link': u'https://math.stackexchange.com/a/2790443', u'answer_id': 2790443}, {u'up_vote_count': 2, u'title': u'Conditional expectation counterexamples', u'question_id': 2790416, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1526929637, u'comments': [{u'edited': False, u'comment_id': 5754052, u'creation_date': 1526929524, u'post_id': 2790451, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 155065, u'user_type': u'registered', u'reputation': 11879, u'link': u'https://math.stackexchange.com/users/155065/michael', u'display_name': u'Michael', u'badge_counts': {u'bronze': 23, u'silver': 11, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2790416/conditional-expectation-counterexamples/2790451#comment5754052_2790451'}, {u'edited': False, u'reply_to_user': {u'user_id': 155065, u'user_type': u'registered', u'reputation': 11879, u'link': u'https://math.stackexchange.com/users/155065/michael', u'display_name': u'Michael', u'badge_counts': {u'bronze': 23, u'silver': 11, u'gold': 0}}, u'comment_id': 5754069, u'creation_date': 1526929725, u'post_id': 2790451, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2790416/conditional-expectation-counterexamples/2790451#comment5754069_2790451'}], u'creation_date': 1526928754, u'comment_count': 2, u'score': 2, u'link': u'https://math.stackexchange.com/questions/2790416/conditional-expectation-counterexamples/2790451#2790451', u'body_markdown': u'First of all, recall that $X \geq 0$ implies $\mathbb{E}(X \mid \mathcal{G}) \geq 0$ almost surely. Moreover, we know that

$$\forall G \in \mathcal{G}: \quad \int_G X \, d\mathbb{P} = \int_G \mathbb{E}(X \mid \mathcal{G}) \, d\mathbb{P};$$

in particular, we find for $G := \{\mathbb{E}(X \mid \mathcal{G}) = 0\}$

$$0 = \int_G \mathbb{E}(X \mid \mathcal{G}) \, d\mathbb{P} = \int_G X \, d\mathbb{P}.$$

As $X \geq 0$ this implies

$$X=0 \quad \text{almost surely on $\{\mathbb{E}(X \mid \mathcal{G})=0\}$}$$

i.e.

$$\{\mathbb{E}(X \mid \mathcal{G})=0\} \subseteq \{X=0\} \quad \text{up to a null set}.$$

Taking the complement, we conclude that

$$\{X&gt;0\} \subseteq \{\mathbb{E}(X \mid \mathcal{G})&gt;0\} \quad \text{up to a null set},$$

and this proves the assertion.', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'is_accepted': False, u'last_edit_date': 1526929637, u'share_link': u'https://math.stackexchange.com/a/2790451', u'answer_id': 2790451}]","Consider $X$ a nonnegative random variable on some probability space $(\Omega, \mathcal{F}, \mathbb{P})$. We are given that

$$
A = \left\{ \omega : X(\omega) &gt; 0 \right\}
$$

and that $\mathcal{G}$ is a sub-sigma-field of $\mathcal{F}$. Can we conclude that $\mathbb{E}(X \ |\ \mathcal{G}) &gt; 0$ for almost all $\omega \in A$?

I think the answer is no, but I&#39;m having trouble coming up with a counterexample. One thing I tried was

$$
\Omega = \left\{ a, b , c \right\}, \; \mathcal{G} = \left\{ \emptyset, \Omega, \{a, b\}, \{c\}\right\}
$$
with $X(\omega) = \mathbf{1}_{\{c\}}$ and $\mathbb{P}(\{c\}) = 0$, $\mathbb{P}(\{ a \}) = \mathbb{P}(\{ b \}) = 1/2$. Here, obviously $A = \{ c \}$ and

$$ \int_A \mathbb{E}(X | \mathcal{G}) \text{d}\mathbb{P} =
\int_A X \text{d} \mathbb{P} = 0, \text{ since } \mathbb{P}(A) = 0$$

However, we can set $\mathbb{E}(X \ |\ \mathcal{G})$ equal to any positive number above for $\omega \in A$, so we cannot disprove the claim. Any help?

More generally, any pointer to resources with &quot;pathological&quot; cases and counterexamples in conditional probability and conditional expectation would be more than helpful.","[Let $X$ be any random variable (possibly one that can take negative values) and let $A = \{\omega : X(\omega) &gt;0\}$. You can indeed conclude $E[X|\mathcal{G}]&gt;0$ for all $\omega \in A$ except possibly a set of probability measure 0 (note that I have replaced your &quot;almost all&quot; with &quot;except for a set of probability measure 0&quot;). 

Suppose $B \subseteq A$, $P[B]&gt;0$, and $E[X|\mathcal{G}]\leq 0$ for all $\omega \in B$. We want to reach a contradiction.  Note that $B \cap\{\omega : X(\omega)&gt;1/n\} \nearrow B$. So there is a positive integer $m$ such that $$P[B \cap \{\omega : X(\omega)&gt;1/m\}] &gt;0 \quad (Eq. *)$$  
So
\begin{align}
0&amp;\overset{(a)}{\geq}\int_B E[X|\mathcal{G}]dP \\
&amp;\overset{(b)}{=} \int_B X dP \\
&amp;\overset{(c)}{\geq} \int_B (1/m)1_{\{X&gt;1/m\}}dP \\
&amp;= (1/m)P[B \cap \{\omega : X(\omega)&gt;1/m\}] \\
&amp;\overset{(d)}{&gt;}0
\end{align}
where (a) holds because $E[X|\mathcal{G}]\leq 0$ for all $\omega \in B$; (b) holds by definition of conditional expectation; (c) holds because $X(\omega) \geq (1/m)1_{\{X&gt;1/m\}}$ for all $\omega \in B \subseteq A$; (d) holds by (Eq. *). The conclusion $0&gt;0$ is the desired contradiction. $\Box$

***
However, a &quot;counter-example&quot; that relates to expectation is that it is not always the case:
$$ E[X+Y]=E[X]+E[Y]$$
This equation is true whenever the right-hand-side does not lead to an undefined case of $\infty - \infty$. It fails, for example, if $E[X]=\infty$ and $Y=1-X$.   , First of all, recall that $X \geq 0$ implies $\mathbb{E}(X \mid \mathcal{G}) \geq 0$ almost surely. Moreover, we know that

$$\forall G \in \mathcal{G}: \quad \int_G X \, d\mathbb{P} = \int_G \mathbb{E}(X \mid \mathcal{G}) \, d\mathbb{P};$$

in particular, we find for $G := \{\mathbb{E}(X \mid \mathcal{G}) = 0\}$

$$0 = \int_G \mathbb{E}(X \mid \mathcal{G}) \, d\mathbb{P} = \int_G X \, d\mathbb{P}.$$

As $X \geq 0$ this implies

$$X=0 \quad \text{almost surely on $\{\mathbb{E}(X \mid \mathcal{G})=0\}$}$$

i.e.

$$\{\mathbb{E}(X \mid \mathcal{G})=0\} \subseteq \{X=0\} \quad \text{up to a null set}.$$

Taking the complement, we conclude that

$$\{X&gt;0\} \subseteq \{\mathbb{E}(X \mid \mathcal{G})&gt;0\} \quad \text{up to a null set},$$

and this proves the assertion.]",,,,,,1,"[{u'edited': False, u'comment_id': 5754031, u'creation_date': 1526929214, u'post_id': 2790416, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 155065, u'user_type': u'registered', u'reputation': 11879, u'link': u'https://math.stackexchange.com/users/155065/michael', u'display_name': u'Michael', u'badge_counts': {u'bronze': 23, u'silver': 11, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2790416/conditional-expectation-counterexamples#comment5754031_2790416'}]",1526927209,0,0,True,1526929637,,https://math.stackexchange.com/questions/2790416/conditional-expectation-counterexamples,,20.0,0.0,4.0,VHarisop,https://math.stackexchange.com/users/334134/vharisop,775.0,334134.0,registered,,2790416,2,https://math.stackexchange.com/q/2790416,"[probability, probability-theory, reference-request, examples-counterexamples, conditional-expectation]",Conditional expectation counterexamples,2,28
1,,1,"[{u'up_vote_count': 1, u'title': u'An example of a sequence of random variables with certain properties.', u'question_id': 2782087, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1526481296, u'creation_date': 1526481296, u'comment_count': 0, u'score': 1, u'link': u'https://math.stackexchange.com/questions/2782087/an-example-of-a-sequence-of-random-variables-with-certain-properties/2783793#2783793', u'body_markdown': u'I found the example, am writing it down if anyone is intrested :

Define $X_n = nI_{(\frac{1}{n+1},\frac{1}{n}]}$ then $X_n$ has the following properties:

1) $X_n\geq 0 $

2) $X_n\overset{as}{\to} X=0$

3) $\mathbb{E}[X_n]=n\biggl(\frac{1}{n}-\frac{1}{n+1}\biggr)=\frac{1}{n+1} \overset{n\to \infty}{\longrightarrow} 0=\mathbb{E}[X]&lt; \infty$

But for $(X_n)_{n=1}^{\infty}$ there is no random variable $Y$ with $\mathbb{E}[\  |Y|\ ]&lt; \infty$ such that $|X_n|\leq |Y|$ since if there exist such $Y$ then its easy to see that for every $n \in \mathbb{N}$

$$\sum_{k=1}^{n}kI_{[\frac{1}{k+1},\frac{1}{k}]} \leq |Y|$$

which implies

$$\sum_{k=1}^{n}\mathbb{E}[\ kI_{(\frac{1}{k+1},\frac{1}{k}]}\ ] \leq \mathbb{E}[\ |Y| \ ]$$

so,
$$\sum_{k=1}^{n}\dfrac{1}{k+1}\leq \mathbb{E}[\ |Y|\ ]$$

for every $n \in \mathbb{N}$ , which cant be true , hence there is no such $Y$.', u'owner': {u'user_id': 522689, u'user_type': u'registered', u'reputation': 640, u'link': u'https://math.stackexchange.com/users/522689/dem0nakos', u'display_name': u'dem0nakos', u'badge_counts': {u'bronze': 11, u'silver': 1, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2783793', u'answer_id': 2783793}]","Is there any example of a sequence of random variables $(X_n)_{n=1}^{\infty}$ such that

&gt; 1)$X_n \geq 0 $, 
&gt; 
&gt; 2)$\mathbb{E}[X_n]&lt;\infty$, 
&gt; 
&gt; 3)$X_n \overset{a.s}{\to} X$ for some integrable random variable $X$
&gt; 
&gt; 4)$\mathbb{E}[X_n] \to \mathbb{E}[X]&lt;\infty$
&gt; 
&gt;  but there is no any integrable random variable $Y$ such that
&gt; $X_n \leq |Y|$?

I found an example in the case where $X_n$ are not positive necessarily but for the case where $X_n \geq 0$ i couldnt find any example.

Thanks in advance!



","[I found the example, am writing it down if anyone is intrested :

Define $X_n = nI_{(\frac{1}{n+1},\frac{1}{n}]}$ then $X_n$ has the following properties:

1) $X_n\geq 0 $

2) $X_n\overset{as}{\to} X=0$

3) $\mathbb{E}[X_n]=n\biggl(\frac{1}{n}-\frac{1}{n+1}\biggr)=\frac{1}{n+1} \overset{n\to \infty}{\longrightarrow} 0=\mathbb{E}[X]&lt; \infty$

But for $(X_n)_{n=1}^{\infty}$ there is no random variable $Y$ with $\mathbb{E}[\  |Y|\ ]&lt; \infty$ such that $|X_n|\leq |Y|$ since if there exist such $Y$ then its easy to see that for every $n \in \mathbb{N}$

$$\sum_{k=1}^{n}kI_{[\frac{1}{k+1},\frac{1}{k}]} \leq |Y|$$

which implies

$$\sum_{k=1}^{n}\mathbb{E}[\ kI_{(\frac{1}{k+1},\frac{1}{k}]}\ ] \leq \mathbb{E}[\ |Y| \ ]$$

so,
$$\sum_{k=1}^{n}\dfrac{1}{k+1}\leq \mathbb{E}[\ |Y|\ ]$$

for every $n \in \mathbb{N}$ , which cant be true , hence there is no such $Y$.]",,,,,,0,,1526381005,0,0,True,1526481296,1526381361.0,https://math.stackexchange.com/questions/2782087/an-example-of-a-sequence-of-random-variables-with-certain-properties,,11.0,0.0,1.0,dem0nakos,https://math.stackexchange.com/users/522689/dem0nakos,640.0,522689.0,registered,,2782087,1,https://math.stackexchange.com/q/2782087,"[probability, random-variables, examples-counterexamples]",An example of a sequence of random variables with certain properties.,1,35
2,2659527.0,1,"[{u'up_vote_count': 1, u'title': u'Continuity counterexamples for probability measures', u'question_id': 2659519, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1519174626, u'creation_date': 1519174626, u'comment_count': 0, u'score': 1, u'link': u'https://math.stackexchange.com/questions/2659519/continuity-counterexamples-for-probability-measures/2659527#2659527', u'body_markdown': u'No.
Actually, your finite additive measure $m$ is not well defined.

For example: by additivity $m(3n+1)+m(3n+2) = m(3n+1\cup3n+2)$ which imply $1+1 = 1$ which is false.
', u'owner': {u'user_id': 443993, u'user_type': u'registered', u'reputation': 89, u'link': u'https://math.stackexchange.com/users/443993/changlele', u'display_name': u'Changlele', u'badge_counts': {u'bronze': 5, u'silver': 0, u'gold': 0}}, u'is_accepted': True, u'share_link': u'https://math.stackexchange.com/a/2659527', u'answer_id': 2659527}]","I&#39;m given a measurable space $(\Omega, \mathcal{F})$ and a finitely additive measure $m$ that satisfies $m(\Omega) = 1$. I&#39;m asked to give counterexamples for continuity from above and below.

My attempt (discontinuity from above): take $\Omega = \mathbb{N}$ and $\mathcal{F} = \mathcal{P}(\mathbb{N})$ the set of subsets of $\mathbb{N}$. Define:
$$
m(A) = \begin{cases}
   0, &amp; A \text{ finite} \\
   1, &amp; \text{otherwise}
\end{cases}
$$
Now, take $A_n = \{ j \in \mathbb{N} \ |\ j \geq n \} $ which satisfies
$$
A_1 \supset A_2 \supset \dots, \quad \bigcap_{i=1}^{\infty} A_i = \emptyset \quad (A_n \downarrow \emptyset)
$$
Then, it obviously holds
\begin{align*}
  m\left(\bigcap_i^{\infty} A_i\right) &amp;= m(\emptyset) = 0  \\
  \lim_{n \to \infty} m(A_n) &amp;= \lim_{n \to \infty} m\left( \{ j \geq n, j \in \mathbb{N} \} \right) = \lim_{n \to \infty} 1 = 1 \neq
  m\left( \bigcap_i^{\infty} A_i \right)
\end{align*}
since, $\forall n \geq 1$, $A_n$ is a co-finite set. Is my approach correct?","[No.
Actually, your finite additive measure $m$ is not well defined.

For example: by additivity $m(3n+1)+m(3n+2) = m(3n+1\cup3n+2)$ which imply $1+1 = 1$ which is false.
]",,,,,,5,"[{u'edited': False, u'comment_id': 5493165, u'creation_date': 1519175145, u'post_id': 2659519, u'score': 1, u'post_type': u'question', u'owner': {u'user_id': 208255, u'user_type': u'registered', u'reputation': 2927, u'link': u'https://math.stackexchange.com/users/208255/user24142', u'display_name': u'user24142', u'badge_counts': {u'bronze': 14, u'silver': 8, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2659519/continuity-counterexamples-for-probability-measures#comment5493165_2659519'}, {u'edited': False, u'reply_to_user': {u'user_id': 208255, u'user_type': u'registered', u'reputation': 2927, u'link': u'https://math.stackexchange.com/users/208255/user24142', u'display_name': u'user24142', u'badge_counts': {u'bronze': 14, u'silver': 8, u'gold': 0}}, u'comment_id': 5493198, u'creation_date': 1519176105, u'post_id': 2659519, u'score': 1, u'post_type': u'question', u'owner': {u'user_id': 334134, u'user_type': u'registered', u'reputation': 775, u'link': u'https://math.stackexchange.com/users/334134/vharisop', u'display_name': u'VHarisop', u'badge_counts': {u'bronze': 20, u'silver': 4, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2659519/continuity-counterexamples-for-probability-measures#comment5493198_2659519'}, {u'edited': False, u'reply_to_user': {u'user_id': 369188, u'user_type': u'registered', u'reputation': 32815, u'link': u'https://math.stackexchange.com/users/369188/salahamam-fatima', u'accept_rate': 80, u'display_name': u'Salahamam_ Fatima', u'badge_counts': {u'bronze': 28, u'silver': 10, u'gold': 2}}, u'comment_id': 5495138, u'creation_date': 1519230830, u'post_id': 2659519, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 474690, u'user_type': u'registered', u'reputation': 742, u'link': u'https://math.stackexchange.com/users/474690/sisyphus', u'display_name': u'Sisyphus', u'badge_counts': {u'bronze': 6, u'silver': 1, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2659519/continuity-counterexamples-for-probability-measures#comment5495138_2659519'}, {u'edited': False, u'reply_to_user': {u'user_id': 474690, u'user_type': u'registered', u'reputation': 742, u'link': u'https://math.stackexchange.com/users/474690/sisyphus', u'display_name': u'Sisyphus', u'badge_counts': {u'bronze': 6, u'silver': 1, u'gold': 1}}, u'comment_id': 5495318, u'creation_date': 1519234166, u'post_id': 2659519, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 369188, u'user_type': u'registered', u'reputation': 32815, u'link': u'https://math.stackexchange.com/users/369188/salahamam-fatima', u'accept_rate': 80, u'display_name': u'Salahamam_ Fatima', u'badge_counts': {u'bronze': 28, u'silver': 10, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2659519/continuity-counterexamples-for-probability-measures#comment5495318_2659519'}, {u'edited': False, u'comment_id': 5497025, u'creation_date': 1519272635, u'post_id': 2659519, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 208255, u'user_type': u'registered', u'reputation': 2927, u'link': u'https://math.stackexchange.com/users/208255/user24142', u'display_name': u'user24142', u'badge_counts': {u'bronze': 14, u'silver': 8, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2659519/continuity-counterexamples-for-probability-measures#comment5497025_2659519'}]",1519174226,0,0,True,1519225994,1519225994.0,https://math.stackexchange.com/questions/2659519/continuity-counterexamples-for-probability-measures,,20.0,0.0,4.0,VHarisop,https://math.stackexchange.com/users/334134/vharisop,775.0,334134.0,registered,,2659519,1,https://math.stackexchange.com/q/2659519,"[probability, measure-theory, proof-verification, examples-counterexamples]",Continuity counterexamples for probability measures,1,44
3,2522151.0,1,"[{u'up_vote_count': 3, u'title': u'Is it possible given random variables X and Y for $E[XY] = E[X]E[Y]$ if X and Y are dependent variables?', u'question_id': 2522123, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1510782802, u'creation_date': 1510782802, u'comment_count': 0, u'score': 3, u'link': u'https://math.stackexchange.com/questions/2522123/is-it-possible-given-random-variables-x-and-y-for-exy-exey-if-x-and-y/2522151#2522151', u'body_markdown': u'Take $X$ to be any symmetric random variable about 0, and $Y=X^2$. Then $E[XY]=E[X^3]=0=E[X]E[Y]=0\cdot E[X^2]$. ', u'owner': {u'user_id': 22064, u'user_type': u'registered', u'reputation': 23324, u'link': u'https://math.stackexchange.com/users/22064/alex-r', u'accept_rate': 55, u'display_name': u'Alex R.', u'badge_counts': {u'bronze': 50, u'silver': 22, u'gold': 1}}, u'is_accepted': True, u'share_link': u'https://math.stackexchange.com/a/2522151', u'answer_id': 2522151}]","Given random dependent variables X and Y, can we choose some X and Y such that $E[XY] = E[X]E[Y]$?","[Take $X$ to be any symmetric random variable about 0, and $Y=X^2$. Then $E[XY]=E[X^3]=0=E[X]E[Y]=0\cdot E[X^2]$. ]",1510790440.0,"This question appears to be off-topic. The users who voted to close gave this specific reason:<ul class=""close-as-off-topic-status-list""><li>&quot;<b>This question is missing context or other details</b>: Please <a href=""https://math.meta.stackexchange.com/questions/9959"">improve the question</a> by providing additional context, which ideally includes your thoughts on the problem and any attempts you have made to solve it. This information helps others identify where you have difficulties and helps them write answers appropriate to your experience level.&quot; &ndash; amWhy, mechanodroid, Misha Lavrov, Leucippus, Jos√© Carlos Santos</li></ul>",False,off-topic,off-topic,0,,1510781952,1,0,True,1510782802,1510782670.0,https://math.stackexchange.com/questions/2522123/is-it-possible-given-random-variables-x-and-y-for-exy-exey-if-x-and-y,,4.0,0.0,0.0,Patrick Connors,https://math.stackexchange.com/users/503458/patrick-connors,101.0,503458.0,registered,,2522123,-1,https://math.stackexchange.com/q/2522123,"[probability, examples-counterexamples]",Is it possible given random variables X and Y for $E[XY] = E[X]E[Y]$ if X and Y are dependent variables?,0,35
4,2492536.0,1,"[{u'up_vote_count': 1, u'title': u'Least squares standard result: why toy example fails?', u'question_id': 2492481, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1509118361, u'creation_date': 1509118361, u'comment_count': 0, u'score': 1, u'link': u'https://math.stackexchange.com/questions/2492481/least-squares-standard-result-why-toy-example-fails/2492536#2492536', u'body_markdown': u'&gt; What am I missing please?

**Answer**: the toy example does not fail!

Let $z=\begin{pmatrix}z_1 &amp; \cdots &amp; z_k\end{pmatrix}&#39;$ so that $x=\begin{pmatrix}1 \\ z\end{pmatrix}$. Then
\begin{align*}
E(\alpha x&#39;)E(x x&#39;)^{-1}&amp;=\alpha\begin{pmatrix}1 &amp; E(z&#39;)\end{pmatrix}\begin{pmatrix}1 &amp; E(z&#39;)\\ E(z) &amp; E(zz&#39;)\end{pmatrix}\\
&amp;=\alpha\begin{pmatrix}1 &amp; E(z&#39;)\end{pmatrix}\begin{pmatrix}1+E(z&#39;)[\text{Var}(z)]^{-1}E(z)&amp;-E(z&#39;)[\text{Var}(z)]^{-1}\\ -[\text{Var}(z)]^{-1}E(z) &amp; [\text{Var}(z)]^{-1}\end{pmatrix}\\
&amp;=\alpha\begin{pmatrix}1 \\ 0_{k\times 1}\end{pmatrix}
\end{align*}
which is your expected answer.', u'owner': {u'user_id': 136641, u'user_type': u'registered', u'reputation': 13172, u'link': u'https://math.stackexchange.com/users/136641/kim-jong-un', u'accept_rate': 89, u'display_name': u'Kim Jong Un', u'badge_counts': {u'bronze': 36, u'silver': 16, u'gold': 1}}, u'is_accepted': True, u'share_link': u'https://math.stackexchange.com/a/2492536', u'answer_id': 2492536}]","&gt; $y$ is a random variable, and $x$ is a $(k+1)\times 1$ random vector:
$$
x=(1,x_1,\ldots,x_k)&#39;.
$$
I recall that a nonrandom $1\times(k+1)$ vector $\beta$ that minimizes $E[(y-\beta x)^2]$ is given by
$$
\hat\beta=E(yx&#39;)E(xx&#39;)^{-1}.\tag{$*$}
$$
Then I test ($*$) by thinking of the case when $y=\alpha$ for some nonrandom $\alpha$. Clearly, the optimal $\beta$ should be $(\alpha,0,\ldots,0)$ but that&#39;s not what ($*$) gives me. What am I missing please?

**Clarification**: At some point I think ($*$) is wrong somehow but for all $\beta$
\begin{align}
E[(y-\beta x)^2]&amp;=E[((\hat\beta-\beta)x+(y-\hat\beta x))^2]\\
&amp;=E[((\hat\beta-\beta)x)^2]+E[(y-\hat\beta x)^2]+2(\hat\beta-\beta)E[x(y-\hat\beta x)].
\end{align}
Since
$$
E[(y-\hat\beta x)x&#39;]=E(yx&#39;)-E(yx&#39;)E(xx&#39;)^{-1}E(xx&#39;)=0\implies E[x(y-\hat\beta x)]=0
$$
so, $\forall\beta$,
$$
E[(y-\beta x)^2]= E[((\hat\beta-\beta)x)^2]+E[(y-\hat\beta x)^2]\geq E[(y-\hat\beta x)^2]
$$
so ($*$) actually seems alright. Frustratingly, I know these are supposedly to be standard results so why doesn&#39;t the simple example above work?","[&gt; What am I missing please?

**Answer**: the toy example does not fail!

Let $z=\begin{pmatrix}z_1 &amp; \cdots &amp; z_k\end{pmatrix}&#39;$ so that $x=\begin{pmatrix}1 \\ z\end{pmatrix}$. Then
\begin{align*}
E(\alpha x&#39;)E(x x&#39;)^{-1}&amp;=\alpha\begin{pmatrix}1 &amp; E(z&#39;)\end{pmatrix}\begin{pmatrix}1 &amp; E(z&#39;)\\ E(z) &amp; E(zz&#39;)\end{pmatrix}\\
&amp;=\alpha\begin{pmatrix}1 &amp; E(z&#39;)\end{pmatrix}\begin{pmatrix}1+E(z&#39;)[\text{Var}(z)]^{-1}E(z)&amp;-E(z&#39;)[\text{Var}(z)]^{-1}\\ -[\text{Var}(z)]^{-1}E(z) &amp; [\text{Var}(z)]^{-1}\end{pmatrix}\\
&amp;=\alpha\begin{pmatrix}1 \\ 0_{k\times 1}\end{pmatrix}
\end{align*}
which is your expected answer.]",,,,,,3,"[{u'edited': False, u'comment_id': 5148548, u'creation_date': 1509116264, u'post_id': 2492481, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 356819, u'user_type': u'registered', u'reputation': 3483, u'link': u'https://math.stackexchange.com/users/356819/cave-johnson', u'accept_rate': 75, u'display_name': u'Cave Johnson', u'badge_counts': {u'bronze': 25, u'silver': 11, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2492481/least-squares-standard-result-why-toy-example-fails#comment5148548_2492481'}, {u'edited': False, u'reply_to_user': {u'user_id': 356819, u'user_type': u'registered', u'reputation': 3483, u'link': u'https://math.stackexchange.com/users/356819/cave-johnson', u'accept_rate': 75, u'display_name': u'Cave Johnson', u'badge_counts': {u'bronze': 25, u'silver': 11, u'gold': 0}}, u'comment_id': 5148571, u'creation_date': 1509117026, u'post_id': 2492481, u'score': 1, u'post_type': u'question', u'owner': {u'user_id': 178464, u'user_type': u'registered', u'reputation': 6751, u'link': u'https://math.stackexchange.com/users/178464/yurnero', u'accept_rate': 65, u'display_name': u'yurnero', u'badge_counts': {u'bronze': 23, u'silver': 8, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2492481/least-squares-standard-result-why-toy-example-fails#comment5148571_2492481'}, {u'edited': False, u'comment_id': 5148588, u'creation_date': 1509117788, u'post_id': 2492481, u'score': 1, u'post_type': u'question', u'owner': {u'user_id': 356819, u'user_type': u'registered', u'reputation': 3483, u'link': u'https://math.stackexchange.com/users/356819/cave-johnson', u'accept_rate': 75, u'display_name': u'Cave Johnson', u'badge_counts': {u'bronze': 25, u'silver': 11, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2492481/least-squares-standard-result-why-toy-example-fails#comment5148588_2492481'}]",1509115267,0,1,True,1509118361,,https://math.stackexchange.com/questions/2492481/least-squares-standard-result-why-toy-example-fails,65.0,23.0,1.0,8.0,yurnero,https://math.stackexchange.com/users/178464/yurnero,6751.0,178464.0,registered,,2492481,1,https://math.stackexchange.com/q/2492481,"[probability, examples-counterexamples, least-squares]",Least squares standard result: why toy example fails?,1,37
5,2472621.0,1,"[{u'up_vote_count': 1, u'title': u'Question about Caratheodory extension theorem applied to $[0,1]$', u'question_id': 2472602, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1508021123, u'comments': [{u'edited': False, u'comment_id': 5108892, u'creation_date': 1508022339, u'post_id': 2472621, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 90914, u'user_type': u'registered', u'reputation': 3810, u'link': u'https://math.stackexchange.com/users/90914/3x89g2', u'accept_rate': 86, u'display_name': u'3x89g2', u'badge_counts': {u'bronze': 32, u'silver': 9, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2472602/question-about-caratheodory-extension-theorem-applied-to-0-1/2472621#comment5108892_2472621'}, {u'edited': False, u'reply_to_user': {u'user_id': 90914, u'user_type': u'registered', u'reputation': 3810, u'link': u'https://math.stackexchange.com/users/90914/3x89g2', u'accept_rate': 86, u'display_name': u'3x89g2', u'badge_counts': {u'bronze': 32, u'silver': 9, u'gold': 1}}, u'comment_id': 5119769, u'creation_date': 1508308237, u'post_id': 2472621, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 149178, u'user_type': u'registered', u'reputation': 6257, u'link': u'https://math.stackexchange.com/users/149178/adayah', u'display_name': u'Adayah', u'badge_counts': {u'bronze': 21, u'silver': 8, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2472602/question-about-caratheodory-extension-theorem-applied-to-0-1/2472621#comment5119769_2472621'}], u'creation_date': 1508021123, u'comment_count': 2, u'score': 1, u'link': u'https://math.stackexchange.com/questions/2472602/question-about-caratheodory-extension-theorem-applied-to-0-1/2472621#2472621', u'body_markdown': u'Answer to both questions: there are $2^{\aleph_0}$ Borel subsets of $[0, 1]$. On the other hand, the Cantor set has measure zero, so every subset of it is in $\mathcal{M}$. There are $2^{2^{\aleph_0}}$ such subsets, so some must not be Borel, although the Cantor set is Borel.', u'owner': {u'user_id': 149178, u'user_type': u'registered', u'reputation': 6257, u'link': u'https://math.stackexchange.com/users/149178/adayah', u'display_name': u'Adayah', u'badge_counts': {u'bronze': 21, u'silver': 8, u'gold': 0}}, u'is_accepted': True, u'share_link': u'https://math.stackexchange.com/a/2472621', u'answer_id': 2472621}]","Let $\mathcal{J}$ be the collection of intervals from $[0,1]$. By intervals, I include singletons, emptyset, etc. So $\mathcal{J}$ looks like

$$\mathcal{J} = \{ (0, 0.7), 0.5 ,\emptyset, [0,1], \cdots \}$$

I have two different $\sigma$-algebras constructed from $\mathcal{J}$. One is $\sigma(\mathcal{J})$, which is the Borel $\sigma$-algebra of subsets of $[0,1]$ and usually denoted as $\mathcal{B}([0,1])$. Another one is the $\sigma$-algebra you get when you apply the Caratheodory extension theorem to $\mathcal{J}$. Let&#39;s call it $\mathcal{M}$.

Apparently we have $\mathcal{B} \subset \mathcal{M}$, by definition. However the following comments on my book confuse me and I don&#39;t know why they are true.

&gt; It can be shown that $\mathcal{M}$ is in fact much bigger than $\mathcal{B}$; it even has larger cardinality (why?). Furthermore, it turns out that the Lebesgue measure restricted to $\mathcal{B}$ is not complete (why?), though on $\mathcal{M}$ it is.

Why those two statements are true? No proof is provided in the book but I am just curious. For the first statement I simply have no idea how to prove it. For the second statement, by definition we must find some $A \in \mathcal{B}$ with $\mathbb{P}(A) = 0$ and some $B \subset A$ such that $B \notin \mathcal{B}$, but cannot think of an example...","[Answer to both questions: there are $2^{\aleph_0}$ Borel subsets of $[0, 1]$. On the other hand, the Cantor set has measure zero, so every subset of it is in $\mathcal{M}$. There are $2^{2^{\aleph_0}}$ such subsets, so some must not be Borel, although the Cantor set is Borel.]",,,,,,0,,1508019569,0,0,True,1508021123,,https://math.stackexchange.com/questions/2472602/question-about-caratheodory-extension-theorem-applied-to-0-1,86.0,32.0,1.0,9.0,3x89g2,https://math.stackexchange.com/users/90914/3x89g2,3810.0,90914.0,registered,,2472602,0,https://math.stackexchange.com/q/2472602,"[probability, measure-theory, examples-counterexamples]","Question about Caratheodory extension theorem applied to $[0,1]$",0,28
6,2462329.0,2,"[{u'up_vote_count': 3, u'title': u'Why mean independence does not imply independence?', u'question_id': 2462328, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1507427228, u'comments': [{u'edited': False, u'comment_id': 5087977, u'creation_date': 1507427897, u'post_id': 2462329, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 312, u'user_type': u'registered', u'reputation': 37551, u'link': u'https://math.stackexchange.com/users/312/leonbloy', u'accept_rate': 64, u'display_name': u'leonbloy', u'badge_counts': {u'bronze': 101, u'silver': 42, u'gold': 6}}, u'link': u'https://math.stackexchange.com/questions/2462328/why-mean-independence-does-not-imply-independence/2462329#comment5087977_2462329'}, {u'edited': False, u'comment_id': 5090196, u'creation_date': 1507492187, u'post_id': 2462329, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 66096, u'user_type': u'registered', u'reputation': 16930, u'link': u'https://math.stackexchange.com/users/66096/gabriel-romon', u'accept_rate': 93, u'display_name': u'Gabriel Romon', u'badge_counts': {u'bronze': 80, u'silver': 28, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2462328/why-mean-independence-does-not-imply-independence/2462329#comment5090196_2462329'}, {u'edited': False, u'reply_to_user': {u'user_id': 66096, u'user_type': u'registered', u'reputation': 16930, u'link': u'https://math.stackexchange.com/users/66096/gabriel-romon', u'accept_rate': 93, u'display_name': u'Gabriel Romon', u'badge_counts': {u'bronze': 80, u'silver': 28, u'gold': 4}}, u'comment_id': 5090465, u'creation_date': 1507497299, u'post_id': 2462329, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 215011, u'user_type': u'registered', u'reputation': 17699, u'link': u'https://math.stackexchange.com/users/215011/grand-chat', u'display_name': u'grand_chat', u'badge_counts': {u'bronze': 20, u'silver': 11, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2462328/why-mean-independence-does-not-imply-independence/2462329#comment5090465_2462329'}], u'creation_date': 1507427228, u'comment_count': 3, u'score': 3, u'link': u'https://math.stackexchange.com/questions/2462328/why-mean-independence-does-not-imply-independence/2462329#2462329', u'body_markdown': u'Let the pair $(X,Y)$ be uniformly distributed over a circle (say the unit circle centered at $(0,0)$). Then for each $y$ we have ${\mathbb E}(X\mid Y=y)=0$, which equals ${\mathbb E}(X)$, but we don&#39;t have independence between $X$ and $Y$.', u'owner': {u'user_id': 215011, u'user_type': u'registered', u'reputation': 17699, u'link': u'https://math.stackexchange.com/users/215011/grand-chat', u'display_name': u'grand_chat', u'badge_counts': {u'bronze': 20, u'silver': 11, u'gold': 1}}, u'is_accepted': True, u'share_link': u'https://math.stackexchange.com/a/2462329', u'answer_id': 2462329}, {u'up_vote_count': 1, u'title': u'Why mean independence does not imply independence?', u'question_id': 2462328, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1507427903, u'comments': [{u'edited': False, u'comment_id': 5088086, u'creation_date': 1507431694, u'post_id': 2462335, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 90914, u'user_type': u'registered', u'reputation': 3810, u'link': u'https://math.stackexchange.com/users/90914/3x89g2', u'accept_rate': 86, u'display_name': u'3x89g2', u'badge_counts': {u'bronze': 32, u'silver': 9, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2462328/why-mean-independence-does-not-imply-independence/2462335#comment5088086_2462335'}, {u'edited': False, u'reply_to_user': {u'user_id': 90914, u'user_type': u'registered', u'reputation': 3810, u'link': u'https://math.stackexchange.com/users/90914/3x89g2', u'accept_rate': 86, u'display_name': u'3x89g2', u'badge_counts': {u'bronze': 32, u'silver': 9, u'gold': 1}}, u'comment_id': 5088097, u'creation_date': 1507431990, u'post_id': 2462335, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 223391, u'user_type': u'registered', u'reputation': 24284, u'link': u'https://math.stackexchange.com/users/223391/zachary-selk', u'accept_rate': 97, u'display_name': u'Zachary Selk', u'badge_counts': {u'bronze': 92, u'silver': 42, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2462328/why-mean-independence-does-not-imply-independence/2462335#comment5088097_2462335'}], u'creation_date': 1507427903, u'comment_count': 2, u'score': 1, u'link': u'https://math.stackexchange.com/questions/2462328/why-mean-independence-does-not-imply-independence/2462335#2462335', u'body_markdown': u'Just because the LHS is free of $y$ doesn&#39;t mean equality a.e. They can both be $0$.

A counterexample would be (in spirit, the same as grand_chat but maybe a bit more elementary): we play a game. I flip a coin, if heads we bet \$10. If tails we bet \$5. Then we flip another coin and if if heads you win and tails I win. 

The original coin flip determines how much we bet and thus how much you win/lose. But the expectation is $0$ in any case.', u'owner': {u'user_id': 223391, u'user_type': u'registered', u'reputation': 24284, u'link': u'https://math.stackexchange.com/users/223391/zachary-selk', u'accept_rate': 97, u'display_name': u'Zachary Selk', u'badge_counts': {u'bronze': 92, u'silver': 42, u'gold': 5}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2462335', u'answer_id': 2462335}]","Why mean independence does not imply independence? I considered

$$
\mathbb{E}(X\mid Y=y) = \mathbb{E}(X) \text{ for all } y\in \mathcal{Y} $$

This implies that

$$\int_\mathcal{X} x f_{X\mid Y} (x,y) \,dx = \int_{\mathcal{X}} x f_X (x) \,dx \text{ for all } y \in \mathcal{Y}$$

For the equality to hold, the left hand side cannot have any $y$ in it after we do the integration. This seems to suggest that $f_{X\mid Y} (x,y)$ has to be free of $y$. Then, if $f_{X\mid Y} (x,y)$ is free of $y$, and the equality holds, it seems that we must have $f_{X\mid Y} (x,y) = f_X (x)$.

I think the last statement I made could have some problem because we probably only have $f_{X\mid Y} (x,y) = f_X (x)$ _almost everywhere_. But what would be an elementary counterexample?","[Let the pair $(X,Y)$ be uniformly distributed over a circle (say the unit circle centered at $(0,0)$). Then for each $y$ we have ${\mathbb E}(X\mid Y=y)=0$, which equals ${\mathbb E}(X)$, but we don&#39;t have independence between $X$ and $Y$., Just because the LHS is free of $y$ doesn&#39;t mean equality a.e. They can both be $0$.

A counterexample would be (in spirit, the same as grand_chat but maybe a bit more elementary): we play a game. I flip a coin, if heads we bet \$10. If tails we bet \$5. Then we flip another coin and if if heads you win and tails I win. 

The original coin flip determines how much we bet and thus how much you win/lose. But the expectation is $0$ in any case.]",,,,,,1,"[{u'edited': False, u'comment_id': 5087973, u'creation_date': 1507427598, u'post_id': 2462328, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 312, u'user_type': u'registered', u'reputation': 37551, u'link': u'https://math.stackexchange.com/users/312/leonbloy', u'accept_rate': 64, u'display_name': u'leonbloy', u'badge_counts': {u'bronze': 101, u'silver': 42, u'gold': 6}}, u'link': u'https://math.stackexchange.com/questions/2462328/why-mean-independence-does-not-imply-independence#comment5087973_2462328'}]",1507426932,0,1,True,1507427903,,https://math.stackexchange.com/questions/2462328/why-mean-independence-does-not-imply-independence,86.0,32.0,1.0,9.0,3x89g2,https://math.stackexchange.com/users/90914/3x89g2,3810.0,90914.0,registered,,2462328,2,https://math.stackexchange.com/q/2462328,"[probability, analysis, probability-theory, examples-counterexamples]",Why mean independence does not imply independence?,2,299
7,2426894.0,1,"[{u'up_vote_count': 2, u'title': u'What does &quot;take away&quot; mean in combinatoric questions: why divide instead of subtract?', u'question_id': 2426882, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1505247182, u'comments': [{u'edited': False, u'comment_id': 5012753, u'creation_date': 1505239100, u'post_id': 2426894, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 242850, u'user_type': u'registered', u'reputation': 2659, u'link': u'https://math.stackexchange.com/users/242850/hendrix', u'accept_rate': 91, u'display_name': u'Hendrix', u'badge_counts': {u'bronze': 39, u'silver': 16, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt/2426894#comment5012753_2426894'}, {u'edited': False, u'reply_to_user': {u'user_id': 242850, u'user_type': u'registered', u'reputation': 2659, u'link': u'https://math.stackexchange.com/users/242850/hendrix', u'accept_rate': 91, u'display_name': u'Hendrix', u'badge_counts': {u'bronze': 39, u'silver': 16, u'gold': 2}}, u'comment_id': 5012992, u'creation_date': 1505243409, u'post_id': 2426894, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 475527, u'user_type': u'registered', u'reputation': 552, u'link': u'https://math.stackexchange.com/users/475527/fullofdill', u'display_name': u'FullofDill', u'badge_counts': {u'bronze': 5, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt/2426894#comment5012992_2426894'}, {u'edited': False, u'reply_to_user': {u'user_id': 242850, u'user_type': u'registered', u'reputation': 2659, u'link': u'https://math.stackexchange.com/users/242850/hendrix', u'accept_rate': 91, u'display_name': u'Hendrix', u'badge_counts': {u'bronze': 39, u'silver': 16, u'gold': 2}}, u'comment_id': 5013005, u'creation_date': 1505243693, u'post_id': 2426894, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 475527, u'user_type': u'registered', u'reputation': 552, u'link': u'https://math.stackexchange.com/users/475527/fullofdill', u'display_name': u'FullofDill', u'badge_counts': {u'bronze': 5, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt/2426894#comment5013005_2426894'}, {u'edited': False, u'comment_id': 5013122, u'creation_date': 1505246509, u'post_id': 2426894, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 242850, u'user_type': u'registered', u'reputation': 2659, u'link': u'https://math.stackexchange.com/users/242850/hendrix', u'accept_rate': 91, u'display_name': u'Hendrix', u'badge_counts': {u'bronze': 39, u'silver': 16, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt/2426894#comment5013122_2426894'}, {u'edited': False, u'reply_to_user': {u'user_id': 242850, u'user_type': u'registered', u'reputation': 2659, u'link': u'https://math.stackexchange.com/users/242850/hendrix', u'accept_rate': 91, u'display_name': u'Hendrix', u'badge_counts': {u'bronze': 39, u'silver': 16, u'gold': 2}}, u'comment_id': 5013129, u'creation_date': 1505246591, u'post_id': 2426894, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 475527, u'user_type': u'registered', u'reputation': 552, u'link': u'https://math.stackexchange.com/users/475527/fullofdill', u'display_name': u'FullofDill', u'badge_counts': {u'bronze': 5, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt/2426894#comment5013129_2426894'}], u'creation_date': 1505238804, u'comment_count': 5, u'score': 2, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt/2426894#2426894', u'body_markdown': u'I always think of it this way:

n! = number of unique permutations * number of times each unique permutation is copied

where n is the number of objects you are permuting. So if we divide n! by the number of times each permutation is copied, we get the right number. In your case, n=10 and each unique arrangement of flowers is copied 5!*3!*2! times



', u'owner': {u'user_id': 475527, u'user_type': u'registered', u'reputation': 552, u'link': u'https://math.stackexchange.com/users/475527/fullofdill', u'display_name': u'FullofDill', u'badge_counts': {u'bronze': 5, u'silver': 0, u'gold': 0}}, u'is_accepted': True, u'last_edit_date': 1505247182, u'share_link': u'https://math.stackexchange.com/a/2426894', u'answer_id': 2426894}]","I dislike combinatorial questions because I am not a native English speaker, and this entire field uses non-rigorous language, such as &quot;placing&quot;, &quot;choosing&quot;, &quot;taking away&quot; and uses playful examples like poker game, which uses words like &quot;diamond&quot; or &quot;spade&quot; that are foreign to me.

The biggest challenge for me right now is to trying to understand why we divide instead of subtract in doing combinatoric questions.

----------------------------------

*Example: A farmer is planting 5 red flowers, 3 yellow flowers, and 2 white flowers in a row. How many different ways can the farmer plant these flowers?*

Ok, so I answer this question like this:

Imagine we have a list of boxes that we can place these flowers in:

[][][][][][][][][][]

The first box can take on 5+3+2 = 10 flowers, next 9....so in total we have 10*9*8....*1 = 10! possible ways, if all flowers are labelled.

Since these flowers are not labelled, now I need to &quot;take away&quot; those &quot;repeated&quot; flowers. (&quot;Taking away&quot; - At least this is what teachers or textbook usually say)

*Ok, so what does &quot;take away&quot; mean? Thought experiment:If I had 5 apples, I take away 3, I have 2 left. Aha! So 5 - 3 = 2. Taking away means subtract!*

Since each of these 5 red flowers can be arranged in 5*4*3*2*1 = 5! ways, yellow flowers in 3! ways, and white flowers in 2! ways.

Therefore, the total number of ways the farmer can arrange these flowers is 10!-5!3!2!.

-----------------------------------
**Why am I wrong in this approach?
Why is the correct approach is to divide 10! by 5!3!2!?**","[I always think of it this way:

n! = number of unique permutations * number of times each unique permutation is copied

where n is the number of objects you are permuting. So if we divide n! by the number of times each permutation is copied, we get the right number. In your case, n=10 and each unique arrangement of flowers is copied 5!*3!*2! times



]",,,,,,7,"[{u'edited': False, u'comment_id': 5012747, u'creation_date': 1505239040, u'post_id': 2426882, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 43949, u'user_type': u'registered', u'reputation': 33779, u'link': u'https://math.stackexchange.com/users/43949/angryavian', u'accept_rate': 75, u'display_name': u'angryavian', u'badge_counts': {u'bronze': 74, u'silver': 28, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt#comment5012747_2426882'}, {u'edited': False, u'comment_id': 5012754, u'creation_date': 1505239100, u'post_id': 2426882, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 23350, u'user_type': u'moderator', u'reputation': 92817, u'link': u'https://math.stackexchange.com/users/23350/pedro-tamaroff', u'accept_rate': 95, u'display_name': u'Pedro Tamaroff', u'badge_counts': {u'bronze': 283, u'silver': 137, u'gold': 10}}, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt#comment5012754_2426882'}, {u'edited': False, u'comment_id': 5012771, u'creation_date': 1505239372, u'post_id': 2426882, u'score': 3, u'post_type': u'question', u'owner': {u'user_id': 2906, u'user_type': u'registered', u'reputation': 75037, u'link': u'https://math.stackexchange.com/users/2906/mark-bennet', u'accept_rate': 67, u'display_name': u'Mark Bennet', u'badge_counts': {u'bronze': 166, u'silver': 71, u'gold': 7}}, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt#comment5012771_2426882'}, {u'edited': False, u'reply_to_user': {u'user_id': 2906, u'user_type': u'registered', u'reputation': 75037, u'link': u'https://math.stackexchange.com/users/2906/mark-bennet', u'accept_rate': 67, u'display_name': u'Mark Bennet', u'badge_counts': {u'bronze': 166, u'silver': 71, u'gold': 7}}, u'comment_id': 5012786, u'creation_date': 1505239754, u'post_id': 2426882, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 242850, u'user_type': u'registered', u'reputation': 2659, u'link': u'https://math.stackexchange.com/users/242850/hendrix', u'accept_rate': 91, u'display_name': u'Hendrix', u'badge_counts': {u'bronze': 39, u'silver': 16, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt#comment5012786_2426882'}, {u'edited': False, u'comment_id': 5012820, u'creation_date': 1505240227, u'post_id': 2426882, u'score': 2, u'post_type': u'question', u'owner': {u'user_id': 1303, u'user_type': u'registered', u'reputation': 159689, u'link': u'https://math.stackexchange.com/users/1303/christian-blatter', u'display_name': u'Christian Blatter', u'badge_counts': {u'bronze': 300, u'silver': 104, u'gold': 7}}, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt#comment5012820_2426882'}, {u'edited': False, u'reply_to_user': {u'user_id': 1303, u'user_type': u'registered', u'reputation': 159689, u'link': u'https://math.stackexchange.com/users/1303/christian-blatter', u'display_name': u'Christian Blatter', u'badge_counts': {u'bronze': 300, u'silver': 104, u'gold': 7}}, u'comment_id': 5012838, u'creation_date': 1505240504, u'post_id': 2426882, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 242850, u'user_type': u'registered', u'reputation': 2659, u'link': u'https://math.stackexchange.com/users/242850/hendrix', u'accept_rate': 91, u'display_name': u'Hendrix', u'badge_counts': {u'bronze': 39, u'silver': 16, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt#comment5012838_2426882'}, {u'edited': False, u'comment_id': 5013306, u'creation_date': 1505251223, u'post_id': 2426882, u'score': 1, u'post_type': u'question', u'owner': {u'user_id': 135106, u'user_type': u'registered', u'reputation': 77587, u'link': u'https://math.stackexchange.com/users/135106/graham-kemp', u'display_name': u'Graham Kemp', u'badge_counts': {u'bronze': 71, u'silver': 32, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt#comment5013306_2426882'}]",1505238196,1,0,True,1505247182,,https://math.stackexchange.com/questions/2426882/what-does-take-away-mean-in-combinatoric-questions-why-divide-instead-of-subt,91.0,39.0,2.0,16.0,Hendrix,https://math.stackexchange.com/users/242850/hendrix,2659.0,242850.0,registered,,2426882,1,https://math.stackexchange.com/q/2426882,"[probability, combinatorics, examples-counterexamples]",What does &quot;take away&quot; mean in combinatoric questions: why divide instead of subtract?,2,48
8,,2,"[{u'up_vote_count': 0, u'title': u'Examples of super- and sub- martingale, which is not a random walk, nor a function of such', u'question_id': 2339714, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1498760805, u'creation_date': 1498760805, u'comment_count': 0, u'score': 0, u'link': u'https://math.stackexchange.com/questions/2339714/examples-of-super-and-sub-martingale-which-is-not-a-random-walk-nor-a-functi/2341023#2341023', u'body_markdown': u'**Example:** Consider a bowl containing $N$ marbles numbered $1,2,\ldots,N$. Choose marbles from the bowl at random, without replacement, until all have been chosen. Let $X_k$ be the number on the $k$th marble selected, and let $\mathcal F_n:=\sigma\{X_k: k=1,2,\ldots,n\}$ for $n=1,2,\ldots,N$. Define the event $B:=\{X_N=1\}$ (This choice of  $B$ is more or less arbitrary.) The sequence of random variables $M_n:=\Bbb E[B\mid\mathcal F_n]$, $n=1,2,\ldots,N$, is a martingale.

*Exercise:* Show that $M_n=\prod_{k=1}^n 1_{\{X_k\not=1\}}\cdot(N-n)^{-1}$ for $n=1,2,\ldots,N-1$.
', u'owner': {u'user_id': 189130, u'user_type': u'registered', u'reputation': 12038, u'link': u'https://math.stackexchange.com/users/189130/john-dawkins', u'display_name': u'John Dawkins', u'badge_counts': {u'bronze': 16, u'silver': 9, u'gold': 1}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2341023', u'answer_id': 2341023}, {u'up_vote_count': 3, u'title': u'Examples of super- and sub- martingale, which is not a random walk, nor a function of such', u'question_id': 2339714, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1498829907, u'comments': [{u'edited': False, u'comment_id': 4822467, u'creation_date': 1498846033, u'post_id': 2341540, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 3643, u'user_type': u'registered', u'reputation': 4178, u'link': u'https://math.stackexchange.com/users/3643/colin-mcquillan', u'display_name': u'Colin McQuillan', u'badge_counts': {u'bronze': 14, u'silver': 10, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2339714/examples-of-super-and-sub-martingale-which-is-not-a-random-walk-nor-a-functi/2341540#comment4822467_2341540'}, {u'edited': False, u'reply_to_user': {u'user_id': 3643, u'user_type': u'registered', u'reputation': 4178, u'link': u'https://math.stackexchange.com/users/3643/colin-mcquillan', u'display_name': u'Colin McQuillan', u'badge_counts': {u'bronze': 14, u'silver': 10, u'gold': 0}}, u'comment_id': 4823429, u'creation_date': 1498885488, u'post_id': 2341540, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2339714/examples-of-super-and-sub-martingale-which-is-not-a-random-walk-nor-a-functi/2341540#comment4823429_2341540'}, {u'edited': False, u'reply_to_user': {u'user_id': 3643, u'user_type': u'registered', u'reputation': 4178, u'link': u'https://math.stackexchange.com/users/3643/colin-mcquillan', u'display_name': u'Colin McQuillan', u'badge_counts': {u'bronze': 14, u'silver': 10, u'gold': 0}}, u'comment_id': 4853826, u'creation_date': 1499882092, u'post_id': 2341540, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195308, u'user_type': u'registered', u'reputation': 11821, u'link': u'https://math.stackexchange.com/users/195308/jason', u'accept_rate': 100, u'display_name': u'Jason', u'badge_counts': {u'bronze': 29, u'silver': 9, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2339714/examples-of-super-and-sub-martingale-which-is-not-a-random-walk-nor-a-functi/2341540#comment4853826_2341540'}], u'creation_date': 1498801751, u'comment_count': 3, u'score': 3, u'link': u'https://math.stackexchange.com/questions/2339714/examples-of-super-and-sub-martingale-which-is-not-a-random-walk-nor-a-functi/2341540#2341540', u'body_markdown': u'Let $(\Omega,\mathcal{A},\mathbb{P})$ be a probability space.

**Example 1:** For any filtration $(\mathcal{F}_n)_{n \geq 1}$ and any $X \in L^1$ the process $M_n := \mathbb{E}(X \mid \mathcal{F}_n)$ is a martingale.

**Example 2:** Let $(\mathcal{F}_n)_{n \geq 1}$ be a filtration and $\mu$ a finite measure on $\mathcal{F}_{\infty} := \sigma(\mathcal{F}_n; n \geq 1)$. Assume that $\mu|_{\mathcal{F}_n}$ is absolutely continuous with respect to $\mathbb{P}|_{\mathcal{F}_n}$, and denote by $M_n$ the Radon-Nikodym density. Then $(M_n)_{n \geq 1}$ is a martingale.

**Example 3:** Consider $\Omega := (0,1)$ endowed with the Lebesgue measure, and let $(a_n)_{n \in \mathbb{N}} \subseteq (0,1)$ be a sequence of monotonically decreasing numbers. Then $$M_n := \frac{1}{a_n} 1_{(0,a_n)}$$ is a martingale.', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'is_accepted': False, u'last_edit_date': 1498829907, u'share_link': u'https://math.stackexchange.com/a/2341540', u'answer_id': 2341540}]","A martingale $X_n$ is defined by these conditions:

(i) That $E|X_n| &lt;\infty$

(ii) That $X_n$ is adapted to $\mathcal{F}_n$ (filtration, i.e. sequence of sigma algebras)

(iii) That $E(X_{n+1} | \mathcal{F}_n) =X_n$ for all $n$

If &quot;$\leq$&quot; in (iii), $X_n$ is a supermartingale. If &quot;$\geq$&quot; in (iii), $X_n$ is a submartingale.

For details, see [Richard Durrett, Probability: Theory and Examples](https://services.math.duke.edu/~rtd/PTE/PTE4_1.pdf) p.198ff. (&lt;-- This is a legal copy uploaded by the author himself.) For brevity I will not repeat here.

By now I seem to have poor understanding of this abstract thing, due to lack of examples...&gt;&lt;

Indeed, it is straightforward to see, if $X_n$ is an iid sum of rvs, each with positive expectation, then $X_n$ is a submartingale. The same is true for &quot;zero expectation&quot; and &quot;martingale&quot;. The same is true for &quot;negative expectation&quot; and &quot;supermartingale&quot;.

For example, $X_n =\xi_1+\dotsb+\xi_n$, where $\xi_i$ all iid, observing Bernoulli, with value $\pm 1$, both probability 1/2. Then $X_n$ is a martingale. If $\xi_i =1$ for probability $&gt;1/2$, $X_n$ is a supermartingale. If $&lt;1/2$, $X_n$ is a submartingale.

And thm 5.2.3 of Durrett&#39;s book states that: If $X_n$ is a martingale and $\varphi$ is a convex function with $E|\varphi(X_n)| &lt; \infty$ for all $n$, then $\varphi(X_n)$ is a submartingale w.r.t. the same filtration. The same is true for &quot;concave function&quot; (still increasing) and &quot;supermartingale&quot;.

However, these conditions seem to portrait only a small subset of (super,sub)-martingales, and my imagination is limited. **Are there examples of martingales, supermartingales, and submartingales, which are not random walk (iid sum of rvs), nor are function of a random walk** (exploiting the fact of last paragraph)?","[**Example:** Consider a bowl containing $N$ marbles numbered $1,2,\ldots,N$. Choose marbles from the bowl at random, without replacement, until all have been chosen. Let $X_k$ be the number on the $k$th marble selected, and let $\mathcal F_n:=\sigma\{X_k: k=1,2,\ldots,n\}$ for $n=1,2,\ldots,N$. Define the event $B:=\{X_N=1\}$ (This choice of  $B$ is more or less arbitrary.) The sequence of random variables $M_n:=\Bbb E[B\mid\mathcal F_n]$, $n=1,2,\ldots,N$, is a martingale.

*Exercise:* Show that $M_n=\prod_{k=1}^n 1_{\{X_k\not=1\}}\cdot(N-n)^{-1}$ for $n=1,2,\ldots,N-1$.
, Let $(\Omega,\mathcal{A},\mathbb{P})$ be a probability space.

**Example 1:** For any filtration $(\mathcal{F}_n)_{n \geq 1}$ and any $X \in L^1$ the process $M_n := \mathbb{E}(X \mid \mathcal{F}_n)$ is a martingale.

**Example 2:** Let $(\mathcal{F}_n)_{n \geq 1}$ be a filtration and $\mu$ a finite measure on $\mathcal{F}_{\infty} := \sigma(\mathcal{F}_n; n \geq 1)$. Assume that $\mu|_{\mathcal{F}_n}$ is absolutely continuous with respect to $\mathbb{P}|_{\mathcal{F}_n}$, and denote by $M_n$ the Radon-Nikodym density. Then $(M_n)_{n \geq 1}$ is a martingale.

**Example 3:** Consider $\Omega := (0,1)$ endowed with the Lebesgue measure, and let $(a_n)_{n \in \mathbb{N}} \subseteq (0,1)$ be a sequence of monotonically decreasing numbers. Then $$M_n := \frac{1}{a_n} 1_{(0,a_n)}$$ is a martingale.]",,,,,,0,,1498674549,0,0,True,1498829907,,https://math.stackexchange.com/questions/2339714/examples-of-super-and-sub-martingale-which-is-not-a-random-walk-nor-a-functi,,11.0,0.0,1.0,Aminopterin,https://math.stackexchange.com/users/392335/aminopterin,977.0,392335.0,registered,,2339714,3,https://math.stackexchange.com/q/2339714,"[probability, examples-counterexamples, martingales, conditional-expectation, random-walk]","Examples of super- and sub- martingale, which is not a random walk, nor a function of such",3,443
9,2253693.0,5,"[{u'up_vote_count': 2, u'title': u'The &quot;true&quot; domain of random variables', u'question_id': 2233721, u'tags': [], u'down_vote_count': 2, u'last_activity_date': 1492175217, u'comments': [{u'edited': False, u'comment_id': 4593238, u'creation_date': 1492175943, u'post_id': 2233860, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2233860#comment4593238_2233860'}, {u'edited': False, u'comment_id': 4593242, u'creation_date': 1492176020, u'post_id': 2233860, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2233860#comment4593242_2233860'}, {u'edited': False, u'comment_id': 4593725, u'creation_date': 1492184614, u'post_id': 2233860, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2233860#comment4593725_2233860'}, {u'edited': False, u'reply_to_user': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'comment_id': 4593741, u'creation_date': 1492184980, u'post_id': 2233860, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 83396, u'user_type': u'registered', u'reputation': 64295, u'link': u'https://math.stackexchange.com/users/83396/ian', u'accept_rate': 71, u'display_name': u'Ian', u'badge_counts': {u'bronze': 79, u'silver': 44, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2233860#comment4593741_2233860'}], u'creation_date': 1492175217, u'comment_count': 4, u'score': 0, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2233860#2233860', u'body_markdown': u'There is no such &quot;true&quot; space.  Measure theory is a **model** to use for probability.  It is not the &quot;true&quot; probability.  A probabilist need not mention any measure space.  But an analyst (like me) prefers to talk about $(\Omega, \mathcal F,\mathbb P)$, which seems foreign to a probabilist.

This is the same thing as saying a differential equation is a **model** for a vibrating string: it is not the &quot;true&quot; vibrating string.   

Or (in mathematics) ZFC can specify a **model** for sets, but they are not necessarily the &quot;true&quot; sets.', u'owner': {u'user_id': 442, u'user_type': u'registered', u'reputation': 57510, u'link': u'https://math.stackexchange.com/users/442/gedgar', u'accept_rate': 17, u'display_name': u'GEdgar', u'badge_counts': {u'bronze': 161, u'silver': 62, u'gold': 2}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2233860', u'answer_id': 2233860}, {u'up_vote_count': 2, u'title': u'The &quot;true&quot; domain of random variables', u'question_id': 2233721, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1493231537, u'comments': [{u'edited': False, u'comment_id': 4633230, u'creation_date': 1493203278, u'post_id': 2245672, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2245672#comment4633230_2245672'}, {u'edited': False, u'comment_id': 4633234, u'creation_date': 1493203326, u'post_id': 2245672, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2245672#comment4633234_2245672'}, {u'edited': False, u'comment_id': 4633235, u'creation_date': 1493203331, u'post_id': 2245672, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2245672#comment4633235_2245672'}, {u'edited': False, u'comment_id': 4633236, u'creation_date': 1493203347, u'post_id': 2245672, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2245672#comment4633236_2245672'}, {u'edited': False, u'comment_id': 4633237, u'creation_date': 1493203359, u'post_id': 2245672, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2245672#comment4633237_2245672'}, {u'edited': False, u'reply_to_user': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'comment_id': 4634559, u'creation_date': 1493231552, u'post_id': 2245672, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195308, u'user_type': u'registered', u'reputation': 11821, u'link': u'https://math.stackexchange.com/users/195308/jason', u'accept_rate': 100, u'display_name': u'Jason', u'badge_counts': {u'bronze': 29, u'silver': 9, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2245672#comment4634559_2245672'}, {u'edited': False, u'comment_id': 4637092, u'creation_date': 1493303029, u'post_id': 2245672, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2245672#comment4637092_2245672'}, {u'edited': False, u'comment_id': 4637102, u'creation_date': 1493303183, u'post_id': 2245672, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2245672#comment4637102_2245672'}, {u'edited': False, u'reply_to_user': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'comment_id': 4640147, u'creation_date': 1493385088, u'post_id': 2245672, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195308, u'user_type': u'registered', u'reputation': 11821, u'link': u'https://math.stackexchange.com/users/195308/jason', u'accept_rate': 100, u'display_name': u'Jason', u'badge_counts': {u'bronze': 29, u'silver': 9, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2245672#comment4640147_2245672'}, {u'edited': False, u'reply_to_user': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'comment_id': 4640150, u'creation_date': 1493385165, u'post_id': 2245672, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195308, u'user_type': u'registered', u'reputation': 11821, u'link': u'https://math.stackexchange.com/users/195308/jason', u'accept_rate': 100, u'display_name': u'Jason', u'badge_counts': {u'bronze': 29, u'silver': 9, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2245672#comment4640150_2245672'}, {u'edited': False, u'comment_id': 4642647, u'creation_date': 1493464481, u'post_id': 2245672, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2245672#comment4642647_2245672'}], u'awarded_bounty_users': [{u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}], u'awarded_bounty_amount': 150, u'comment_count': 11, u'score': 2, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2245672#2245672', u'body_markdown': u'If you are only interested in a specific collection of random variables, then I would argue that the most &quot;natural&quot; setting is to look at their joint law as you have done for the coin tosses. For example, if $(Z_n)$ is an iid sequence of $\mathcal N(0,1)$ random variables, we would have $\Omega=\mathbb R^{\mathbb N}$, $\mathcal F$ the (Borel) product $\sigma$-field, and $\mathbb P$ the probability measure such that
$$\mathbb P\left\{\omega\in\mathbb R^{\mathbb N}\,:\,\omega(n)\in A_n\text{ for }n=1,\ldots,N\right\}=\prod_{n=1}^N\frac1{\sqrt{2\pi}}\int_{A_n}e^{\frac{-x_n^2}{2}}dx_n$$
for all Borel sets $A_1,\ldots,A_N$ (recall this uniquely defines a probability measure by Kolmogorov&#39;s theorem). In this case we have $Z_n(\omega):=\omega(n)$. Of course, having the random variables be independent is a trivial example, but the basic idea remains in far greater generality: suppose for each $i\in I$, we have a measurable space $(E_i,\mathcal A_i)$ and random variables $X_i$ defined on $E_i$ such that
$$\mathbb P(X_i\in A_i\text{ for }i\in F)=:p\bigg(F,\prod_{i\in F}A_i\bigg)$$
is known for every *finite* $F\subset I$ and every collection of measurable sets $A_i\in\mathcal A_i$. Consider $\Omega:=\prod_{i\in I}E_i$, $\mathcal F$ the product $\sigma$-field of the $\mathcal A_i$&#39;s, and the unique probability measure $\mu$ on $\mathcal F$ such that
$$\mu\{\omega\in\Omega\,:\,\omega(i)\in A_i\text{ for }i\in F\}=p\bigg(F,\prod_{i\in F}A_i\bigg).$$
As far as the collection of random variables $(X_i)$ is concerned, $(\Omega,\mathcal F,\mu)$ knows as much as whatever our original probability space does, so we may as well assume our original space was $(\Omega,\mathcal F)$ with $\mathbb P=\mu$. Again, in this case we have $X_i(\omega)=\omega(i)$.

This set-up is not perfect, of course. For a simple example, take Brownian motion $(B_t)$. We would like to say $\mathbb P(t\mapsto B_t\text{ is continuous})=1$, but under the product $\sigma$-field this event is not even measurable. There are ways to work around such problems (in this specific case you use Kolmogorov&#39;s continuity theorem) but are usually handled on a case-by-case basis.

Another issue is when you are looking at a sequence of spaces. Consider for instance particles on the discrete $N$-torus performing symmetric simple exclusion. Explicitly, each particle independently performs a (continuous time) simple random walk on the the torus $\mathbb T_N:=\mathbb Z/N\mathbb Z$, but if a particle attempts to jump to a position which is already occupied, no jump occurs. It is interesting to consider the asymptotics of such a process, i.e. what happens as $N$ becomes large. But for distinct $N$, we necessarily require different probability spaces. How does it make sense to consider different $N$ simultaneously? What would be the probability of an event of the form
$$\{\text{the system on the $N$-torus is at state $A$}\}\cap\{\text{the system on the $M$-torus is at state $B$}\}?$$

This is why we don&#39;t usually bother with the probability space too much. We know it exists - Kolmogorov&#39;s theorem guarantees that in many cases, and when there is delicate points like continuity, there are theorems that get around the problem. So we ignore it. Why do we care about the space? It&#39;s not that it&#39;s something so abstract we couldn&#39;t possibly begin to understand it, but we are almost without exception interested in some collection of random variables, and knowing everything we can about their joint law is enough.

EDIT: To address your questions below.

$1)$ The [Kac-Rice][1] formula provides a method for computing the (expected) number of zeroes of a smooth Gaussian field. The source I have linked deals exclusively with the case where the field depends only on finitely many iid $\mathcal N(0,1)$ random variables, in which case existence of the appropriate probability space is dealt with via our earlier example. However, the Kac-Rice formula still holds for a more general smooth Gaussian field $F:U\rightarrow\mathbb R$ for some open $U\subset\mathbb R^N$, only we now need to be careful in what conditions we place on the correlations; without a certain degree of correlation, we cannot hope to have a smooth field (e.g. if $\{F(x)\}_{x\in U}$ are iid then obviously $F$ is not smooth, or even continuous). Once we have appropriate conditions, the approach is similar to the Brownian motion case: first we construct a field in the standard (i.e. Kolmogorov consistency theorem) way, and then we show there is a smooth version.

$2)$ I don&#39;t believe there is a sensible answer to this question. This is common when we model particle systems using probability theory: we assume there are $N$ particles and construct our model, then we see what happens if $N$ is large (which seems sensible since if our system is macroscopic, we would expect something on the order of $10^{20}$ particles). We are not assuming that, for instance, we have some global space and then we keep adding more particles - for each $N$, the models are distinct. As you may imagine one needs to think about what it means for such a system to &quot;converge&quot; - typically, we will identify the state of the system with some empirical measure and then consider weak convergence of measures.

$3)$ One must be careful to remember that random variables and probability theory in general is a *model* for statistics, they are NOT the same thing. So strictly speaking, there isn&#39;t some abstract probability space underlying people&#39;s heights; height is deterministic, and it is simply a matter of who you choose to survey. Of course, it may be extremely useful to model such an experiment as drawing a sample of size $N$ from a particular distribution. I would argue that the most &quot;natural&quot; probability space for this model would be the joint law of an independent (infinite) sequence of random variables of the given distribution. So for example, if our distribution was the standard normal (which is obviously absurd for height, but you get the idea), then the natural space is the very first example I gave. As we saw there, this probability measure is more than capable with dealing with only a finite number of random variables, and has the advantage that it does not matter what your size $N$ is - you could keep surveying more people if you wanted. Again, this is getting into how you choose to model a specific experiment or problem, and it is important not to assert that there is a &quot;true&quot; probability space.


  [1]: http://www3.nd.edu/~lnicolae/Kac_Rice.pdf', u'owner': {u'user_id': 195308, u'user_type': u'registered', u'reputation': 11821, u'link': u'https://math.stackexchange.com/users/195308/jason', u'accept_rate': 100, u'display_name': u'Jason', u'badge_counts': {u'bronze': 29, u'silver': 9, u'gold': 1}}, u'is_accepted': False, u'last_edit_date': 1493231537, u'creation_date': 1492812381, u'share_link': u'https://math.stackexchange.com/a/2245672', u'answer_id': 2245672}, {u'up_vote_count': 1, u'title': u'The &quot;true&quot; domain of random variables', u'question_id': 2233721, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1493014597, u'comments': [{u'edited': False, u'comment_id': 4633203, u'creation_date': 1493202107, u'post_id': 2249288, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2249288#comment4633203_2249288'}], u'creation_date': 1493014597, u'comment_count': 1, u'score': 1, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2249288#2249288', u'body_markdown': u'The sample space is usually chosen as the simplest and easiest-to-understand representation of the relevant aspects of the system.

For the experiment of flipping $n$ coins, the sample space $\{H,T\}^n$ is good because all of its $2^n$ outcomes are equally likely.  One could alternatively use the sample space $\{1, ..., n\}$, but then one needs to assign non-equal probability masses, and those would be computed with the equally-likely model for $\{H,T\}^n$ in mind. 

In standard probability courses, a lot of probability is done even before defining random variables.  Abstract sample spaces are used and axioms are defined.  This shows how a variety of different situations can be treated and emphasizes important concepts of _outcome_ and _event_.  

The topic of random variables occurs only later in standard courses.  Random variables are good ways to represent events of interest.  It is encouraging to know that random variables have a direct connection with sample spaces and probability axioms (so that the same probability theory that was learned before still applies). It is also useful to recognize that many different probability experiments can be modeled by the same kinds of random variables, i.e., variables with the same cumulative distribution functions (CDFs). In some cases it is easier to work directly with the CDFs (or joint CDFs for random vectors), rather than describing a sample space.  This is a way of representing the problem very simply, where the random variables or vectors are just identity functions on $\mathbb{R}$ or $\mathbb{R}^n$. ', u'owner': {u'user_id': 155065, u'user_type': u'registered', u'reputation': 11879, u'link': u'https://math.stackexchange.com/users/155065/michael', u'display_name': u'Michael', u'badge_counts': {u'bronze': 23, u'silver': 11, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2249288', u'answer_id': 2249288}, {u'up_vote_count': 2, u'title': u'The &quot;true&quot; domain of random variables', u'question_id': 2233721, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1498480494, u'comments': [{u'edited': False, u'comment_id': 4637124, u'creation_date': 1493303531, u'post_id': 2253693, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2253693#comment4637124_2253693'}, {u'edited': False, u'comment_id': 4637127, u'creation_date': 1493303573, u'post_id': 2253693, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2253693#comment4637127_2253693'}, {u'edited': False, u'reply_to_user': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'comment_id': 4637479, u'creation_date': 1493310279, u'post_id': 2253693, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 408433, u'user_type': u'registered', u'reputation': 841, u'link': u'https://math.stackexchange.com/users/408433/bey', u'accept_rate': 100, u'display_name': u'Bey', u'badge_counts': {u'bronze': 9, u'silver': 1, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2253693#comment4637479_2253693'}], u'creation_date': 1493238593, u'comment_count': 3, u'score': 2, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2253693#2253693', u'body_markdown': u'Here is [paper][1] that discusses your question (see page 3). And this stack overflow question:
https://math.stackexchange.com/questions/18198/what-are-the-sample-spaces-when-talking-about-continuous-random-variables

As you&#39;ll see, random variables are *not* required to use probability theory, they are just convenient ways to capture aspects of the underlying sample space we are interested in. We could choose to work directly with the underlying sample space if we knew it (as a running example I will use $\Omega = \{H,T\}^N$ for an N-coin-toss experiment). 

Basically, the decision to model outcomes of an experiment as a random variable or treat them as direct observations of the sample space is mostly a matter of perspective. The random variables view separates the *object* itself (possibly an abstract object) $\omega \in \Omega$ from the questions we can ask about it (e.g., &quot;HH&quot; vs &quot;Number of tails&quot;,&quot;Number of Heads&quot;, &quot;At least one tail&quot;, &quot;No more than 2 Heads&quot; etc).

If you only care about one question, then the views are isomorphic. However, if you want to ask multiple questions about the same observational unit, then the random variables view is more consistent with what you are trying to do. For example, you ask the height and weight of 100 randomly chosen people -- in this case, a random variables view makes more sense, as &quot;height&quot; and &quot;weights&quot; are not independent objects in the real world that &quot;just happen&quot; to be correlated - they are linked through people ($\omega \in \Omega$). 

So, let&#39;s say I gave you the underlying sample space  $\Omega$ for a problem. Now what? You will want to start to ask questions about the probability of various events defined as measurable sets with elements from $\Omega$ (e.g., all outcomes where we toss at least three heads). There are two ways to do this:

 1. Create the set of all $\omega \in \Omega$ that have three heads and then calculate the probability of this set.
 2. Define an integer-valued random variable $X(\omega)$ that returns the number of heads in $\omega$. This will create a new sample space called the [*image*][2] of $X(\omega)$, along with an *induced* probability measure $P&#39;$ that is defined over the integers 0 to N. This induced measure is called a [pushforward measure (or image measure)][3]. Now you can re-cast your question as $P&#39;(X=3)$ as opposed to $P(\{\omega \in \Omega: \#\text{Heads}(\omega) = 3\})$ using the original space. 

You are probably familiar with this stuff -- however, you want to know **why** we bother with it. In the case of the analysis of a single random variable, we can very well re-define our sample space by using the induced sample space (or simply define a sample space to match the properties of the random variable).

This changes when we move to [*jointly distributed* random variables][4]. Without $\Omega$ (at least implicitly), we&#39;d have no way to index *joint observations*. Here&#39;s an example:

Lets say you sample 5 values from each of two random variables, $X$ and $Y$:

 - Observed X&#39;s = $1,1,2,5,3$
 - Observed Y&#39;s = $0,1,1,0,1$

Now, you want to develop a joint distribution that describes these observations *as random variables* (i.e., different aspects of some common object). How will you do this? Most importantly, you need to first *associate* an observation from $X$ with an observation from $Y$. Implicit in this association is the assumption that there is some common sample space $\Omega_J$ that justifies us associating, say, the first observation of $X$ with the first observation of $Y$ to form the joint observation $(1,0)$ (in this example).

So, in my example, we are assuming there is some underlying event $\omega&#39;\in \Omega_J$ such that $X(\omega&#39;)=1$ and $Y(\omega&#39;)=0$ and that there is a valid underlying probability space $(\Omega_J,\mathcal{F}_J,P_J)$ whose *image* will produce the observed joint distribution of $(X,Y)$.

However, we could dispense with all of this if we chose to model $X,Y$ not as random variables but as **direct observations** (the integers are our experimental units or foundation data). 

At this point, you may still be unconvinced of the usefulness of the sample space view...

So, let&#39;s say you develop your distribution of $X,Y$ directly (no sample space[i.e., domain-less in your terminology]), then you want to add a new quantity $Z$. How do you do this. Without an underlying sample space you need to develop the joint distribution manually from first principles (i.e., ad hoc) whereas invoking the idea of an underlying sample space makes extending joint distributions a natural consequence of defining a new function over the same (usually implicit) underlying probability space. The fact that this can be assumed to be true is a major theoretical elegance of modern probability theory.

Again, it&#39;s a matter of perspective, but the random variables view, at least to me, has a philosophical/conceptual elegance to it when you consider joint observations and stochastic processes.

Here is a [nice post in math.overflow][5] that discusses something similar.


  [1]: http://dsp.ucsd.edu/~kreutz/PEI-05%20Support%20Files/Basic%20Random%20Variables%20Concepts.pdf
  [2]: https://en.wikipedia.org/wiki/Image_(mathematics)
  [3]: https://en.wikipedia.org/wiki/Pushforward_measure
  [4]: http://www.math.uiuc.edu/~rsong/461f10/lect6.pdf
  [5]: https://mathoverflow.net/questions/250500/why-do-we-need-random-variables', u'owner': {u'user_id': 408433, u'user_type': u'registered', u'reputation': 841, u'link': u'https://math.stackexchange.com/users/408433/bey', u'accept_rate': 100, u'display_name': u'Bey', u'badge_counts': {u'bronze': 9, u'silver': 1, u'gold': 0}}, u'is_accepted': True, u'last_edit_date': 1498480494, u'share_link': u'https://math.stackexchange.com/a/2253693', u'answer_id': 2253693}, {u'up_vote_count': 0, u'title': u'The &quot;true&quot; domain of random variables', u'question_id': 2233721, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1519054489, u'comments': [{u'edited': False, u'comment_id': 5488173, u'creation_date': 1519052942, u'post_id': 2657010, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 16397, u'user_type': u'registered', u'reputation': 7367, u'link': u'https://math.stackexchange.com/users/16397/r-e-s', u'accept_rate': 68, u'display_name': u'r.e.s.', u'badge_counts': {u'bronze': 50, u'silver': 18, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2657010#comment5488173_2657010'}], u'creation_date': 1519049602, u'comment_count': 1, u'score': 0, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables/2657010#2657010', u'body_markdown': u'(Note: the details in this post are not completely correct; there is some awkwardness related to events of probability zero. What one needs is the [Loomis-Sikorski representation theorem][1], as indicated by the comment by @r.e.s. )

There is a generic construction, which basically defines

&gt; A sample is a consistent way of specifying which events hold and which events do not

Let $\mathcal{E}$ be the set of all possible *events* that can be constructed &amp;mdash; that is, boolean valued random variables. Or equivalently, all real random variables that take values in $\{ 0, 1 \}$.

For example, if $X$ is a real random variable, then for every real number $x$, then $X &gt; x$ is an event. (and the collection of all of these events uniquely determines $X$)

The boolean operations (e.g. $\wedge$, $\vee$, and $\neg$) give operations on $\mathcal{E}$. If you develop random sets in one reasonable way, then $\mathcal{E}$ will actually be an abstract $\sigma$-algebra. 

[Stone&#39;s representation theorem][2] says that, every abstract $\sigma$-algebra can be expressed as a $\sigma$-algebra of subsets of a set $\Omega$.

The theorem also gives a specific way to construct such an $\Omega$: as the set of ultrafilters on $\mathcal{E}$. The definition of ultrafilter is pretty much literally a precise way to state the definition given at the top of this post.

We can take $(\Omega, \mathcal{E})$ as the underlying measurable space. All events are measurable functions on this space, and two events are the same if and only if they correspond to the same measurable function, so this space really does give a faithful way to talk about the random variables.

---

In your example of flipping $n$ coins, if you take the events to be the ones you can construct out of the events &quot;the $n$-th coin is heads&quot;. Running through this construction really does lead to $\Omega \cong \{ H, T \}^n$.

---

Incidentally, there is an approach to measure theory that complete eliminates the need to have a sample space: that of [measurable locales][3]


  [1]: https://terrytao.wordpress.com/tag/stone-representation-theorem/
  [2]: https://en.wikipedia.org/wiki/Stone%27s_representation_theorem_for_Boolean_algebras
  [3]: https://ncatlab.org/nlab/show/measurable+locale', u'owner': {u'user_id': 14972, u'user_type': u'registered', u'reputation': 104735, u'link': u'https://math.stackexchange.com/users/14972/hurkyl', u'accept_rate': 62, u'display_name': u'Hurkyl', u'badge_counts': {u'bronze': 243, u'silver': 104, u'gold': 8}}, u'is_accepted': False, u'last_edit_date': 1519054489, u'share_link': u'https://math.stackexchange.com/a/2657010', u'answer_id': 2657010}]","Typically in applied probabilistic or statical literature we work with random variables whose domain we don&#39;t specify. We just care about the set in which the random variables takes values.

For example, the number of aces in hand at a certain cardgame, the height of a population or the income of a company in a certain year are all random variables (the last two examples come from statistics).
But in all of these examples, the domain is never given.

While we could always construct any number of artificial probability spaces, that would serve as domain,  I&#39;m interested in what a  Ã∂&quot;Ã∂tÃ∂rÃ∂uÃ∂eÃ∂&quot;  compelling probability space domain could be that really models (the underlying the experiment of) these three examples?

**EDIT** To prevent unclarity with what I mean by &quot;compelling&quot;. Let me be more precise by giving an example: Consider the random variable that counts the number of heads when flipping a coin $n$ times. Thus it takes values from $0,1,\ldots,n$. But which experiment would most likely be perform in order to lead to these values?     
 The most complelling space $\Omega$ would be $\Omega=\{ H,T\}^n$, the space of sequences of $n$ coin flipping, since this is what actually happens.      
 But one could just as well define this random variable on the set $\{0,1,‚Ä¶,n\}$, in which case the random variable would be the identity function. This space I would call artificial, not &quot;compelling&quot;, because it doesn&#39;t give an accurate representation of the underlying experiment any more.      
In particular I&#39;m interested in the underlying space for the statistical examples.

P.S. See also [this][1] other question of mine, which also has a bounty running.


  [1]: https://math.stackexchange.com/questions/2233731/discarding-random-variables-in-favor-of-a-domain-less-definition","[There is no such &quot;true&quot; space.  Measure theory is a **model** to use for probability.  It is not the &quot;true&quot; probability.  A probabilist need not mention any measure space.  But an analyst (like me) prefers to talk about $(\Omega, \mathcal F,\mathbb P)$, which seems foreign to a probabilist.

This is the same thing as saying a differential equation is a **model** for a vibrating string: it is not the &quot;true&quot; vibrating string.   

Or (in mathematics) ZFC can specify a **model** for sets, but they are not necessarily the &quot;true&quot; sets., If you are only interested in a specific collection of random variables, then I would argue that the most &quot;natural&quot; setting is to look at their joint law as you have done for the coin tosses. For example, if $(Z_n)$ is an iid sequence of $\mathcal N(0,1)$ random variables, we would have $\Omega=\mathbb R^{\mathbb N}$, $\mathcal F$ the (Borel) product $\sigma$-field, and $\mathbb P$ the probability measure such that
$$\mathbb P\left\{\omega\in\mathbb R^{\mathbb N}\,:\,\omega(n)\in A_n\text{ for }n=1,\ldots,N\right\}=\prod_{n=1}^N\frac1{\sqrt{2\pi}}\int_{A_n}e^{\frac{-x_n^2}{2}}dx_n$$
for all Borel sets $A_1,\ldots,A_N$ (recall this uniquely defines a probability measure by Kolmogorov&#39;s theorem). In this case we have $Z_n(\omega):=\omega(n)$. Of course, having the random variables be independent is a trivial example, but the basic idea remains in far greater generality: suppose for each $i\in I$, we have a measurable space $(E_i,\mathcal A_i)$ and random variables $X_i$ defined on $E_i$ such that
$$\mathbb P(X_i\in A_i\text{ for }i\in F)=:p\bigg(F,\prod_{i\in F}A_i\bigg)$$
is known for every *finite* $F\subset I$ and every collection of measurable sets $A_i\in\mathcal A_i$. Consider $\Omega:=\prod_{i\in I}E_i$, $\mathcal F$ the product $\sigma$-field of the $\mathcal A_i$&#39;s, and the unique probability measure $\mu$ on $\mathcal F$ such that
$$\mu\{\omega\in\Omega\,:\,\omega(i)\in A_i\text{ for }i\in F\}=p\bigg(F,\prod_{i\in F}A_i\bigg).$$
As far as the collection of random variables $(X_i)$ is concerned, $(\Omega,\mathcal F,\mu)$ knows as much as whatever our original probability space does, so we may as well assume our original space was $(\Omega,\mathcal F)$ with $\mathbb P=\mu$. Again, in this case we have $X_i(\omega)=\omega(i)$.

This set-up is not perfect, of course. For a simple example, take Brownian motion $(B_t)$. We would like to say $\mathbb P(t\mapsto B_t\text{ is continuous})=1$, but under the product $\sigma$-field this event is not even measurable. There are ways to work around such problems (in this specific case you use Kolmogorov&#39;s continuity theorem) but are usually handled on a case-by-case basis.

Another issue is when you are looking at a sequence of spaces. Consider for instance particles on the discrete $N$-torus performing symmetric simple exclusion. Explicitly, each particle independently performs a (continuous time) simple random walk on the the torus $\mathbb T_N:=\mathbb Z/N\mathbb Z$, but if a particle attempts to jump to a position which is already occupied, no jump occurs. It is interesting to consider the asymptotics of such a process, i.e. what happens as $N$ becomes large. But for distinct $N$, we necessarily require different probability spaces. How does it make sense to consider different $N$ simultaneously? What would be the probability of an event of the form
$$\{\text{the system on the $N$-torus is at state $A$}\}\cap\{\text{the system on the $M$-torus is at state $B$}\}?$$

This is why we don&#39;t usually bother with the probability space too much. We know it exists - Kolmogorov&#39;s theorem guarantees that in many cases, and when there is delicate points like continuity, there are theorems that get around the problem. So we ignore it. Why do we care about the space? It&#39;s not that it&#39;s something so abstract we couldn&#39;t possibly begin to understand it, but we are almost without exception interested in some collection of random variables, and knowing everything we can about their joint law is enough.

EDIT: To address your questions below.

$1)$ The [Kac-Rice][1] formula provides a method for computing the (expected) number of zeroes of a smooth Gaussian field. The source I have linked deals exclusively with the case where the field depends only on finitely many iid $\mathcal N(0,1)$ random variables, in which case existence of the appropriate probability space is dealt with via our earlier example. However, the Kac-Rice formula still holds for a more general smooth Gaussian field $F:U\rightarrow\mathbb R$ for some open $U\subset\mathbb R^N$, only we now need to be careful in what conditions we place on the correlations; without a certain degree of correlation, we cannot hope to have a smooth field (e.g. if $\{F(x)\}_{x\in U}$ are iid then obviously $F$ is not smooth, or even continuous). Once we have appropriate conditions, the approach is similar to the Brownian motion case: first we construct a field in the standard (i.e. Kolmogorov consistency theorem) way, and then we show there is a smooth version.

$2)$ I don&#39;t believe there is a sensible answer to this question. This is common when we model particle systems using probability theory: we assume there are $N$ particles and construct our model, then we see what happens if $N$ is large (which seems sensible since if our system is macroscopic, we would expect something on the order of $10^{20}$ particles). We are not assuming that, for instance, we have some global space and then we keep adding more particles - for each $N$, the models are distinct. As you may imagine one needs to think about what it means for such a system to &quot;converge&quot; - typically, we will identify the state of the system with some empirical measure and then consider weak convergence of measures.

$3)$ One must be careful to remember that random variables and probability theory in general is a *model* for statistics, they are NOT the same thing. So strictly speaking, there isn&#39;t some abstract probability space underlying people&#39;s heights; height is deterministic, and it is simply a matter of who you choose to survey. Of course, it may be extremely useful to model such an experiment as drawing a sample of size $N$ from a particular distribution. I would argue that the most &quot;natural&quot; probability space for this model would be the joint law of an independent (infinite) sequence of random variables of the given distribution. So for example, if our distribution was the standard normal (which is obviously absurd for height, but you get the idea), then the natural space is the very first example I gave. As we saw there, this probability measure is more than capable with dealing with only a finite number of random variables, and has the advantage that it does not matter what your size $N$ is - you could keep surveying more people if you wanted. Again, this is getting into how you choose to model a specific experiment or problem, and it is important not to assert that there is a &quot;true&quot; probability space.


  [1]: http://www3.nd.edu/~lnicolae/Kac_Rice.pdf, The sample space is usually chosen as the simplest and easiest-to-understand representation of the relevant aspects of the system.

For the experiment of flipping $n$ coins, the sample space $\{H,T\}^n$ is good because all of its $2^n$ outcomes are equally likely.  One could alternatively use the sample space $\{1, ..., n\}$, but then one needs to assign non-equal probability masses, and those would be computed with the equally-likely model for $\{H,T\}^n$ in mind. 

In standard probability courses, a lot of probability is done even before defining random variables.  Abstract sample spaces are used and axioms are defined.  This shows how a variety of different situations can be treated and emphasizes important concepts of _outcome_ and _event_.  

The topic of random variables occurs only later in standard courses.  Random variables are good ways to represent events of interest.  It is encouraging to know that random variables have a direct connection with sample spaces and probability axioms (so that the same probability theory that was learned before still applies). It is also useful to recognize that many different probability experiments can be modeled by the same kinds of random variables, i.e., variables with the same cumulative distribution functions (CDFs). In some cases it is easier to work directly with the CDFs (or joint CDFs for random vectors), rather than describing a sample space.  This is a way of representing the problem very simply, where the random variables or vectors are just identity functions on $\mathbb{R}$ or $\mathbb{R}^n$. , Here is [paper][1] that discusses your question (see page 3). And this stack overflow question:
https://math.stackexchange.com/questions/18198/what-are-the-sample-spaces-when-talking-about-continuous-random-variables

As you&#39;ll see, random variables are *not* required to use probability theory, they are just convenient ways to capture aspects of the underlying sample space we are interested in. We could choose to work directly with the underlying sample space if we knew it (as a running example I will use $\Omega = \{H,T\}^N$ for an N-coin-toss experiment). 

Basically, the decision to model outcomes of an experiment as a random variable or treat them as direct observations of the sample space is mostly a matter of perspective. The random variables view separates the *object* itself (possibly an abstract object) $\omega \in \Omega$ from the questions we can ask about it (e.g., &quot;HH&quot; vs &quot;Number of tails&quot;,&quot;Number of Heads&quot;, &quot;At least one tail&quot;, &quot;No more than 2 Heads&quot; etc).

If you only care about one question, then the views are isomorphic. However, if you want to ask multiple questions about the same observational unit, then the random variables view is more consistent with what you are trying to do. For example, you ask the height and weight of 100 randomly chosen people -- in this case, a random variables view makes more sense, as &quot;height&quot; and &quot;weights&quot; are not independent objects in the real world that &quot;just happen&quot; to be correlated - they are linked through people ($\omega \in \Omega$). 

So, let&#39;s say I gave you the underlying sample space  $\Omega$ for a problem. Now what? You will want to start to ask questions about the probability of various events defined as measurable sets with elements from $\Omega$ (e.g., all outcomes where we toss at least three heads). There are two ways to do this:

 1. Create the set of all $\omega \in \Omega$ that have three heads and then calculate the probability of this set.
 2. Define an integer-valued random variable $X(\omega)$ that returns the number of heads in $\omega$. This will create a new sample space called the [*image*][2] of $X(\omega)$, along with an *induced* probability measure $P&#39;$ that is defined over the integers 0 to N. This induced measure is called a [pushforward measure (or image measure)][3]. Now you can re-cast your question as $P&#39;(X=3)$ as opposed to $P(\{\omega \in \Omega: \#\text{Heads}(\omega) = 3\})$ using the original space. 

You are probably familiar with this stuff -- however, you want to know **why** we bother with it. In the case of the analysis of a single random variable, we can very well re-define our sample space by using the induced sample space (or simply define a sample space to match the properties of the random variable).

This changes when we move to [*jointly distributed* random variables][4]. Without $\Omega$ (at least implicitly), we&#39;d have no way to index *joint observations*. Here&#39;s an example:

Lets say you sample 5 values from each of two random variables, $X$ and $Y$:

 - Observed X&#39;s = $1,1,2,5,3$
 - Observed Y&#39;s = $0,1,1,0,1$

Now, you want to develop a joint distribution that describes these observations *as random variables* (i.e., different aspects of some common object). How will you do this? Most importantly, you need to first *associate* an observation from $X$ with an observation from $Y$. Implicit in this association is the assumption that there is some common sample space $\Omega_J$ that justifies us associating, say, the first observation of $X$ with the first observation of $Y$ to form the joint observation $(1,0)$ (in this example).

So, in my example, we are assuming there is some underlying event $\omega&#39;\in \Omega_J$ such that $X(\omega&#39;)=1$ and $Y(\omega&#39;)=0$ and that there is a valid underlying probability space $(\Omega_J,\mathcal{F}_J,P_J)$ whose *image* will produce the observed joint distribution of $(X,Y)$.

However, we could dispense with all of this if we chose to model $X,Y$ not as random variables but as **direct observations** (the integers are our experimental units or foundation data). 

At this point, you may still be unconvinced of the usefulness of the sample space view...

So, let&#39;s say you develop your distribution of $X,Y$ directly (no sample space[i.e., domain-less in your terminology]), then you want to add a new quantity $Z$. How do you do this. Without an underlying sample space you need to develop the joint distribution manually from first principles (i.e., ad hoc) whereas invoking the idea of an underlying sample space makes extending joint distributions a natural consequence of defining a new function over the same (usually implicit) underlying probability space. The fact that this can be assumed to be true is a major theoretical elegance of modern probability theory.

Again, it&#39;s a matter of perspective, but the random variables view, at least to me, has a philosophical/conceptual elegance to it when you consider joint observations and stochastic processes.

Here is a [nice post in math.overflow][5] that discusses something similar.


  [1]: http://dsp.ucsd.edu/~kreutz/PEI-05%20Support%20Files/Basic%20Random%20Variables%20Concepts.pdf
  [2]: https://en.wikipedia.org/wiki/Image_(mathematics)
  [3]: https://en.wikipedia.org/wiki/Pushforward_measure
  [4]: http://www.math.uiuc.edu/~rsong/461f10/lect6.pdf
  [5]: https://mathoverflow.net/questions/250500/why-do-we-need-random-variables, (Note: the details in this post are not completely correct; there is some awkwardness related to events of probability zero. What one needs is the [Loomis-Sikorski representation theorem][1], as indicated by the comment by @r.e.s. )

There is a generic construction, which basically defines

&gt; A sample is a consistent way of specifying which events hold and which events do not

Let $\mathcal{E}$ be the set of all possible *events* that can be constructed &amp;mdash; that is, boolean valued random variables. Or equivalently, all real random variables that take values in $\{ 0, 1 \}$.

For example, if $X$ is a real random variable, then for every real number $x$, then $X &gt; x$ is an event. (and the collection of all of these events uniquely determines $X$)

The boolean operations (e.g. $\wedge$, $\vee$, and $\neg$) give operations on $\mathcal{E}$. If you develop random sets in one reasonable way, then $\mathcal{E}$ will actually be an abstract $\sigma$-algebra. 

[Stone&#39;s representation theorem][2] says that, every abstract $\sigma$-algebra can be expressed as a $\sigma$-algebra of subsets of a set $\Omega$.

The theorem also gives a specific way to construct such an $\Omega$: as the set of ultrafilters on $\mathcal{E}$. The definition of ultrafilter is pretty much literally a precise way to state the definition given at the top of this post.

We can take $(\Omega, \mathcal{E})$ as the underlying measurable space. All events are measurable functions on this space, and two events are the same if and only if they correspond to the same measurable function, so this space really does give a faithful way to talk about the random variables.

---

In your example of flipping $n$ coins, if you take the events to be the ones you can construct out of the events &quot;the $n$-th coin is heads&quot;. Running through this construction really does lead to $\Omega \cong \{ H, T \}^n$.

---

Incidentally, there is an approach to measure theory that complete eliminates the need to have a sample space: that of [measurable locales][3]


  [1]: https://terrytao.wordpress.com/tag/stone-representation-theorem/
  [2]: https://en.wikipedia.org/wiki/Stone%27s_representation_theorem_for_Boolean_algebras
  [3]: https://ncatlab.org/nlab/show/measurable+locale]",,,,,,8,"[{u'edited': False, u'comment_id': 4593736, u'creation_date': 1492184878, u'post_id': 2233721, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 83396, u'user_type': u'registered', u'reputation': 64295, u'link': u'https://math.stackexchange.com/users/83396/ian', u'accept_rate': 71, u'display_name': u'Ian', u'badge_counts': {u'bronze': 79, u'silver': 44, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables#comment4593736_2233721'}, {u'edited': False, u'comment_id': 4594050, u'creation_date': 1492191428, u'post_id': 2233721, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 98199, u'user_type': u'registered', u'reputation': 33115, u'link': u'https://math.stackexchange.com/users/98199/mart%c3%adn-blas-p%c3%a9rez-pinilla', u'display_name': u'Mart&#237;n-Blas P&#233;rez Pinilla', u'badge_counts': {u'bronze': 69, u'silver': 25, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables#comment4594050_2233721'}, {u'edited': False, u'reply_to_user': {u'user_id': 83396, u'user_type': u'registered', u'reputation': 64295, u'link': u'https://math.stackexchange.com/users/83396/ian', u'accept_rate': 71, u'display_name': u'Ian', u'badge_counts': {u'bronze': 79, u'silver': 44, u'gold': 2}}, u'comment_id': 4594239, u'creation_date': 1492195550, u'post_id': 2233721, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables#comment4594239_2233721'}, {u'edited': False, u'comment_id': 4594279, u'creation_date': 1492196148, u'post_id': 2233721, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables#comment4594279_2233721'}, {u'edited': False, u'comment_id': 4594360, u'creation_date': 1492197898, u'post_id': 2233721, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 83396, u'user_type': u'registered', u'reputation': 64295, u'link': u'https://math.stackexchange.com/users/83396/ian', u'accept_rate': 71, u'display_name': u'Ian', u'badge_counts': {u'bronze': 79, u'silver': 44, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables#comment4594360_2233721'}, {u'edited': False, u'reply_to_user': {u'user_id': 83396, u'user_type': u'registered', u'reputation': 64295, u'link': u'https://math.stackexchange.com/users/83396/ian', u'accept_rate': 71, u'display_name': u'Ian', u'badge_counts': {u'bronze': 79, u'silver': 44, u'gold': 2}}, u'comment_id': 4597837, u'creation_date': 1492302722, u'post_id': 2233721, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables#comment4597837_2233721'}, {u'edited': False, u'comment_id': 4616453, u'creation_date': 1492776561, u'post_id': 2233721, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 42926, u'user_type': u'registered', u'reputation': 793, u'link': u'https://math.stackexchange.com/users/42926/kludg', u'display_name': u'kludg', u'badge_counts': {u'bronze': 11, u'silver': 4, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables#comment4616453_2233721'}, {u'edited': False, u'reply_to_user': {u'user_id': 42926, u'user_type': u'registered', u'reputation': 793, u'link': u'https://math.stackexchange.com/users/42926/kludg', u'display_name': u'kludg', u'badge_counts': {u'bronze': 11, u'silver': 4, u'gold': 0}}, u'comment_id': 4642774, u'creation_date': 1493467727, u'post_id': 2233721, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 8875, u'user_type': u'registered', u'reputation': 1671, u'link': u'https://math.stackexchange.com/users/8875/temo', u'accept_rate': 82, u'display_name': u'temo', u'badge_counts': {u'bronze': 41, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables#comment4642774_2233721'}]",1492167837,0,3,True,1519054489,1492770558.0,https://math.stackexchange.com/questions/2233721/the-true-domain-of-random-variables,82.0,41.0,0.0,14.0,temo,https://math.stackexchange.com/users/8875/temo,1671.0,8875.0,registered,,2233721,8,https://math.stackexchange.com/q/2233721,"[probability, probability-theory, random-variables, examples-counterexamples, mathematical-modeling]",The &quot;true&quot; domain of random variables,8,342
10,2165943.0,2,"[{u'up_vote_count': 4, u'title': u'Any counter example for&#160;$P(A|C)=P(A),P(B|C)=P(B)$ but&#160;$P(A\cap B|C)\neq P(A\cap B)$?', u'question_id': 2165927, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1488317653, u'creation_date': 1488315681, u'comment_count': 0, u'score': 4, u'link': u'https://math.stackexchange.com/questions/2165927/any-counter-example-for-pac-pa-pbc-pb-but-pa-cap-bc-neq-pa-cap/2165943#2165943', u'body_markdown': u'Consider a dice with 8 faces with numbers from $1$ to $8$ on them respectively. We roll that dice. Denote $X$ as the resulting face.

Let $A=[X=1,X=2]$, $B = [X=2,X = 3]$, $C=[X~\text{is even}]$.  Then we definitely have $$P(A|C)=P(X=2\vert C)=\frac14=P(A)$$ and $$P(B|C)=P(X=2\vert C)=\frac14=P(B).$$

But $$P(A\cap B|C) = P(X = 2\vert C) = \frac14\ne \frac18 = P(X = 2) = P(A\cap B) $$', u'owner': {u'user_id': 140670, u'user_type': u'registered', u'reputation': 2137, u'link': u'https://math.stackexchange.com/users/140670/andrei-kulunchakov', u'accept_rate': 92, u'display_name': u'Andrei Kulunchakov', u'badge_counts': {u'bronze': 19, u'silver': 5, u'gold': 0}}, u'is_accepted': True, u'last_edit_date': 1488317653, u'share_link': u'https://math.stackexchange.com/a/2165943', u'answer_id': 2165943}, {u'up_vote_count': 3, u'title': u'Any counter example for&#160;$P(A|C)=P(A),P(B|C)=P(B)$ but&#160;$P(A\cap B|C)\neq P(A\cap B)$?', u'question_id': 2165927, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1488315918, u'creation_date': 1488315918, u'comment_count': 0, u'score': 3, u'link': u'https://math.stackexchange.com/questions/2165927/any-counter-example-for-pac-pa-pbc-pb-but-pa-cap-bc-neq-pa-cap/2165948#2165948', u'body_markdown': u'Let $\Omega = \{1,2,3,4\}$ be the sample space, events $A = \{1,2\}$, $B = \{1,3\}$, $C = \{1,4\}$.

\begin{align}
P(A|C) &amp;= P(\text{choose 1 or 2 | 1 or 4 chosen}) = \frac12 \\
P(A) &amp;= P(\text{choose 1 or 2}) = \frac12 = P(A|C) \\
P(B|C) &amp;= P(B) = \frac12 \quad \text{similarly} \\
P(A\cap B | C) &amp;= P(\text{choose 1 | 1 or 4 chosen}) = \frac12, \text{ but} \\
P(A\cap B) &amp;= P(\text{choose 1}) = \frac14 \ne P(A\cap B | C).
\end{align}', u'owner': {u'user_id': 290189, u'user_type': u'registered', u'reputation': 11719, u'link': u'https://math.stackexchange.com/users/290189/gnu-supporter', u'accept_rate': 89, u'display_name': u'GNU Supporter', u'badge_counts': {u'bronze': 42, u'silver': 20, u'gold': 7}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2165948', u'answer_id': 2165948}]","Let $A,B,C$ be three events, what would be an example that $P(A|C)=P(A)$ and $P(B|C)=P(B)$ **do not** imply $P(A\cap B|C)= P(A\cap B)$?","[Consider a dice with 8 faces with numbers from $1$ to $8$ on them respectively. We roll that dice. Denote $X$ as the resulting face.

Let $A=[X=1,X=2]$, $B = [X=2,X = 3]$, $C=[X~\text{is even}]$.  Then we definitely have $$P(A|C)=P(X=2\vert C)=\frac14=P(A)$$ and $$P(B|C)=P(X=2\vert C)=\frac14=P(B).$$

But $$P(A\cap B|C) = P(X = 2\vert C) = \frac14\ne \frac18 = P(X = 2) = P(A\cap B) $$, Let $\Omega = \{1,2,3,4\}$ be the sample space, events $A = \{1,2\}$, $B = \{1,3\}$, $C = \{1,4\}$.

\begin{align}
P(A|C) &amp;= P(\text{choose 1 or 2 | 1 or 4 chosen}) = \frac12 \\
P(A) &amp;= P(\text{choose 1 or 2}) = \frac12 = P(A|C) \\
P(B|C) &amp;= P(B) = \frac12 \quad \text{similarly} \\
P(A\cap B | C) &amp;= P(\text{choose 1 | 1 or 4 chosen}) = \frac12, \text{ but} \\
P(A\cap B) &amp;= P(\text{choose 1}) = \frac14 \ne P(A\cap B | C).
\end{align}]",,,,,,0,,1488315045,0,0,True,1516392593,1516392593.0,https://math.stackexchange.com/questions/2165927/any-counter-example-for-pac-pa-pbc-pb-but-pa-cap-bc-neq-pa-cap,71.0,14.0,0.0,5.0,Ralph B.,https://math.stackexchange.com/users/181974/ralph-b,965.0,181974.0,registered,,2165927,5,https://math.stackexchange.com/q/2165927,"[probability, examples-counterexamples]","Any counter example for&#160;$P(A|C)=P(A),P(B|C)=P(B)$ but&#160;$P(A\cap B|C)\neq P(A\cap B)$?",5,64
11,2158758.0,1,"[{u'community_owned_date': 1487900393, u'up_vote_count': 2, u'title': u'calculate all possible combinations with respect to a conditions', u'question_id': 2158749, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1487900393, u'creation_date': 1487900393, u'comment_count': 0, u'score': 2, u'link': u'https://math.stackexchange.com/questions/2158749/calculate-all-possible-combinations-with-respect-to-a-conditions/2158758#2158758', u'body_markdown': u'How many ways can you select $2$ from $5$ men, $2$ from $5$ women, and $1$ from those $2$ specified women?

How many ways can you select $2$ from $5$ men, $3$ from $5$ women, and $0$ from those $2$ specified women?

Add the result.', u'owner': {u'user_id': 135106, u'user_type': u'registered', u'reputation': 77587, u'link': u'https://math.stackexchange.com/users/135106/graham-kemp', u'display_name': u'Graham Kemp', u'badge_counts': {u'bronze': 71, u'silver': 32, u'gold': 4}}, u'is_accepted': True, u'share_link': u'https://math.stackexchange.com/a/2158758', u'answer_id': 2158758}]","*******************************************************************************
we have a group of people 5 men and 7 womens
we take 2 men and 3 womens to form a group
how many possible groups we can have if 2 women can&#39;t be in the same group?

the 2 women can be any womens from the  7 womens ","[How many ways can you select $2$ from $5$ men, $2$ from $5$ women, and $1$ from those $2$ specified women?

How many ways can you select $2$ from $5$ men, $3$ from $5$ women, and $0$ from those $2$ specified women?

Add the result.]",,,,,,3,"[{u'edited': False, u'comment_id': 4440030, u'creation_date': 1487899935, u'post_id': 2158749, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 416020, u'user_type': u'registered', u'reputation': 5413, u'link': u'https://math.stackexchange.com/users/416020/mrnovice', u'accept_rate': 87, u'display_name': u'mrnovice', u'badge_counts': {u'bronze': 25, u'silver': 3, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2158749/calculate-all-possible-combinations-with-respect-to-a-conditions#comment4440030_2158749'}, {u'edited': False, u'reply_to_user': {u'user_id': 416020, u'user_type': u'registered', u'reputation': 5413, u'link': u'https://math.stackexchange.com/users/416020/mrnovice', u'accept_rate': 87, u'display_name': u'mrnovice', u'badge_counts': {u'bronze': 25, u'silver': 3, u'gold': 1}}, u'comment_id': 4440045, u'creation_date': 1487900247, u'post_id': 2158749, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 276762, u'user_type': u'registered', u'reputation': 50, u'link': u'https://math.stackexchange.com/users/276762/khalid-es-safi', u'accept_rate': 100, u'display_name': u'Khalid Es-safi', u'badge_counts': {u'bronze': 6, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2158749/calculate-all-possible-combinations-with-respect-to-a-conditions#comment4440045_2158749'}, {u'edited': False, u'comment_id': 4440057, u'creation_date': 1487900481, u'post_id': 2158749, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 135106, u'user_type': u'registered', u'reputation': 77587, u'link': u'https://math.stackexchange.com/users/135106/graham-kemp', u'display_name': u'Graham Kemp', u'badge_counts': {u'bronze': 71, u'silver': 32, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2158749/calculate-all-possible-combinations-with-respect-to-a-conditions#comment4440057_2158749'}]",1487899816,0,0,True,1487900393,,https://math.stackexchange.com/questions/2158749/calculate-all-possible-combinations-with-respect-to-a-conditions,100.0,6.0,0.0,0.0,Khalid Es-safi,https://math.stackexchange.com/users/276762/khalid-es-safi,50.0,276762.0,registered,,2158749,2,https://math.stackexchange.com/q/2158749,"[probability, combinatorics, examples-counterexamples]",calculate all possible combinations with respect to a conditions,2,25
12,2140502.0,30,"[{u'up_vote_count': 103, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 3, u'last_activity_date': 1487105061, u'comments': [{u'edited': False, u'comment_id': 4402554, u'creation_date': 1486886079, u'post_id': 2140502, u'score': 28, u'post_type': u'answer', u'owner': {u'user_id': 297916, u'user_type': u'registered', u'reputation': 2583, u'link': u'https://math.stackexchange.com/users/297916/justin-benfield', u'accept_rate': 33, u'display_name': u'Justin Benfield', u'badge_counts': {u'bronze': 20, u'silver': 5, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4402554_2140502'}, {u'edited': False, u'comment_id': 4402832, u'creation_date': 1486895931, u'post_id': 2140502, u'score': 21, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4402832_2140502'}, {u'edited': False, u'comment_id': 4402961, u'creation_date': 1486899815, u'post_id': 2140502, u'score': 5, u'post_type': u'answer', u'owner': {u'user_id': 236048, u'user_type': u'registered', u'reputation': 21325, u'link': u'https://math.stackexchange.com/users/236048/wythagoras', u'accept_rate': 100, u'display_name': u'wythagoras', u'badge_counts': {u'bronze': 101, u'silver': 41, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4402961_2140502'}, {u'edited': False, u'comment_id': 4403982, u'creation_date': 1486923065, u'post_id': 2140502, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 278700, u'user_type': u'registered', u'reputation': 465, u'link': u'https://math.stackexchange.com/users/278700/aalok', u'display_name': u'Aalok', u'badge_counts': {u'bronze': 10, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4403982_2140502'}, {u'edited': False, u'reply_to_user': {u'user_id': 278700, u'user_type': u'registered', u'reputation': 465, u'link': u'https://math.stackexchange.com/users/278700/aalok', u'display_name': u'Aalok', u'badge_counts': {u'bronze': 10, u'silver': 2, u'gold': 0}}, u'comment_id': 4404016, u'creation_date': 1486923692, u'post_id': 2140502, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 6616, u'user_type': u'registered', u'reputation': 348, u'link': u'https://math.stackexchange.com/users/6616/pa%c5%adlo-ebermann', u'display_name': u'Pa\u016dlo Ebermann', u'badge_counts': {u'bronze': 14, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4404016_2140502'}, {u'edited': False, u'comment_id': 4404074, u'creation_date': 1486924541, u'post_id': 2140502, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 278700, u'user_type': u'registered', u'reputation': 465, u'link': u'https://math.stackexchange.com/users/278700/aalok', u'display_name': u'Aalok', u'badge_counts': {u'bronze': 10, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4404074_2140502'}, {u'edited': False, u'comment_id': 4405650, u'creation_date': 1486962092, u'post_id': 2140502, u'score': 13, u'post_type': u'answer', u'owner': {u'user_id': 396325, u'user_type': u'registered', u'reputation': 211, u'link': u'https://math.stackexchange.com/users/396325/chai-t-rex', u'display_name': u'Chai T. Rex', u'badge_counts': {u'bronze': 8, u'silver': 1, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4405650_2140502'}, {u'edited': False, u'comment_id': 4405819, u'creation_date': 1486969384, u'post_id': 2140502, u'score': 6, u'post_type': u'answer', u'owner': {u'user_id': 67842, u'user_type': u'registered', u'reputation': 8473, u'link': u'https://math.stackexchange.com/users/67842/glen-o', u'display_name': u'Glen O', u'badge_counts': {u'bronze': 28, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4405819_2140502'}, {u'edited': False, u'reply_to_user': {u'user_id': 396325, u'user_type': u'registered', u'reputation': 211, u'link': u'https://math.stackexchange.com/users/396325/chai-t-rex', u'display_name': u'Chai T. Rex', u'badge_counts': {u'bronze': 8, u'silver': 1, u'gold': 0}}, u'comment_id': 4405894, u'creation_date': 1486972610, u'post_id': 2140502, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 218794, u'user_type': u'registered', u'reputation': 1483, u'link': u'https://math.stackexchange.com/users/218794/agnishom-chattopadhyay', u'accept_rate': 56, u'display_name': u'Agnishom Chattopadhyay', u'badge_counts': {u'bronze': 16, u'silver': 6, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4405894_2140502'}, {u'edited': False, u'comment_id': 4406320, u'creation_date': 1486986909, u'post_id': 2140502, u'score': 5, u'post_type': u'answer', u'owner': {u'user_id': 187461, u'user_type': u'registered', u'reputation': 1094, u'link': u'https://math.stackexchange.com/users/187461/kviiri', u'display_name': u'kviiri', u'badge_counts': {u'bronze': 11, u'silver': 5, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4406320_2140502'}, {u'edited': False, u'comment_id': 4406543, u'creation_date': 1486993263, u'post_id': 2140502, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 98449, u'user_type': u'registered', u'reputation': 4444, u'link': u'https://math.stackexchange.com/users/98449/jik', u'display_name': u'JiK', u'badge_counts': {u'bronze': 30, u'silver': 11, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4406543_2140502'}, {u'edited': False, u'comment_id': 4406884, u'creation_date': 1486999735, u'post_id': 2140502, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 139123, u'user_type': u'registered', u'reputation': 46593, u'link': u'https://math.stackexchange.com/users/139123/david-k', u'display_name': u'David K', u'badge_counts': {u'bronze': 104, u'silver': 39, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4406884_2140502'}, {u'edited': False, u'comment_id': 4407895, u'creation_date': 1487018305, u'post_id': 2140502, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 396325, u'user_type': u'registered', u'reputation': 211, u'link': u'https://math.stackexchange.com/users/396325/chai-t-rex', u'display_name': u'Chai T. Rex', u'badge_counts': {u'bronze': 8, u'silver': 1, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4407895_2140502'}, {u'edited': False, u'comment_id': 4408397, u'creation_date': 1487028096, u'post_id': 2140502, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 65332, u'user_type': u'registered', u'reputation': 2080, u'link': u'https://math.stackexchange.com/users/65332/the-vee', u'accept_rate': 100, u'display_name': u'The Vee', u'badge_counts': {u'bronze': 22, u'silver': 7, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4408397_2140502'}, {u'edited': False, u'reply_to_user': {u'user_id': 65332, u'user_type': u'registered', u'reputation': 2080, u'link': u'https://math.stackexchange.com/users/65332/the-vee', u'accept_rate': 100, u'display_name': u'The Vee', u'badge_counts': {u'bronze': 22, u'silver': 7, u'gold': 0}}, u'comment_id': 4409840, u'creation_date': 1487075289, u'post_id': 2140502, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 20413, u'user_type': u'registered', u'reputation': 7218, u'link': u'https://math.stackexchange.com/users/20413/d-thomine', u'accept_rate': 89, u'display_name': u'D. Thomine', u'badge_counts': {u'bronze': 35, u'silver': 13, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4409840_2140502'}, {u'edited': False, u'reply_to_user': {u'user_id': 187461, u'user_type': u'registered', u'reputation': 1094, u'link': u'https://math.stackexchange.com/users/187461/kviiri', u'display_name': u'kviiri', u'badge_counts': {u'bronze': 11, u'silver': 5, u'gold': 0}}, u'comment_id': 4413042, u'creation_date': 1487156908, u'post_id': 2140502, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 52394, u'user_type': u'registered', u'reputation': 163, u'link': u'https://math.stackexchange.com/users/52394/john-r-ramsden', u'display_name': u'John R Ramsden', u'badge_counts': {u'bronze': 6, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4413042_2140502'}, {u'edited': False, u'reply_to_user': {u'user_id': 52394, u'user_type': u'registered', u'reputation': 163, u'link': u'https://math.stackexchange.com/users/52394/john-r-ramsden', u'display_name': u'John R Ramsden', u'badge_counts': {u'bronze': 6, u'silver': 0, u'gold': 0}}, u'comment_id': 4413056, u'creation_date': 1487157483, u'post_id': 2140502, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 187461, u'user_type': u'registered', u'reputation': 1094, u'link': u'https://math.stackexchange.com/users/187461/kviiri', u'display_name': u'kviiri', u'badge_counts': {u'bronze': 11, u'silver': 5, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4413056_2140502'}, {u'edited': False, u'reply_to_user': {u'user_id': 187461, u'user_type': u'registered', u'reputation': 1094, u'link': u'https://math.stackexchange.com/users/187461/kviiri', u'display_name': u'kviiri', u'badge_counts': {u'bronze': 11, u'silver': 5, u'gold': 0}}, u'comment_id': 4416466, u'creation_date': 1487246185, u'post_id': 2140502, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 52394, u'user_type': u'registered', u'reputation': 163, u'link': u'https://math.stackexchange.com/users/52394/john-r-ramsden', u'display_name': u'John R Ramsden', u'badge_counts': {u'bronze': 6, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4416466_2140502'}, {u'edited': False, u'reply_to_user': {u'user_id': 52394, u'user_type': u'registered', u'reputation': 163, u'link': u'https://math.stackexchange.com/users/52394/john-r-ramsden', u'display_name': u'John R Ramsden', u'badge_counts': {u'bronze': 6, u'silver': 0, u'gold': 0}}, u'comment_id': 4416473, u'creation_date': 1487246604, u'post_id': 2140502, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 187461, u'user_type': u'registered', u'reputation': 1094, u'link': u'https://math.stackexchange.com/users/187461/kviiri', u'display_name': u'kviiri', u'badge_counts': {u'bronze': 11, u'silver': 5, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4416473_2140502'}, {u'edited': False, u'comment_id': 4416777, u'creation_date': 1487256147, u'post_id': 2140502, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 263389, u'user_type': u'registered', u'reputation': 1172, u'link': u'https://math.stackexchange.com/users/263389/brick', u'display_name': u'Brick', u'badge_counts': {u'bronze': 19, u'silver': 6, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4416777_2140502'}, {u'edited': False, u'comment_id': 4421790, u'creation_date': 1487406988, u'post_id': 2140502, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 29966, u'user_type': u'registered', u'reputation': 11036, u'link': u'https://math.stackexchange.com/users/29966/ben-millwood', u'accept_rate': 83, u'display_name': u'Ben Millwood', u'badge_counts': {u'bronze': 48, u'silver': 19, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment4421790_2140502'}, {u'edited': False, u'reply_to_user': {u'user_id': 297916, u'user_type': u'registered', u'reputation': 2583, u'link': u'https://math.stackexchange.com/users/297916/justin-benfield', u'accept_rate': 33, u'display_name': u'Justin Benfield', u'badge_counts': {u'bronze': 20, u'silver': 5, u'gold': 2}}, u'comment_id': 5018053, u'creation_date': 1505405890, u'post_id': 2140502, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 19473, u'user_type': u'registered', u'reputation': 150, u'link': u'https://math.stackexchange.com/users/19473/patrickt', u'display_name': u'PatrickT', u'badge_counts': {u'bronze': 11, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment5018053_2140502'}, {u'edited': False, u'reply_to_user': {u'user_id': 19473, u'user_type': u'registered', u'reputation': 150, u'link': u'https://math.stackexchange.com/users/19473/patrickt', u'display_name': u'PatrickT', u'badge_counts': {u'bronze': 11, u'silver': 2, u'gold': 0}}, u'comment_id': 5037517, u'creation_date': 1505978055, u'post_id': 2140502, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 297916, u'user_type': u'registered', u'reputation': 2583, u'link': u'https://math.stackexchange.com/users/297916/justin-benfield', u'accept_rate': 33, u'display_name': u'Justin Benfield', u'badge_counts': {u'bronze': 20, u'silver': 5, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment5037517_2140502'}, {u'edited': False, u'reply_to_user': {u'user_id': 297916, u'user_type': u'registered', u'reputation': 2583, u'link': u'https://math.stackexchange.com/users/297916/justin-benfield', u'accept_rate': 33, u'display_name': u'Justin Benfield', u'badge_counts': {u'bronze': 20, u'silver': 5, u'gold': 2}}, u'comment_id': 5039083, u'creation_date': 1506019665, u'post_id': 2140502, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 19473, u'user_type': u'registered', u'reputation': 150, u'link': u'https://math.stackexchange.com/users/19473/patrickt', u'display_name': u'PatrickT', u'badge_counts': {u'bronze': 11, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#comment5039083_2140502'}], u'creation_date': 1486885807, u'comment_count': 24, u'score': 100, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140502#2140502', u'body_markdown': u'The most famous counter-intuitive probability theory example is the [Monty Hall Problem](https://brilliant.org/wiki/monty-hall-problem/)

* In a game show, there are three doors behind which there are a car and two goats. However, which door conceals which is unknown to you, the player.
* Your aim is to select the door behind which the car is. So, you go and stand in front of a door of your choice.
* At this point, regardless of which door you selected, the game show host chooses and opens one of the remaining two doors. If you chose the door with the car, the host selects one of the two remaining doors at random (with equal probability) and opens that door. If you chose a door with a goat, the host selects and opens the other door with a goat.
* You are given the option of standing where you are and switching to the other closed door.

Does switching to the other door increase your chances of winning? Or does it not matter?

The answer is that it _does_ matter whether or not you switch. This is initially counter-intuitive for someone seeing this problem for the first time.

---

* If a family has two children, at least one of which is a daughter, what is the probability that both of them are daughters?
* If a family has two children, the elder of which is a daughter, what is the probability that both of them are the daughters?

A beginner in probability would expect the answers to both these questions to be the same, which they are not.

[Math with Bad Drawings](https://mathwithbaddrawings.com/2013/10/14/the-riddle-of-the-odorless-incense/) explains this paradox with a great story as a part of a seven-post series in Probability Theory

---

[Nontransitive Dice](https://en.wikipedia.org/wiki/Nontransitive_dice)

Let persons P, Q, R have three distinct dice.

If it is the case that P is more likely to win over Q, and Q is more likely to win over R, is it the case that P is likely to win over R?

The answer, strangely, is no. One such dice configuration is $(\left \{2,2,4,4,9,9 \right\},\left \{ 1,1,6,6,8,8\right \},\left \{ 3,3,5,5,7,7 \right \})$

---

[Sleeping Beauty Paradox](https://brilliant.org/discussions/thread/rationality-revisited-the-sleeping-beauty-paradox/)

(This is related to philosophy/epistemology and is more related to subjective probability/beliefs than objective interpretations of it.)


Today is Sunday. Sleeping Beauty drinks a powerful sleeping potion and falls asleep.

Her attendant tosses a [fair coin](https://en.wikipedia.org/wiki/Fair_coin) and records the result.

* The coin lands in **Heads**. Beauty is awakened only on **Monday** and interviewed. Her memory is erased and she is again put back to sleep.
* The coin lands in **Tails**. Beauty is awakened and interviewed on **Monday**. Her memory is erased and she&#39;s put back to sleep again. On **Tuesday**, she is once again awaken, interviewed and finally put back to sleep. 

In essence, the awakenings on Mondays and Tuesdays are indistinguishable to her.

The most important question she&#39;s asked in the interviews is

&gt; What is your credence (degree of belief) that the coin landed in heads?

Given that Sleeping Beauty is epistemologically rational and is aware of all the rules of the experiment on Sunday, what should be her answer?

This problem seems simple on the surface but there are both arguments for the answer $\frac{1}{2}$ and $\frac{1}{3}$ and there is no common consensus among modern epistemologists on this one.

---

[Ellsberg Paradox](https://brilliant.org/discussions/thread/rationality-revisited-the-ellsberg-paradox/)

Consider the following situation:

&gt; In an urn, you have 90 balls of 3 colors: red, blue and yellow.
&gt; 30 balls are known to be red. All the other balls are either blue or yellow.
&gt;
&gt; There are two lotteries:
&gt;
&gt; * **Lottery A:** A random ball is chosen. You win a prize if the ball is red.
&gt; * **Lottery B:** A random ball is chosen. You win a prize if the ball is blue.

Question: In which lottery would you want to participate?

&gt; * **Lottery X:** A random ball is chosen. You win a prize if the ball is either red or yellow.
&gt; * **Lottery Y:** A random ball is chosen. You win a prize if the ball is either blue or yellow.

Question: In which lottery would you want to participate?

If you are an average person, you&#39;d choose Lottery A over Lottery B and Lottery Y over Lottery X. 

However, it can be shown that there is no way to assign probabilities in a way that make this look rational. One way to deal with this is to extend the concept of probability to that of imprecise probabilities.', u'owner': {u'user_id': 218794, u'user_type': u'registered', u'reputation': 1483, u'link': u'https://math.stackexchange.com/users/218794/agnishom-chattopadhyay', u'accept_rate': 56, u'display_name': u'Agnishom Chattopadhyay', u'badge_counts': {u'bronze': 16, u'silver': 6, u'gold': 1}}, u'is_accepted': True, u'last_edit_date': 1487105061, u'share_link': u'https://math.stackexchange.com/a/2140502', u'answer_id': 2140502}, {u'up_vote_count': 17, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 2, u'last_activity_date': 1489584708, u'comments': [{u'edited': False, u'comment_id': 4403299, u'creation_date': 1486909692, u'post_id': 2140513, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140513#comment4403299_2140513'}, {u'edited': False, u'reply_to_user': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'comment_id': 4403341, u'creation_date': 1486910629, u'post_id': 2140513, u'score': 0, u'post_type': u'answer', u'owner': {u'display_name': u'user415542', u'user_type': u'does_not_exist'}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140513#comment4403341_2140513'}, {u'edited': False, u'comment_id': 4404846, u'creation_date': 1486938730, u'post_id': 2140513, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 312097, u'user_type': u'registered', u'reputation': 2275, u'link': u'https://math.stackexchange.com/users/312097/a-b', u'accept_rate': 99, u'display_name': u'A---B', u'badge_counts': {u'bronze': 35, u'silver': 11, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140513#comment4404846_2140513'}, {u'edited': False, u'reply_to_user': {u'user_id': 312097, u'user_type': u'registered', u'reputation': 2275, u'link': u'https://math.stackexchange.com/users/312097/a-b', u'accept_rate': 99, u'display_name': u'A---B', u'badge_counts': {u'bronze': 35, u'silver': 11, u'gold': 1}}, u'comment_id': 4405499, u'creation_date': 1486957033, u'post_id': 2140513, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140513#comment4405499_2140513'}, {u'edited': False, u'comment_id': 4408943, u'creation_date': 1487043142, u'post_id': 2140513, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 276406, u'user_type': u'registered', u'reputation': 2507, u'link': u'https://math.stackexchange.com/users/276406/wildcard', u'display_name': u'Wildcard', u'badge_counts': {u'bronze': 27, u'silver': 7, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140513#comment4408943_2140513'}, {u'edited': False, u'reply_to_user': {u'user_id': 276406, u'user_type': u'registered', u'reputation': 2507, u'link': u'https://math.stackexchange.com/users/276406/wildcard', u'display_name': u'Wildcard', u'badge_counts': {u'bronze': 27, u'silver': 7, u'gold': 0}}, u'comment_id': 4414441, u'creation_date': 1487186166, u'post_id': 2140513, u'score': 1, u'post_type': u'answer', u'owner': {u'display_name': u'user415542', u'user_type': u'does_not_exist'}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140513#comment4414441_2140513'}, {u'edited': False, u'comment_id': 5797807, u'creation_date': 1528403811, u'post_id': 2140513, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 568216, u'user_type': u'registered', u'reputation': 101, u'link': u'https://math.stackexchange.com/users/568216/tonio', u'display_name': u'Tonio', u'badge_counts': {u'bronze': 0, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140513#comment5797807_2140513'}], u'creation_date': 1486887060, u'comment_count': 7, u'score': 15, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140513#2140513', u'body_markdown': u'A famous example is this one that is called St. Petersburg paradox:


Consider a game in which you earn $2^n\: \$ $  if you get $n$ consecutive **Heads** in a fair coin tosses. The fair entrance fee of this game is $\infty$', u'owner': {u'display_name': u'user415542', u'user_type': u'does_not_exist'}, u'is_accepted': False, u'last_edit_date': 1489584708, u'share_link': u'https://math.stackexchange.com/a/2140513', u'answer_id': 2140513}, {u'up_vote_count': 24, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 1, u'last_activity_date': 1486892415, u'comments': [{u'edited': False, u'comment_id': 4402758, u'creation_date': 1486892557, u'post_id': 2140580, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4402758_2140580'}, {u'edited': False, u'reply_to_user': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'comment_id': 4402779, u'creation_date': 1486893500, u'post_id': 2140580, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 85606, u'user_type': u'registered', u'reputation': 1069, u'link': u'https://math.stackexchange.com/users/85606/ymbirtt', u'display_name': u'ymbirtt', u'badge_counts': {u'bronze': 14, u'silver': 4, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4402779_2140580'}, {u'edited': False, u'comment_id': 4402781, u'creation_date': 1486893672, u'post_id': 2140580, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4402781_2140580'}, {u'edited': False, u'reply_to_user': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'comment_id': 4405464, u'creation_date': 1486956280, u'post_id': 2140580, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4405464_2140580'}, {u'edited': False, u'reply_to_user': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'comment_id': 4405502, u'creation_date': 1486957102, u'post_id': 2140580, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4405502_2140580'}, {u'edited': False, u'comment_id': 4405642, u'creation_date': 1486961815, u'post_id': 2140580, u'score': 6, u'post_type': u'answer', u'owner': {u'user_id': 1827, u'user_type': u'registered', u'reputation': 270056, u'link': u'https://math.stackexchange.com/users/1827/ross-millikan', u'accept_rate': 80, u'display_name': u'Ross Millikan', u'badge_counts': {u'bronze': 341, u'silver': 180, u'gold': 21}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4405642_2140580'}, {u'edited': False, u'reply_to_user': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'comment_id': 4405957, u'creation_date': 1486974445, u'post_id': 2140580, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 85606, u'user_type': u'registered', u'reputation': 1069, u'link': u'https://math.stackexchange.com/users/85606/ymbirtt', u'display_name': u'ymbirtt', u'badge_counts': {u'bronze': 14, u'silver': 4, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4405957_2140580'}, {u'edited': False, u'reply_to_user': {u'user_id': 1827, u'user_type': u'registered', u'reputation': 270056, u'link': u'https://math.stackexchange.com/users/1827/ross-millikan', u'accept_rate': 80, u'display_name': u'Ross Millikan', u'badge_counts': {u'bronze': 341, u'silver': 180, u'gold': 21}}, u'comment_id': 4405966, u'creation_date': 1486974784, u'post_id': 2140580, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 85606, u'user_type': u'registered', u'reputation': 1069, u'link': u'https://math.stackexchange.com/users/85606/ymbirtt', u'display_name': u'ymbirtt', u'badge_counts': {u'bronze': 14, u'silver': 4, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4405966_2140580'}, {u'edited': False, u'reply_to_user': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'comment_id': 4406363, u'creation_date': 1486988106, u'post_id': 2140580, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4406363_2140580'}, {u'edited': False, u'reply_to_user': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'comment_id': 4406374, u'creation_date': 1486988477, u'post_id': 2140580, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4406374_2140580'}, {u'edited': False, u'reply_to_user': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'comment_id': 4406438, u'creation_date': 1486989991, u'post_id': 2140580, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4406438_2140580'}, {u'edited': False, u'comment_id': 4407018, u'creation_date': 1487001740, u'post_id': 2140580, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 139123, u'user_type': u'registered', u'reputation': 46593, u'link': u'https://math.stackexchange.com/users/139123/david-k', u'display_name': u'David K', u'badge_counts': {u'bronze': 104, u'silver': 39, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4407018_2140580'}, {u'edited': False, u'comment_id': 4408559, u'creation_date': 1487032306, u'post_id': 2140580, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 224454, u'user_type': u'registered', u'reputation': 24381, u'link': u'https://math.stackexchange.com/users/224454/brian-tung', u'display_name': u'Brian Tung', u'badge_counts': {u'bronze': 51, u'silver': 23, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4408559_2140580'}, {u'edited': False, u'reply_to_user': {u'user_id': 139123, u'user_type': u'registered', u'reputation': 46593, u'link': u'https://math.stackexchange.com/users/139123/david-k', u'display_name': u'David K', u'badge_counts': {u'bronze': 104, u'silver': 39, u'gold': 3}}, u'comment_id': 4409778, u'creation_date': 1487074012, u'post_id': 2140580, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4409778_2140580'}, {u'edited': False, u'reply_to_user': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'comment_id': 4410053, u'creation_date': 1487080565, u'post_id': 2140580, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 139123, u'user_type': u'registered', u'reputation': 46593, u'link': u'https://math.stackexchange.com/users/139123/david-k', u'display_name': u'David K', u'badge_counts': {u'bronze': 104, u'silver': 39, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4410053_2140580'}, {u'edited': False, u'reply_to_user': {u'user_id': 139123, u'user_type': u'registered', u'reputation': 46593, u'link': u'https://math.stackexchange.com/users/139123/david-k', u'display_name': u'David K', u'badge_counts': {u'bronze': 104, u'silver': 39, u'gold': 3}}, u'comment_id': 4410091, u'creation_date': 1487081261, u'post_id': 2140580, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#comment4410091_2140580'}], u'creation_date': 1486892415, u'comment_count': 16, u'score': 23, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140580#2140580', u'body_markdown': u'A while back, the xkcd blog posted [this problem][1], which I found fascinating. Usually when I re-tell it, I do so slightly differently from the original author:

&gt; I have selected two numbers from $\mathbb{R}$, following some unknown
&gt; and not necessarily independent distribution. I have written each
&gt; number in a separate envelope. By fair coin toss, I select one of
&gt; these two envelopes to open, revealing that number. I then ask the
&gt; question &quot;Is the number in the other envelope larger than this one?&quot;.
&gt; You win if you guess correctly.
&gt; 
&gt; Can you win this game with probability $&gt;\frac{1}{2}$? Note, that is a
&gt; strict inequality. Winning with probability $=\frac{1}{2}$ is
&gt; obviously easy.

Now, the solution to this starts out with a double-integral, so depending on the level of the class you&#39;re teaching it may not be appropriate.


  [1]: https://blog.xkcd.com/2010/02/09/math-puzzle/', u'owner': {u'user_id': 85606, u'user_type': u'registered', u'reputation': 1069, u'link': u'https://math.stackexchange.com/users/85606/ymbirtt', u'display_name': u'ymbirtt', u'badge_counts': {u'bronze': 14, u'silver': 4, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2140580', u'answer_id': 2140580}, {u'up_vote_count': 17, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1487136531, u'comments': [{u'edited': False, u'reply_to_user': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'comment_id': 4405895, u'creation_date': 1486972645, u'post_id': 2140588, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 132007, u'user_type': u'registered', u'reputation': 54037, u'link': u'https://math.stackexchange.com/users/132007/markus-scheuer', u'accept_rate': 79, u'display_name': u'Markus Scheuer', u'badge_counts': {u'bronze': 131, u'silver': 49, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140588#comment4405895_2140588'}, {u'edited': False, u'comment_id': 4407793, u'creation_date': 1487016571, u'post_id': 2140588, u'score': 3, u'post_type': u'answer', u'owner': {u'user_id': 206300, u'user_type': u'registered', u'reputation': 143, u'link': u'https://math.stackexchange.com/users/206300/mbomb007', u'display_name': u'mbomb007', u'badge_counts': {u'bronze': 8, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140588#comment4407793_2140588'}, {u'edited': False, u'comment_id': 4408432, u'creation_date': 1487028863, u'post_id': 2140588, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 105319, u'user_type': u'registered', u'reputation': 108, u'link': u'https://math.stackexchange.com/users/105319/ojdo', u'display_name': u'ojdo', u'badge_counts': {u'bronze': 5, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140588#comment4408432_2140588'}, {u'edited': False, u'reply_to_user': {u'user_id': 105319, u'user_type': u'registered', u'reputation': 108, u'link': u'https://math.stackexchange.com/users/105319/ojdo', u'display_name': u'ojdo', u'badge_counts': {u'bronze': 5, u'silver': 0, u'gold': 0}}, u'comment_id': 4409362, u'creation_date': 1487058865, u'post_id': 2140588, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 132007, u'user_type': u'registered', u'reputation': 54037, u'link': u'https://math.stackexchange.com/users/132007/markus-scheuer', u'accept_rate': 79, u'display_name': u'Markus Scheuer', u'badge_counts': {u'bronze': 131, u'silver': 49, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140588#comment4409362_2140588'}, {u'edited': False, u'comment_id': 4410033, u'creation_date': 1487080301, u'post_id': 2140588, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 50346, u'user_type': u'registered', u'reputation': 206, u'link': u'https://math.stackexchange.com/users/50346/ben-aaronson', u'display_name': u'Ben Aaronson', u'badge_counts': {u'bronze': 9, u'silver': 1, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140588#comment4410033_2140588'}, {u'edited': False, u'reply_to_user': {u'user_id': 50346, u'user_type': u'registered', u'reputation': 206, u'link': u'https://math.stackexchange.com/users/50346/ben-aaronson', u'display_name': u'Ben Aaronson', u'badge_counts': {u'bronze': 9, u'silver': 1, u'gold': 0}}, u'comment_id': 4410478, u'creation_date': 1487088466, u'post_id': 2140588, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 132007, u'user_type': u'registered', u'reputation': 54037, u'link': u'https://math.stackexchange.com/users/132007/markus-scheuer', u'accept_rate': 79, u'display_name': u'Markus Scheuer', u'badge_counts': {u'bronze': 131, u'silver': 49, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140588#comment4410478_2140588'}, {u'edited': False, u'reply_to_user': {u'user_id': 50346, u'user_type': u'registered', u'reputation': 206, u'link': u'https://math.stackexchange.com/users/50346/ben-aaronson', u'display_name': u'Ben Aaronson', u'badge_counts': {u'bronze': 9, u'silver': 1, u'gold': 0}}, u'comment_id': 4412373, u'creation_date': 1487133330, u'post_id': 2140588, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140588#comment4412373_2140588'}, {u'edited': False, u'comment_id': 4413410, u'creation_date': 1487168426, u'post_id': 2140588, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 50346, u'user_type': u'registered', u'reputation': 206, u'link': u'https://math.stackexchange.com/users/50346/ben-aaronson', u'display_name': u'Ben Aaronson', u'badge_counts': {u'bronze': 9, u'silver': 1, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140588#comment4413410_2140588'}], u'creation_date': 1486892758, u'comment_count': 8, u'score': 17, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140588#2140588', u'body_markdown': u'Strongly related   with    OPs example  is this consequence of the *[Arc sine law for last visits](https://www.dartmouth.edu/~chance/teaching\_aids/books\_articles/probability\_book/Chapter12.pdf)*. Let&#39;s assume playing with a fair coin.

&gt;**Theorem (false)**
&gt;*In a long coin-tossing game each player will be on the winning side for about half the time, and the lead will pass not infrequently from one player to the other.*

The following text is from the classic *[An Introduction to Probability Theory and Its Applications, volume 1](https://www.amazon.com/Introduction-Probability-Theory-Applications-Vol/dp/8126518057)*, by William Feller.

&gt;- According to widespread beliefs a so-called law of averages should ensure the *Theorem* above. But, in fact this theorem is wrong and contrary to the *usual* belief the following holds:

&gt;   With probability $\frac{1}{2}$ *no equalization occurred in the second half of the game regardless of the length of the game.* Furthermore, the probabilities near the end point are *greatest*.
', u'owner': {u'user_id': 132007, u'user_type': u'registered', u'reputation': 54037, u'link': u'https://math.stackexchange.com/users/132007/markus-scheuer', u'accept_rate': 79, u'display_name': u'Markus Scheuer', u'badge_counts': {u'bronze': 131, u'silver': 49, u'gold': 4}}, u'is_accepted': False, u'last_edit_date': 1487136531, u'share_link': u'https://math.stackexchange.com/a/2140588', u'answer_id': 2140588}, {u'up_vote_count': 37, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1487302605, u'comments': [{u'edited': False, u'comment_id': 4405583, u'creation_date': 1486959454, u'post_id': 2140606, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140606#comment4405583_2140606'}, {u'edited': False, u'comment_id': 4405590, u'creation_date': 1486959766, u'post_id': 2140606, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140606#comment4405590_2140606'}, {u'edited': False, u'comment_id': 4406676, u'creation_date': 1486995891, u'post_id': 2140606, u'score': 5, u'post_type': u'answer', u'owner': {u'user_id': 67842, u'user_type': u'registered', u'reputation': 8473, u'link': u'https://math.stackexchange.com/users/67842/glen-o', u'display_name': u'Glen O', u'badge_counts': {u'bronze': 28, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140606#comment4406676_2140606'}, {u'edited': False, u'comment_id': 4413846, u'creation_date': 1487176508, u'post_id': 2140606, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 83396, u'user_type': u'registered', u'reputation': 64295, u'link': u'https://math.stackexchange.com/users/83396/ian', u'accept_rate': 71, u'display_name': u'Ian', u'badge_counts': {u'bronze': 79, u'silver': 44, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140606#comment4413846_2140606'}, {u'edited': False, u'comment_id': 4413849, u'creation_date': 1487176511, u'post_id': 2140606, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 83396, u'user_type': u'registered', u'reputation': 64295, u'link': u'https://math.stackexchange.com/users/83396/ian', u'accept_rate': 71, u'display_name': u'Ian', u'badge_counts': {u'bronze': 79, u'silver': 44, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140606#comment4413849_2140606'}, {u'edited': False, u'comment_id': 4418752, u'creation_date': 1487302975, u'post_id': 2140606, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 415563, u'user_type': u'registered', u'reputation': 471, u'link': u'https://math.stackexchange.com/users/415563/nikhil-pandey', u'display_name': u'Nikhil Pandey', u'badge_counts': {u'bronze': 3, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140606#comment4418752_2140606'}, {u'edited': False, u'comment_id': 4426864, u'creation_date': 1487550719, u'post_id': 2140606, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 415563, u'user_type': u'registered', u'reputation': 471, u'link': u'https://math.stackexchange.com/users/415563/nikhil-pandey', u'display_name': u'Nikhil Pandey', u'badge_counts': {u'bronze': 3, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140606#comment4426864_2140606'}], u'creation_date': 1486894056, u'comment_count': 7, u'score': 37, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140606#2140606', u'body_markdown': u'Birthday Problem
==============
For me this was the first example of how counter intuitive the real world probability problems are due to the inherent underestimation/overestimation involved in mental maps for permutation and combination (which is an inverse multiplication problem in general), which form the basis for probability calculation. 
The question is:

&gt; How many people should be in a room so that the probability of at least
&gt; two people sharing the same birthday, is at least as high as the probability of
&gt; getting heads in a toss of an unbiased coin (i.e., $0.5$).

This is a good problem for students to hone their skills in estimating the permutations and combinations, the base for computation of _a priori probability_.


I still feel the number of persons for the answer to be surreal and hard to believe! (The real answer is $23$).

Pupils should at this juncture be told about quick and dirty mental maps for permutations and combinations calculations and should be encouraged  to inculcate a habit of mental computations, which will help them in forming intuition about probability. It will also serve them well in taking to the other higher level problems such as the Monty Hall problem or conditional probability problems mentioned above, such as:

&gt; $0.5\%$ of the total population out of a population of $10$ million is
&gt; supposed to be affected by a strange disease. A test has been
&gt; developed for that disease and it has a truth ratio of $99\%$ (i.e., its
&gt; true $99\%$ of the times). A random person from the population is
&gt; selected and is found to be tested positive for that disease. What is the real probability
&gt; of that person suffering from the strange disease.
&gt; The real answer here is approximately $33\%$.

Here strange disease can be replaced by any real world problems (such as HIV patients or a successful trading / betting strategy or number of terrorists in a country) and this example can be used to give students a feel, why in such cases (HIV patients or so) there are bound to be many false positives (as no real world tests, I believe for such cases are $99\%$ true) and how popular opinions are wrong in such cases most of the times.

This should be the starting point for introducing some of the work of **Daniel Kahneman** and **Amos Tversky** as no probability course in modern times can be complete without giving pupils a sense of how fragile one&#39;s intuitions and estimates are in estimating probabilities and uncertainties and how to deal with them.  $20\%$ of the course should be devoted to this aspect and it can be one of the final real world projects of students.', u'owner': {u'user_id': 415563, u'user_type': u'registered', u'reputation': 471, u'link': u'https://math.stackexchange.com/users/415563/nikhil-pandey', u'display_name': u'Nikhil Pandey', u'badge_counts': {u'bronze': 3, u'silver': 2, u'gold': 0}}, u'is_accepted': False, u'last_edit_date': 1487302605, u'share_link': u'https://math.stackexchange.com/a/2140606', u'answer_id': 2140606}, {u'up_vote_count': 10, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1486974288, u'comments': [{u'edited': False, u'comment_id': 4409014, u'creation_date': 1487045119, u'post_id': 2140612, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 276406, u'user_type': u'registered', u'reputation': 2507, u'link': u'https://math.stackexchange.com/users/276406/wildcard', u'display_name': u'Wildcard', u'badge_counts': {u'bronze': 27, u'silver': 7, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140612#comment4409014_2140612'}, {u'edited': False, u'comment_id': 4409017, u'creation_date': 1487045349, u'post_id': 2140612, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 276406, u'user_type': u'registered', u'reputation': 2507, u'link': u'https://math.stackexchange.com/users/276406/wildcard', u'display_name': u'Wildcard', u'badge_counts': {u'bronze': 27, u'silver': 7, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140612#comment4409017_2140612'}, {u'edited': False, u'reply_to_user': {u'user_id': 276406, u'user_type': u'registered', u'reputation': 2507, u'link': u'https://math.stackexchange.com/users/276406/wildcard', u'display_name': u'Wildcard', u'badge_counts': {u'bronze': 27, u'silver': 7, u'gold': 0}}, u'comment_id': 4409525, u'creation_date': 1487066159, u'post_id': 2140612, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 62009, u'user_type': u'registered', u'reputation': 7053, u'link': u'https://math.stackexchange.com/users/62009/peter-franek', u'accept_rate': 61, u'display_name': u'Peter Franek', u'badge_counts': {u'bronze': 34, u'silver': 19, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140612#comment4409525_2140612'}, {u'edited': False, u'comment_id': 4410048, u'creation_date': 1487080526, u'post_id': 2140612, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 50346, u'user_type': u'registered', u'reputation': 206, u'link': u'https://math.stackexchange.com/users/50346/ben-aaronson', u'display_name': u'Ben Aaronson', u'badge_counts': {u'bronze': 9, u'silver': 1, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140612#comment4410048_2140612'}, {u'edited': False, u'reply_to_user': {u'user_id': 50346, u'user_type': u'registered', u'reputation': 206, u'link': u'https://math.stackexchange.com/users/50346/ben-aaronson', u'display_name': u'Ben Aaronson', u'badge_counts': {u'bronze': 9, u'silver': 1, u'gold': 0}}, u'comment_id': 4410060, u'creation_date': 1487080684, u'post_id': 2140612, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 62009, u'user_type': u'registered', u'reputation': 7053, u'link': u'https://math.stackexchange.com/users/62009/peter-franek', u'accept_rate': 61, u'display_name': u'Peter Franek', u'badge_counts': {u'bronze': 34, u'silver': 19, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140612#comment4410060_2140612'}, {u'edited': False, u'comment_id': 4410078, u'creation_date': 1487081039, u'post_id': 2140612, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 50346, u'user_type': u'registered', u'reputation': 206, u'link': u'https://math.stackexchange.com/users/50346/ben-aaronson', u'display_name': u'Ben Aaronson', u'badge_counts': {u'bronze': 9, u'silver': 1, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140612#comment4410078_2140612'}, {u'edited': False, u'comment_id': 4410210, u'creation_date': 1487083268, u'post_id': 2140612, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 139123, u'user_type': u'registered', u'reputation': 46593, u'link': u'https://math.stackexchange.com/users/139123/david-k', u'display_name': u'David K', u'badge_counts': {u'bronze': 104, u'silver': 39, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140612#comment4410210_2140612'}], u'creation_date': 1486894266, u'comment_count': 7, u'score': 10, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140612#2140612', u'body_markdown': u'The [boy or girl paradox][1] already mentioned by Agnishom has an interesting [variation][1]:

*&#39;&#39;Suppose we were told not only that Mr. Smith has two children, and one of them is a boy, but also that the boy was born on a Tuesday: does this change the previous analyses?&#39;&#39;* (for the question &#39;&#39;what is the probability that both children are boys&#39;&#39;)?

Using some elementary computations with Bayes formula, the seemingly useless information that a child was born on Tuesday, changes the results.

To understand the intuition behind, consider an extreme case where you knew that one boy was born on December $30$. Then it is very unlikely that the other child is born on that date too, so one child is &#39;&#39;specified&#39;&#39; by the date-information. This reduces the question to &#39;&#39;is the other child a boy&#39;&#39;? and changes the probability from $\frac13$ to approximately $\frac12$.

However, I do **not** recommend to use this example for teaching, as there are many interpretations of this paradox (that partially depend on language nuances of the formulation) and it can add more confusion then clarify something.


  [1]: https://en.wikipedia.org/wiki/Boy_or_Girl_paradox#Information_about_the_child', u'owner': {u'user_id': 62009, u'user_type': u'registered', u'reputation': 7053, u'link': u'https://math.stackexchange.com/users/62009/peter-franek', u'accept_rate': 61, u'display_name': u'Peter Franek', u'badge_counts': {u'bronze': 34, u'silver': 19, u'gold': 3}}, u'is_accepted': False, u'last_edit_date': 1486974288, u'share_link': u'https://math.stackexchange.com/a/2140612', u'answer_id': 2140612}, {u'up_vote_count': 17, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1486999229, u'comments': [{u'edited': False, u'comment_id': 4404248, u'creation_date': 1486927517, u'post_id': 2140679, u'score': 8, u'post_type': u'answer', u'owner': {u'user_id': 14972, u'user_type': u'registered', u'reputation': 104735, u'link': u'https://math.stackexchange.com/users/14972/hurkyl', u'accept_rate': 62, u'display_name': u'Hurkyl', u'badge_counts': {u'bronze': 243, u'silver': 104, u'gold': 8}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4404248_2140679'}, {u'edited': False, u'comment_id': 4404854, u'creation_date': 1486939210, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 62009, u'user_type': u'registered', u'reputation': 7053, u'link': u'https://math.stackexchange.com/users/62009/peter-franek', u'accept_rate': 61, u'display_name': u'Peter Franek', u'badge_counts': {u'bronze': 34, u'silver': 19, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4404854_2140679'}, {u'edited': False, u'reply_to_user': {u'user_id': 14972, u'user_type': u'registered', u'reputation': 104735, u'link': u'https://math.stackexchange.com/users/14972/hurkyl', u'accept_rate': 62, u'display_name': u'Hurkyl', u'badge_counts': {u'bronze': 243, u'silver': 104, u'gold': 8}}, u'comment_id': 4405423, u'creation_date': 1486954614, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4405423_2140679'}, {u'edited': False, u'reply_to_user': {u'user_id': 14972, u'user_type': u'registered', u'reputation': 104735, u'link': u'https://math.stackexchange.com/users/14972/hurkyl', u'accept_rate': 62, u'display_name': u'Hurkyl', u'badge_counts': {u'bronze': 243, u'silver': 104, u'gold': 8}}, u'comment_id': 4405427, u'creation_date': 1486954838, u'post_id': 2140679, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4405427_2140679'}, {u'edited': False, u'reply_to_user': {u'user_id': 62009, u'user_type': u'registered', u'reputation': 7053, u'link': u'https://math.stackexchange.com/users/62009/peter-franek', u'accept_rate': 61, u'display_name': u'Peter Franek', u'badge_counts': {u'bronze': 34, u'silver': 19, u'gold': 3}}, u'comment_id': 4405440, u'creation_date': 1486955336, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4405440_2140679'}, {u'edited': False, u'comment_id': 4405497, u'creation_date': 1486957026, u'post_id': 2140679, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 14972, u'user_type': u'registered', u'reputation': 104735, u'link': u'https://math.stackexchange.com/users/14972/hurkyl', u'accept_rate': 62, u'display_name': u'Hurkyl', u'badge_counts': {u'bronze': 243, u'silver': 104, u'gold': 8}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4405497_2140679'}, {u'edited': False, u'comment_id': 4405503, u'creation_date': 1486957127, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 14972, u'user_type': u'registered', u'reputation': 104735, u'link': u'https://math.stackexchange.com/users/14972/hurkyl', u'accept_rate': 62, u'display_name': u'Hurkyl', u'badge_counts': {u'bronze': 243, u'silver': 104, u'gold': 8}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4405503_2140679'}, {u'edited': False, u'reply_to_user': {u'user_id': 14972, u'user_type': u'registered', u'reputation': 104735, u'link': u'https://math.stackexchange.com/users/14972/hurkyl', u'accept_rate': 62, u'display_name': u'Hurkyl', u'badge_counts': {u'bronze': 243, u'silver': 104, u'gold': 8}}, u'comment_id': 4405536, u'creation_date': 1486958063, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4405536_2140679'}, {u'edited': False, u'comment_id': 4405587, u'creation_date': 1486959602, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 14972, u'user_type': u'registered', u'reputation': 104735, u'link': u'https://math.stackexchange.com/users/14972/hurkyl', u'accept_rate': 62, u'display_name': u'Hurkyl', u'badge_counts': {u'bronze': 243, u'silver': 104, u'gold': 8}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4405587_2140679'}, {u'edited': False, u'reply_to_user': {u'user_id': 14972, u'user_type': u'registered', u'reputation': 104735, u'link': u'https://math.stackexchange.com/users/14972/hurkyl', u'accept_rate': 62, u'display_name': u'Hurkyl', u'badge_counts': {u'bronze': 243, u'silver': 104, u'gold': 8}}, u'comment_id': 4405628, u'creation_date': 1486961371, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4405628_2140679'}, {u'edited': False, u'comment_id': 4405931, u'creation_date': 1486973661, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 397623, u'user_type': u'registered', u'reputation': 109, u'link': u'https://math.stackexchange.com/users/397623/jollyjoker', u'display_name': u'JollyJoker', u'badge_counts': {u'bronze': 3, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4405931_2140679'}, {u'edited': False, u'comment_id': 4406092, u'creation_date': 1486978695, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 153429, u'user_type': u'registered', u'reputation': 3215, u'link': u'https://math.stackexchange.com/users/153429/meni-rosenfeld', u'display_name': u'Meni Rosenfeld', u'badge_counts': {u'bronze': 21, u'silver': 9, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4406092_2140679'}, {u'edited': False, u'comment_id': 4406106, u'creation_date': 1486979008, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 153429, u'user_type': u'registered', u'reputation': 3215, u'link': u'https://math.stackexchange.com/users/153429/meni-rosenfeld', u'display_name': u'Meni Rosenfeld', u'badge_counts': {u'bronze': 21, u'silver': 9, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4406106_2140679'}, {u'edited': False, u'comment_id': 4406118, u'creation_date': 1486979431, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 153429, u'user_type': u'registered', u'reputation': 3215, u'link': u'https://math.stackexchange.com/users/153429/meni-rosenfeld', u'display_name': u'Meni Rosenfeld', u'badge_counts': {u'bronze': 21, u'silver': 9, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4406118_2140679'}, {u'edited': False, u'reply_to_user': {u'user_id': 153429, u'user_type': u'registered', u'reputation': 3215, u'link': u'https://math.stackexchange.com/users/153429/meni-rosenfeld', u'display_name': u'Meni Rosenfeld', u'badge_counts': {u'bronze': 21, u'silver': 9, u'gold': 2}}, u'comment_id': 4406288, u'creation_date': 1486985990, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4406288_2140679'}, {u'edited': False, u'reply_to_user': {u'user_id': 153429, u'user_type': u'registered', u'reputation': 3215, u'link': u'https://math.stackexchange.com/users/153429/meni-rosenfeld', u'display_name': u'Meni Rosenfeld', u'badge_counts': {u'bronze': 21, u'silver': 9, u'gold': 2}}, u'comment_id': 4406296, u'creation_date': 1486986138, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4406296_2140679'}, {u'edited': False, u'reply_to_user': {u'user_id': 153429, u'user_type': u'registered', u'reputation': 3215, u'link': u'https://math.stackexchange.com/users/153429/meni-rosenfeld', u'display_name': u'Meni Rosenfeld', u'badge_counts': {u'bronze': 21, u'silver': 9, u'gold': 2}}, u'comment_id': 4406305, u'creation_date': 1486986474, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4406305_2140679'}, {u'edited': False, u'comment_id': 4406405, u'creation_date': 1486989107, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 153429, u'user_type': u'registered', u'reputation': 3215, u'link': u'https://math.stackexchange.com/users/153429/meni-rosenfeld', u'display_name': u'Meni Rosenfeld', u'badge_counts': {u'bronze': 21, u'silver': 9, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4406405_2140679'}, {u'edited': False, u'reply_to_user': {u'user_id': 153429, u'user_type': u'registered', u'reputation': 3215, u'link': u'https://math.stackexchange.com/users/153429/meni-rosenfeld', u'display_name': u'Meni Rosenfeld', u'badge_counts': {u'bronze': 21, u'silver': 9, u'gold': 2}}, u'comment_id': 4406432, u'creation_date': 1486989888, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4406432_2140679'}, {u'edited': False, u'reply_to_user': {u'user_id': 153429, u'user_type': u'registered', u'reputation': 3215, u'link': u'https://math.stackexchange.com/users/153429/meni-rosenfeld', u'display_name': u'Meni Rosenfeld', u'badge_counts': {u'bronze': 21, u'silver': 9, u'gold': 2}}, u'comment_id': 4406433, u'creation_date': 1486989891, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4406433_2140679'}, {u'edited': False, u'comment_id': 4406974, u'creation_date': 1487000935, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4406974_2140679'}, {u'edited': False, u'reply_to_user': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'comment_id': 4407012, u'creation_date': 1487001631, u'post_id': 2140679, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4407012_2140679'}, {u'edited': False, u'comment_id': 4407059, u'creation_date': 1487002502, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment4407059_2140679'}, {u'edited': False, u'comment_id': 5795722, u'creation_date': 1528336473, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 27193, u'user_type': u'registered', u'reputation': 1498, u'link': u'https://math.stackexchange.com/users/27193/nathaniel', u'accept_rate': 43, u'display_name': u'Nathaniel', u'badge_counts': {u'bronze': 30, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment5795722_2140679'}, {u'edited': False, u'reply_to_user': {u'user_id': 27193, u'user_type': u'registered', u'reputation': 1498, u'link': u'https://math.stackexchange.com/users/27193/nathaniel', u'accept_rate': 43, u'display_name': u'Nathaniel', u'badge_counts': {u'bronze': 30, u'silver': 14, u'gold': 0}}, u'comment_id': 5795773, u'creation_date': 1528339437, u'post_id': 2140679, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#comment5795773_2140679'}], u'creation_date': 1486898373, u'comment_count': 25, u'score': 17, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2140679#2140679', u'body_markdown': u'I particular like the **triple-or-nothing game**:

&gt; You start with $1$ sweet $^{[1]}$ in the pot. At each step, you can either choose to leave the game with all the sweets in the pot, or you can continue the game. If you continue, a fair coin is flipped, and if it comes up heads then the sweets in the pot are tripled, but if it comes up tails then the pot is emptied.

&gt; If you can play this game only once, how many sweets would you be willing to pay to play? And how should you play? (Assume that you want to get the most sweets possible.)

&gt; &lt;sub&gt;$^{[1]}$ Let&#39;s not be money-minded here...&lt;/sub&gt;

The naive (and incorrect) analysis is to compute that at any step if there are $x$ sweets in the pot and you continue the game then the expected number of sweets in the pot will become $1.5x$. Thus you should not stop. But that is stupid; if you never stop you will never get any sweets! So when to stop?

Worse still, a **correct** analysis will tell you that no matter how many sweets you pay, you can play in such a way that the expected number of sweets you leave with is more than what you paid! The (silly) conclusion is that you should be willing to pay any number of sweets to play!

If you think really carefully about it, you will realize that expectation is a very poor indicator of rationality of choice. Instead, everyone will have some risk aversity, more generally a mapping from probability distributions to favourability. One possibility is that a probability distribution is unfavourable iff its median is not positive (representing no net gain). Then clearly this game will never be favourable to anyone with this kind of risk aversity except if you commit to playing for exactly one step. In real life, people will evaluate distributions in a much more complicated way than just checking the median.

That said, a reasonable rule of thumb is that it is not worth to make a decision whose estimated benefit does not have both positive mean and positive median. Positive mean is necessary for rules of thumb, otherwise you will not benefit in the long run. Positive median will prevent other stupid decisions such as playing the triple-or-nothing game for more than one step or paying more than 1.5 sweets to play it. More risk-averse people will play for zero steps and just take the initial sweet and leave!

This rule will show (reasonably) not only that it is not worth to pay even 2 sweets to play the triple-or-nothing game only once, but also that it is not worth to offer the game for others to play! Any application of probability to real-life decisions should be able to deal with such situations.

---

[Further remarks...]

My claim about the rule of thumb being reasonable is that it should work quite well in **real life**. Whether it agrees with various mathematical models of human rationality is irrelevant. Secondly, my rule of thumb is merely for determining whether a **single** option is worth taking or not. To compare between **multiple** choices of which you must pick one, you would have to extend the rule of thumb. One possible way is to define the value of each choice to be the minimum of the mean and median benefit. Then you of course pick the choice with the maximum value. Thirdly, different people will of course have **different** ways to evaluate a choice based on its benefit&#39;s probability distribution (assuming it can even be translated to some real number). A very risk averse person might take the minimum of the 1st percentile (roughly speaking the minimum benefit you believe you will gain in 99% of the cases) and the mean (average benefit). Someone else may combine the percentiles and mean in a different fashion, such as taking $-\infty$ as the value if the 5th percentile is below some threshold (such as representing serious hurt), but taking the mean otherwise.', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'is_accepted': False, u'last_edit_date': 1486999229, u'share_link': u'https://math.stackexchange.com/a/2140679', u'answer_id': 2140679}, {u'up_vote_count': 25, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 1, u'last_activity_date': 1487032530, u'comments': [{u'edited': False, u'comment_id': 4405224, u'creation_date': 1486949061, u'post_id': 2141081, u'score': 19, u'post_type': u'answer', u'owner': {u'user_id': 191074, u'user_type': u'registered', u'reputation': 682, u'link': u'https://math.stackexchange.com/users/191074/theonlygusti', u'accept_rate': 43, u'display_name': u'theonlygusti', u'badge_counts': {u'bronze': 15, u'silver': 5, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4405224_2141081'}, {u'edited': False, u'reply_to_user': {u'user_id': 191074, u'user_type': u'registered', u'reputation': 682, u'link': u'https://math.stackexchange.com/users/191074/theonlygusti', u'accept_rate': 43, u'display_name': u'theonlygusti', u'badge_counts': {u'bronze': 15, u'silver': 5, u'gold': 0}}, u'comment_id': 4405543, u'creation_date': 1486958232, u'post_id': 2141081, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4405543_2141081'}, {u'edited': False, u'reply_to_user': {u'user_id': 191074, u'user_type': u'registered', u'reputation': 682, u'link': u'https://math.stackexchange.com/users/191074/theonlygusti', u'accept_rate': 43, u'display_name': u'theonlygusti', u'badge_counts': {u'bronze': 15, u'silver': 5, u'gold': 0}}, u'comment_id': 4405899, u'creation_date': 1486972782, u'post_id': 2141081, u'score': 18, u'post_type': u'answer', u'owner': {u'user_id': 5001, u'user_type': u'registered', u'reputation': 643, u'link': u'https://math.stackexchange.com/users/5001/rawling', u'display_name': u'Rawling', u'badge_counts': {u'bronze': 13, u'silver': 4, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4405899_2141081'}, {u'edited': False, u'reply_to_user': {u'user_id': 191074, u'user_type': u'registered', u'reputation': 682, u'link': u'https://math.stackexchange.com/users/191074/theonlygusti', u'accept_rate': 43, u'display_name': u'theonlygusti', u'badge_counts': {u'bronze': 15, u'silver': 5, u'gold': 0}}, u'comment_id': 4406415, u'creation_date': 1486989356, u'post_id': 2141081, u'score': 5, u'post_type': u'answer', u'owner': {u'user_id': 153429, u'user_type': u'registered', u'reputation': 3215, u'link': u'https://math.stackexchange.com/users/153429/meni-rosenfeld', u'display_name': u'Meni Rosenfeld', u'badge_counts': {u'bronze': 21, u'silver': 9, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4406415_2141081'}, {u'edited': False, u'comment_id': 4406600, u'creation_date': 1486994158, u'post_id': 2141081, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 21434, u'user_type': u'registered', u'reputation': 125, u'link': u'https://math.stackexchange.com/users/21434/user3490', u'display_name': u'user3490', u'badge_counts': {u'bronze': 3, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4406600_2141081'}, {u'edited': False, u'reply_to_user': {u'user_id': 21434, u'user_type': u'registered', u'reputation': 125, u'link': u'https://math.stackexchange.com/users/21434/user3490', u'display_name': u'user3490', u'badge_counts': {u'bronze': 3, u'silver': 0, u'gold': 0}}, u'comment_id': 4406703, u'creation_date': 1486996226, u'post_id': 2141081, u'score': 5, u'post_type': u'answer', u'owner': {u'user_id': 67842, u'user_type': u'registered', u'reputation': 8473, u'link': u'https://math.stackexchange.com/users/67842/glen-o', u'display_name': u'Glen O', u'badge_counts': {u'bronze': 28, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4406703_2141081'}, {u'edited': False, u'comment_id': 4407530, u'creation_date': 1487011489, u'post_id': 2141081, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 178670, u'user_type': u'registered', u'reputation': 101, u'link': u'https://math.stackexchange.com/users/178670/fixer1234', u'display_name': u'fixer1234', u'badge_counts': {u'bronze': 1, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4407530_2141081'}, {u'edited': False, u'reply_to_user': {u'user_id': 191074, u'user_type': u'registered', u'reputation': 682, u'link': u'https://math.stackexchange.com/users/191074/theonlygusti', u'accept_rate': 43, u'display_name': u'theonlygusti', u'badge_counts': {u'bronze': 15, u'silver': 5, u'gold': 0}}, u'comment_id': 4408532, u'creation_date': 1487031616, u'post_id': 2141081, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 266243, u'user_type': u'registered', u'reputation': 5422, u'link': u'https://math.stackexchange.com/users/266243/daniel-r-collins', u'accept_rate': 44, u'display_name': u'Daniel R. Collins', u'badge_counts': {u'bronze': 32, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4408532_2141081'}, {u'edited': False, u'comment_id': 4408538, u'creation_date': 1487031815, u'post_id': 2141081, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 224454, u'user_type': u'registered', u'reputation': 24381, u'link': u'https://math.stackexchange.com/users/224454/brian-tung', u'display_name': u'Brian Tung', u'badge_counts': {u'bronze': 51, u'silver': 23, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4408538_2141081'}, {u'edited': False, u'comment_id': 4408546, u'creation_date': 1487031971, u'post_id': 2141081, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 266243, u'user_type': u'registered', u'reputation': 5422, u'link': u'https://math.stackexchange.com/users/266243/daniel-r-collins', u'accept_rate': 44, u'display_name': u'Daniel R. Collins', u'badge_counts': {u'bronze': 32, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4408546_2141081'}, {u'edited': False, u'comment_id': 4411102, u'creation_date': 1487102154, u'post_id': 2141081, u'score': 4, u'post_type': u'answer', u'owner': {u'user_id': 221375, u'user_type': u'registered', u'reputation': 108, u'link': u'https://math.stackexchange.com/users/221375/kyle', u'display_name': u'Kyle', u'badge_counts': {u'bronze': 6, u'silver': 1, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4411102_2141081'}, {u'edited': False, u'comment_id': 4411485, u'creation_date': 1487107482, u'post_id': 2141081, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 8309, u'user_type': u'registered', u'reputation': 5090, u'link': u'https://math.stackexchange.com/users/8309/martianinvader', u'display_name': u'MartianInvader', u'badge_counts': {u'bronze': 25, u'silver': 12, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4411485_2141081'}, {u'edited': False, u'comment_id': 4411614, u'creation_date': 1487109635, u'post_id': 2141081, u'score': 3, u'post_type': u'answer', u'owner': {u'user_id': 72968, u'user_type': u'registered', u'reputation': 935, u'link': u'https://math.stackexchange.com/users/72968/silverfish', u'display_name': u'Silverfish', u'badge_counts': {u'bronze': 22, u'silver': 8, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4411614_2141081'}, {u'edited': False, u'comment_id': 4411888, u'creation_date': 1487116625, u'post_id': 2141081, u'score': 3, u'post_type': u'answer', u'owner': {u'user_id': 221811, u'user_type': u'registered', u'reputation': 51939, u'link': u'https://math.stackexchange.com/users/221811/chappers', u'accept_rate': 44, u'display_name': u'Chappers', u'badge_counts': {u'bronze': 86, u'silver': 39, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4411888_2141081'}, {u'edited': False, u'comment_id': 4419336, u'creation_date': 1487324947, u'post_id': 2141081, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 382396, u'user_type': u'registered', u'reputation': 111, u'link': u'https://math.stackexchange.com/users/382396/kami-kaze', u'display_name': u'Kami Kaze', u'badge_counts': {u'bronze': 4, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#comment4419336_2141081'}], u'creation_date': 1486919652, u'comment_count': 15, u'score': 24, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141081#2141081', u'body_markdown': u'I find that **almost anything** about probability is counter-intuitive to my college students on first encounter. Possibly this may depend on your audience. Here are a few examples:

$1.$ Question: &quot;If a certain event has a $40\%$ chance of success, and we run $50$ experiments, then how many would you expect to succeed?&quot; The most common responses I usually get are &quot;all of them&quot; and &quot;none of them&quot;. This is after an hour-long lecture on the subject. 

$2.$ Question: &quot;Interpret this probability statement: There is a $30\%$ chance of rain today in the New York area.&quot; I usually only get about a $65\%$ successful response rate on this on a multiple-choice quiz, even after the hour-long lecture on the subject. Once I had a student so bamboozled by it that she called up the national meteorology service for a consultation.

$3.$ Question: &quot;We have a hand of four cards $\{A, 2, 3, 4\}$, and pick out two at random; what is the probability we get the $A$ or $2$ ?&quot; Common responses are $25\%$, $50\%$, and $75\%$. I&#39;ve never had anyone in a class intuit the correct answer on first presentation. 

$4.$ Question: &quot;If you drive to school on a given day, you either get in an accident or you don&#39;t. Are these equally likely outcomes?&quot; At least half of any class answers &quot;yes&quot; on the first presentation. This can be repeated with the same result with similar follow-up questions. ', u'owner': {u'user_id': 266243, u'user_type': u'registered', u'reputation': 5422, u'link': u'https://math.stackexchange.com/users/266243/daniel-r-collins', u'accept_rate': 44, u'display_name': u'Daniel R. Collins', u'badge_counts': {u'bronze': 32, u'silver': 14, u'gold': 0}}, u'is_accepted': False, u'last_edit_date': 1487032530, u'share_link': u'https://math.stackexchange.com/a/2141081', u'answer_id': 2141081}, {u'up_vote_count': 14, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 1, u'last_activity_date': 1487116818, u'comments': [{u'edited': False, u'comment_id': 4406824, u'creation_date': 1486998789, u'post_id': 2141200, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 67842, u'user_type': u'registered', u'reputation': 8473, u'link': u'https://math.stackexchange.com/users/67842/glen-o', u'display_name': u'Glen O', u'badge_counts': {u'bronze': 28, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141200#comment4406824_2141200'}, {u'edited': False, u'reply_to_user': {u'user_id': 67842, u'user_type': u'registered', u'reputation': 8473, u'link': u'https://math.stackexchange.com/users/67842/glen-o', u'display_name': u'Glen O', u'badge_counts': {u'bronze': 28, u'silver': 14, u'gold': 0}}, u'comment_id': 4406837, u'creation_date': 1486998997, u'post_id': 2141200, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 278700, u'user_type': u'registered', u'reputation': 465, u'link': u'https://math.stackexchange.com/users/278700/aalok', u'display_name': u'Aalok', u'badge_counts': {u'bronze': 10, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141200#comment4406837_2141200'}, {u'edited': False, u'comment_id': 4406995, u'creation_date': 1487001281, u'post_id': 2141200, u'score': 3, u'post_type': u'answer', u'owner': {u'user_id': 67842, u'user_type': u'registered', u'reputation': 8473, u'link': u'https://math.stackexchange.com/users/67842/glen-o', u'display_name': u'Glen O', u'badge_counts': {u'bronze': 28, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141200#comment4406995_2141200'}, {u'edited': False, u'reply_to_user': {u'user_id': 67842, u'user_type': u'registered', u'reputation': 8473, u'link': u'https://math.stackexchange.com/users/67842/glen-o', u'display_name': u'Glen O', u'badge_counts': {u'bronze': 28, u'silver': 14, u'gold': 0}}, u'comment_id': 4407047, u'creation_date': 1487002270, u'post_id': 2141200, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 278700, u'user_type': u'registered', u'reputation': 465, u'link': u'https://math.stackexchange.com/users/278700/aalok', u'display_name': u'Aalok', u'badge_counts': {u'bronze': 10, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141200#comment4407047_2141200'}, {u'edited': False, u'comment_id': 4407119, u'creation_date': 1487003576, u'post_id': 2141200, u'score': 3, u'post_type': u'answer', u'owner': {u'user_id': 67842, u'user_type': u'registered', u'reputation': 8473, u'link': u'https://math.stackexchange.com/users/67842/glen-o', u'display_name': u'Glen O', u'badge_counts': {u'bronze': 28, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141200#comment4407119_2141200'}], u'creation_date': 1486924265, u'comment_count': 5, u'score': 13, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141200#2141200', u'body_markdown': u'**Bertrand&#39;s Paradox**

&gt; Given two concentric circles ($S_1$, $S_2$) with radii $R_1=r$ and $R_2=\frac{r}2$, what is the probability, upon choosing a chord $c$ of the circle $S_1$ at random, that $c\:\cap\: S_2 \neq \emptyset$ ?

Simply speaking, your task is to  
&gt;choose a
chord of the larger circle at random and find the probability that it will intersect the
smaller circle.




Surprisingly, Bertrand&#39;s Paradox offers **three distinct yet valid solutions**.

The same problem can also be stated as: 

&gt; Given an equilateral triangle inscribed in a circle, find the
&gt; probability of randomly choosing a chord of the circle greater than
&gt; the length of a side of the triangle.

The _counter-intuition_ steps in when you understand that the answer to the stated problem is $\frac12,\:\frac13,$ and even $\frac14$ at the same time, and all three answers are perfectly valid.

**The crucial reason why there are three solutions to this in different cases is that the methods of selection of `random variables` are different in each case.**

Here&#39;s the [Wikipedia page][1] for details on how each value is obtained and through what steps.

I remember that a professor had begun my high-school level probability class using Bertrand&#39;s Paradox as an introductory example.

  [1]: https://en.m.wikipedia.org/wiki/Bertrand_paradox_%28probability%29', u'owner': {u'user_id': 278700, u'user_type': u'registered', u'reputation': 465, u'link': u'https://math.stackexchange.com/users/278700/aalok', u'display_name': u'Aalok', u'badge_counts': {u'bronze': 10, u'silver': 2, u'gold': 0}}, u'is_accepted': False, u'last_edit_date': 1487116818, u'share_link': u'https://math.stackexchange.com/a/2141200', u'answer_id': 2141200}, {u'up_vote_count': 2, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 1, u'last_activity_date': 1486927335, u'comments': [{u'edited': False, u'comment_id': 4404213, u'creation_date': 1486927040, u'post_id': 2141263, u'score': 3, u'post_type': u'answer', u'owner': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141263#comment4404213_2141263'}, {u'edited': False, u'reply_to_user': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'comment_id': 4404241, u'creation_date': 1486927395, u'post_id': 2141263, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 415642, u'user_type': u'registered', u'reputation': 46, u'link': u'https://math.stackexchange.com/users/415642/david-stolnicki', u'display_name': u'David Stolnicki', u'badge_counts': {u'bronze': 7, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141263#comment4404241_2141263'}], u'creation_date': 1486926856, u'comment_count': 2, u'score': 1, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141263#2141263', u'body_markdown': u'Consider the $d-$dimensional sphere,  then as $d$ goes to infinity the mass concentrates on the equator $x_1=0$', u'owner': {u'user_id': 415642, u'user_type': u'registered', u'reputation': 46, u'link': u'https://math.stackexchange.com/users/415642/david-stolnicki', u'display_name': u'David Stolnicki', u'badge_counts': {u'bronze': 7, u'silver': 0, u'gold': 0}}, u'is_accepted': False, u'last_edit_date': 1486927335, u'share_link': u'https://math.stackexchange.com/a/2141263', u'answer_id': 2141263}, {u'up_vote_count': 25, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1486975370, u'comments': [{u'edited': False, u'comment_id': 4406290, u'creation_date': 1486986016, u'post_id': 2141322, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 397623, u'user_type': u'registered', u'reputation': 109, u'link': u'https://math.stackexchange.com/users/397623/jollyjoker', u'display_name': u'JollyJoker', u'badge_counts': {u'bronze': 3, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141322#comment4406290_2141322'}, {u'edited': False, u'comment_id': 4406857, u'creation_date': 1486999218, u'post_id': 2141322, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141322#comment4406857_2141322'}, {u'edited': False, u'comment_id': 4406965, u'creation_date': 1487000835, u'post_id': 2141322, u'score': 12, u'post_type': u'answer', u'owner': {u'user_id': 341019, u'user_type': u'registered', u'reputation': 18033, u'link': u'https://math.stackexchange.com/users/341019/especially-lime', u'display_name': u'Especially Lime', u'badge_counts': {u'bronze': 50, u'silver': 20, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141322#comment4406965_2141322'}, {u'edited': False, u'comment_id': 4407779, u'creation_date': 1487016369, u'post_id': 2141322, u'score': 3, u'post_type': u'answer', u'owner': {u'user_id': 397623, u'user_type': u'registered', u'reputation': 109, u'link': u'https://math.stackexchange.com/users/397623/jollyjoker', u'display_name': u'JollyJoker', u'badge_counts': {u'bronze': 3, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141322#comment4407779_2141322'}, {u'edited': False, u'reply_to_user': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'comment_id': 4416007, u'creation_date': 1487230655, u'post_id': 2141322, u'score': 5, u'post_type': u'answer', u'owner': {u'user_id': 548, u'user_type': u'registered', u'reputation': 217, u'link': u'https://math.stackexchange.com/users/548/hobbs', u'display_name': u'hobbs', u'badge_counts': {u'bronze': 8, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141322#comment4416007_2141322'}], u'creation_date': 1486929236, u'comment_count': 5, u'score': 25, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141322#2141322', u'body_markdown': u'**Airplane Seating**

$100$ people are boarding a plane in a line and each of them is assigned to one of the $100$ seats on a plane. However, the first person in line forgot his boarding pass and as a result decided to sit down in a random seat. The second person will do the following:

1. Sit in her seat if it still available.
2. If her seat is not available, choose a random seat among the seats remaining and sit there.

Each following person sits according to the same rules as the second person. What is the probability the $100^{th}$ person will be able to sit in her assigned seat?


Most people think the probability is very small and think there is a tiny chance of the 100th person&#39;s seat being left after all the people move around. But the actual probability ends up being $\frac{1}{2}$.', u'owner': {u'user_id': 149691, u'user_type': u'registered', u'reputation': 489, u'link': u'https://math.stackexchange.com/users/149691/user35734', u'display_name': u'user35734', u'badge_counts': {u'bronze': 7, u'silver': 3, u'gold': 0}}, u'is_accepted': False, u'last_edit_date': 1486975370, u'share_link': u'https://math.stackexchange.com/a/2141322', u'answer_id': 2141322}, {u'up_vote_count': 8, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1486970309, u'comments': [{u'edited': False, u'comment_id': 4405833, u'creation_date': 1486969812, u'post_id': 2141520, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141520#comment4405833_2141520'}, {u'edited': False, u'comment_id': 4405842, u'creation_date': 1486970113, u'post_id': 2141520, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141520#comment4405842_2141520'}, {u'edited': False, u'reply_to_user': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'comment_id': 4405985, u'creation_date': 1486975634, u'post_id': 2141520, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 34930, u'user_type': u'registered', u'reputation': 27897, u'link': u'https://math.stackexchange.com/users/34930/celtschk', u'accept_rate': 78, u'display_name': u'celtschk', u'badge_counts': {u'bronze': 95, u'silver': 53, u'gold': 6}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141520#comment4405985_2141520'}, {u'edited': False, u'comment_id': 4406121, u'creation_date': 1486979488, u'post_id': 2141520, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141520#comment4406121_2141520'}, {u'edited': False, u'comment_id': 4408638, u'creation_date': 1487034332, u'post_id': 2141520, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 210401, u'user_type': u'registered', u'reputation': 6836, u'link': u'https://math.stackexchange.com/users/210401/david-g-stork', u'accept_rate': 29, u'display_name': u'David G. Stork', u'badge_counts': {u'bronze': 27, u'silver': 7, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141520#comment4408638_2141520'}, {u'edited': False, u'comment_id': 4409032, u'creation_date': 1487046271, u'post_id': 2141520, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 276406, u'user_type': u'registered', u'reputation': 2507, u'link': u'https://math.stackexchange.com/users/276406/wildcard', u'display_name': u'Wildcard', u'badge_counts': {u'bronze': 27, u'silver': 7, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141520#comment4409032_2141520'}], u'creation_date': 1486937199, u'comment_count': 6, u'score': 8, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141520#2141520', u'body_markdown': u'I think the most stunning example are the [non-transitive dice.][1]

Take three cubic dice with the following numbers on their sides:

  * Die $A:$ 	$3 \:	3 \:	3 \:	3 \:	3 \:	6$
  * Die $B:$	$2 \:	2 \:	2 \:	5 \:	5 \:	5$
  * Die $C:$	$1 \:	4 	\:4 \:	4 \:	4 	\:4$

Now I offer you the following game: You choose a die as you like, then I choose another die, and then we are rolling and the highest number wins.

No matter which die you choose, I can choose another one that wins more often than loses against your choice.


  [1]: https://plus.maths.org/content/non-transitiv-dice', u'owner': {u'user_id': 34930, u'user_type': u'registered', u'reputation': 27897, u'link': u'https://math.stackexchange.com/users/34930/celtschk', u'accept_rate': 78, u'display_name': u'celtschk', u'badge_counts': {u'bronze': 95, u'silver': 53, u'gold': 6}}, u'is_accepted': False, u'last_edit_date': 1486970309, u'share_link': u'https://math.stackexchange.com/a/2141520', u'answer_id': 2141520}, {u'up_vote_count': 6, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1486937503, u'comments': [{u'edited': False, u'comment_id': 4410841, u'creation_date': 1487097198, u'post_id': 2141528, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 22004, u'user_type': u'registered', u'reputation': 668, u'link': u'https://math.stackexchange.com/users/22004/polyapal', u'display_name': u'PolyaPal', u'badge_counts': {u'bronze': 8, u'silver': 4, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141528#comment4410841_2141528'}, {u'edited': False, u'comment_id': 4414474, u'creation_date': 1487186942, u'post_id': 2141528, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 136, u'user_type': u'registered', u'reputation': 5285, u'link': u'https://math.stackexchange.com/users/136/blueraja-danny-pflughoeft', u'accept_rate': 73, u'display_name': u'BlueRaja - Danny Pflughoeft', u'badge_counts': {u'bronze': 42, u'silver': 26, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141528#comment4414474_2141528'}, {u'edited': False, u'comment_id': 4414884, u'creation_date': 1487195905, u'post_id': 2141528, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 72968, u'user_type': u'registered', u'reputation': 935, u'link': u'https://math.stackexchange.com/users/72968/silverfish', u'display_name': u'Silverfish', u'badge_counts': {u'bronze': 22, u'silver': 8, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141528#comment4414884_2141528'}], u'creation_date': 1486937503, u'comment_count': 3, u'score': 6, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141528#2141528', u'body_markdown': u'Perhaps Parrondo&#39;s Paradox would be interesting. One can combine losing propositions into a winning proposition.

Simpson&#39;s Paradox is also interesting. (And actually occurred in a court case.)', u'owner': {u'user_id': 377514, u'user_type': u'registered', u'reputation': 239, u'link': u'https://math.stackexchange.com/users/377514/ttw', u'display_name': u'ttw', u'badge_counts': {u'bronze': 2, u'silver': 2, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2141528', u'answer_id': 2141528}, {u'up_vote_count': 6, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 4, u'last_activity_date': 1486948794, u'comments': [{u'edited': False, u'comment_id': 4405983, u'creation_date': 1486975525, u'post_id': 2141728, u'score': 7, u'post_type': u'answer', u'owner': {u'user_id': 34930, u'user_type': u'registered', u'reputation': 27897, u'link': u'https://math.stackexchange.com/users/34930/celtschk', u'accept_rate': 78, u'display_name': u'celtschk', u'badge_counts': {u'bronze': 95, u'silver': 53, u'gold': 6}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141728#comment4405983_2141728'}, {u'edited': False, u'comment_id': 4406156, u'creation_date': 1486980610, u'post_id': 2141728, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 14972, u'user_type': u'registered', u'reputation': 104735, u'link': u'https://math.stackexchange.com/users/14972/hurkyl', u'accept_rate': 62, u'display_name': u'Hurkyl', u'badge_counts': {u'bronze': 243, u'silver': 104, u'gold': 8}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141728#comment4406156_2141728'}, {u'edited': False, u'comment_id': 4406860, u'creation_date': 1486999298, u'post_id': 2141728, u'score': 3, u'post_type': u'answer', u'owner': {u'user_id': 67842, u'user_type': u'registered', u'reputation': 8473, u'link': u'https://math.stackexchange.com/users/67842/glen-o', u'display_name': u'Glen O', u'badge_counts': {u'bronze': 28, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141728#comment4406860_2141728'}, {u'edited': False, u'comment_id': 4410343, u'creation_date': 1487085650, u'post_id': 2141728, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 165723, u'user_type': u'registered', u'reputation': 123, u'link': u'https://math.stackexchange.com/users/165723/dberm22', u'display_name': u'dberm22', u'badge_counts': {u'bronze': 6, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141728#comment4410343_2141728'}, {u'edited': False, u'comment_id': 4411865, u'creation_date': 1487116195, u'post_id': 2141728, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 67710, u'user_type': u'registered', u'reputation': 1672, u'link': u'https://math.stackexchange.com/users/67710/ned', u'display_name': u'Ned', u'badge_counts': {u'bronze': 9, u'silver': 8, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141728#comment4411865_2141728'}], u'creation_date': 1486948794, u'comment_count': 5, u'score': 2, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141728#2141728', u'body_markdown': u'I flip two coins. Given that one is heads, what&#39;s the probability the other one is heads?

Surprisingly, it&#39;s not $\frac12$.', u'owner': {u'user_id': 191074, u'user_type': u'registered', u'reputation': 682, u'link': u'https://math.stackexchange.com/users/191074/theonlygusti', u'accept_rate': 43, u'display_name': u'theonlygusti', u'badge_counts': {u'bronze': 15, u'silver': 5, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2141728', u'answer_id': 2141728}, {u'up_vote_count': 4, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1487013151, u'comments': [{u'edited': False, u'comment_id': 4406870, u'creation_date': 1486999521, u'post_id': 2141955, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 67842, u'user_type': u'registered', u'reputation': 8473, u'link': u'https://math.stackexchange.com/users/67842/glen-o', u'display_name': u'Glen O', u'badge_counts': {u'bronze': 28, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141955#comment4406870_2141955'}, {u'edited': False, u'reply_to_user': {u'user_id': 67842, u'user_type': u'registered', u'reputation': 8473, u'link': u'https://math.stackexchange.com/users/67842/glen-o', u'display_name': u'Glen O', u'badge_counts': {u'bronze': 28, u'silver': 14, u'gold': 0}}, u'comment_id': 4407599, u'creation_date': 1487013215, u'post_id': 2141955, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 254665, u'user_type': u'registered', u'reputation': 30478, u'link': u'https://math.stackexchange.com/users/254665/danielwainfleet', u'accept_rate': 91, u'display_name': u'DanielWainfleet', u'badge_counts': {u'bronze': 39, u'silver': 14, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141955#comment4407599_2141955'}, {u'edited': False, u'comment_id': 4408544, u'creation_date': 1487031931, u'post_id': 2141955, u'score': 4, u'post_type': u'answer', u'owner': {u'user_id': 224454, u'user_type': u'registered', u'reputation': 24381, u'link': u'https://math.stackexchange.com/users/224454/brian-tung', u'display_name': u'Brian Tung', u'badge_counts': {u'bronze': 51, u'silver': 23, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141955#comment4408544_2141955'}, {u'edited': False, u'reply_to_user': {u'user_id': 224454, u'user_type': u'registered', u'reputation': 24381, u'link': u'https://math.stackexchange.com/users/224454/brian-tung', u'display_name': u'Brian Tung', u'badge_counts': {u'bronze': 51, u'silver': 23, u'gold': 2}}, u'comment_id': 4408570, u'creation_date': 1487032670, u'post_id': 2141955, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 254665, u'user_type': u'registered', u'reputation': 30478, u'link': u'https://math.stackexchange.com/users/254665/danielwainfleet', u'accept_rate': 91, u'display_name': u'DanielWainfleet', u'badge_counts': {u'bronze': 39, u'silver': 14, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141955#comment4408570_2141955'}], u'creation_date': 1486964015, u'comment_count': 4, u'score': 4, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2141955#2141955', u'body_markdown': u'The secretary&#39;s problem (which has other names).The secretary has $n$ letters  ($0&lt;n&lt;\infty$) and $n$ pre-addressed envelopes but puts the letters into the envelopes randomly, one letter per envelope. What is the chance $C(n)$ that NO letter gets into the right envelope?

 The answer is $C(n)=\sum_{j=0}^n(-1)^j/j!,$ which converges to $1/e$ as $n\to \infty$. I think  the method of solution is instructive.

 One counter-intuitive result is that $C(n)$ is not monotonic in $n.$

 Also many people would be inclined to guess that $C(n)&gt;1/2$ for large $n.$ 

Another version of this is to take two  shuffled decks, each with $n$ playing cards,  and ask for the chance that no card occupies the same position in both decks.

I first saw this in &quot;101 Great Problems In  Elementary Mathematics&quot; by H. Dorrie.', u'owner': {u'user_id': 254665, u'user_type': u'registered', u'reputation': 30478, u'link': u'https://math.stackexchange.com/users/254665/danielwainfleet', u'accept_rate': 91, u'display_name': u'DanielWainfleet', u'badge_counts': {u'bronze': 39, u'silver': 14, u'gold': 3}}, u'is_accepted': False, u'last_edit_date': 1487013151, u'share_link': u'https://math.stackexchange.com/a/2141955', u'answer_id': 2141955}, {u'up_vote_count': 6, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1486968497, u'comments': [{u'edited': False, u'comment_id': 4405874, u'creation_date': 1486971742, u'post_id': 2142005, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 40119, u'user_type': u'registered', u'reputation': 25123, u'link': u'https://math.stackexchange.com/users/40119/littleo', u'accept_rate': 50, u'display_name': u'littleO', u'badge_counts': {u'bronze': 97, u'silver': 37, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142005#comment4405874_2142005'}, {u'edited': False, u'reply_to_user': {u'user_id': 40119, u'user_type': u'registered', u'reputation': 25123, u'link': u'https://math.stackexchange.com/users/40119/littleo', u'accept_rate': 50, u'display_name': u'littleO', u'badge_counts': {u'bronze': 97, u'silver': 37, u'gold': 5}}, u'comment_id': 4405918, u'creation_date': 1486973309, u'post_id': 2142005, u'score': 0, u'post_type': u'answer', u'owner': {u'display_name': u'user410372', u'user_type': u'does_not_exist'}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142005#comment4405918_2142005'}, {u'edited': False, u'comment_id': 4405980, u'creation_date': 1486975372, u'post_id': 2142005, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 40119, u'user_type': u'registered', u'reputation': 25123, u'link': u'https://math.stackexchange.com/users/40119/littleo', u'accept_rate': 50, u'display_name': u'littleO', u'badge_counts': {u'bronze': 97, u'silver': 37, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142005#comment4405980_2142005'}, {u'edited': False, u'reply_to_user': {u'user_id': 40119, u'user_type': u'registered', u'reputation': 25123, u'link': u'https://math.stackexchange.com/users/40119/littleo', u'accept_rate': 50, u'display_name': u'littleO', u'badge_counts': {u'bronze': 97, u'silver': 37, u'gold': 5}}, u'comment_id': 4405988, u'creation_date': 1486975697, u'post_id': 2142005, u'score': 1, u'post_type': u'answer', u'owner': {u'display_name': u'user410372', u'user_type': u'does_not_exist'}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142005#comment4405988_2142005'}, {u'edited': False, u'comment_id': 4406011, u'creation_date': 1486976643, u'post_id': 2142005, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 40119, u'user_type': u'registered', u'reputation': 25123, u'link': u'https://math.stackexchange.com/users/40119/littleo', u'accept_rate': 50, u'display_name': u'littleO', u'badge_counts': {u'bronze': 97, u'silver': 37, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142005#comment4406011_2142005'}, {u'edited': False, u'comment_id': 4406018, u'creation_date': 1486976874, u'post_id': 2142005, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 397623, u'user_type': u'registered', u'reputation': 109, u'link': u'https://math.stackexchange.com/users/397623/jollyjoker', u'display_name': u'JollyJoker', u'badge_counts': {u'bronze': 3, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142005#comment4406018_2142005'}, {u'edited': False, u'reply_to_user': {u'user_id': 40119, u'user_type': u'registered', u'reputation': 25123, u'link': u'https://math.stackexchange.com/users/40119/littleo', u'accept_rate': 50, u'display_name': u'littleO', u'badge_counts': {u'bronze': 97, u'silver': 37, u'gold': 5}}, u'comment_id': 4406073, u'creation_date': 1486978099, u'post_id': 2142005, u'score': 0, u'post_type': u'answer', u'owner': {u'display_name': u'user410372', u'user_type': u'does_not_exist'}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142005#comment4406073_2142005'}, {u'edited': False, u'reply_to_user': {u'user_id': 397623, u'user_type': u'registered', u'reputation': 109, u'link': u'https://math.stackexchange.com/users/397623/jollyjoker', u'display_name': u'JollyJoker', u'badge_counts': {u'bronze': 3, u'silver': 0, u'gold': 0}}, u'comment_id': 4406081, u'creation_date': 1486978243, u'post_id': 2142005, u'score': 1, u'post_type': u'answer', u'owner': {u'display_name': u'user410372', u'user_type': u'does_not_exist'}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142005#comment4406081_2142005'}, {u'edited': False, u'comment_id': 4406091, u'creation_date': 1486978669, u'post_id': 2142005, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 397623, u'user_type': u'registered', u'reputation': 109, u'link': u'https://math.stackexchange.com/users/397623/jollyjoker', u'display_name': u'JollyJoker', u'badge_counts': {u'bronze': 3, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142005#comment4406091_2142005'}, {u'edited': False, u'comment_id': 4406640, u'creation_date': 1486995090, u'post_id': 2142005, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 278700, u'user_type': u'registered', u'reputation': 465, u'link': u'https://math.stackexchange.com/users/278700/aalok', u'display_name': u'Aalok', u'badge_counts': {u'bronze': 10, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142005#comment4406640_2142005'}], u'creation_date': 1486968497, u'comment_count': 10, u'score': 6, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142005#2142005', u'body_markdown': u'It&#39;s not counter intuitive  but it&#39;s amazing for teaching in class.

Pick $a,b \in [n]$ randomly. $\mathbb{P}[gcd(a,b)=1]$ tends to $\frac{6}{\pi^2}$ as $n$ goes to infinity.

Also, there is some other interesting problem whose answers have $\pi , e ,...$', u'owner': {u'display_name': u'user410372', u'user_type': u'does_not_exist'}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2142005', u'answer_id': 2142005}, {u'up_vote_count': 14, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1486983433, u'comments': [{u'edited': False, u'comment_id': 4409021, u'creation_date': 1487045621, u'post_id': 2142067, u'score': 4, u'post_type': u'answer', u'owner': {u'user_id': 276406, u'user_type': u'registered', u'reputation': 2507, u'link': u'https://math.stackexchange.com/users/276406/wildcard', u'display_name': u'Wildcard', u'badge_counts': {u'bronze': 27, u'silver': 7, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142067#comment4409021_2142067'}, {u'edited': False, u'reply_to_user': {u'user_id': 276406, u'user_type': u'registered', u'reputation': 2507, u'link': u'https://math.stackexchange.com/users/276406/wildcard', u'display_name': u'Wildcard', u'badge_counts': {u'bronze': 27, u'silver': 7, u'gold': 0}}, u'comment_id': 4409110, u'creation_date': 1487050193, u'post_id': 2142067, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 128946, u'user_type': u'registered', u'reputation': 509, u'link': u'https://math.stackexchange.com/users/128946/abcdexter', u'accept_rate': 100, u'display_name': u'ABcDexter', u'badge_counts': {u'bronze': 21, u'silver': 6, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142067#comment4409110_2142067'}], u'creation_date': 1486972996, u'comment_count': 2, u'score': 14, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142067#2142067', u'body_markdown': u'[Base rate fallacy][1]
--
If presented with related base rate information (or generic information) and specific information (information only pertaining to a certain case), the mind tends to ignore the former and focus on the latter.

**Example**:  
A group of police officers have breathalyzers displaying false drunkenness in 5% of the cases in which the driver is sober. However, the breathalyzers never fail to detect a truly drunk person. One in a thousand drivers is driving drunk. Suppose the police officers then stop a driver at random, and force the driver to take a breathalyzer test. It indicates that the driver is drunk. We assume you don&#39;t know anything else about him or her. How high is the probability he or she really is drunk?  

Intuitive first answer might be as high as 0.95, but the correct probability is about 0.02.

Solution :
Using [Bayes&#39;s theorem][2].   

The goal is to find the probability that the driver is drunk given that the breathalyzer indicated he/she is drunk, which can be represented as
$${\displaystyle p(\mathrm {drunk} |D)}$$  
where &quot;**D**&quot; means that the breathalyzer indicates that the driver is drunk.    

Bayes&#39;s theorem tells us that
  
$$ {\displaystyle p(\mathrm {drunk} |D) = {\frac {p(D|\mathrm {drunk} )\,  
p(\mathrm {drunk} )}{p(D)}}}     
$$

We were told the following in the first paragraph:

$${\displaystyle p(\mathrm {drunk} )=0.001}   $$
$${\displaystyle p(\mathrm {sober} )=0.999}   $$
$${\displaystyle p(D|\mathrm {drunk} )=1.00}   $$
$${\displaystyle p(D|\mathrm {sober} )=0.05} $$


As you can see from the formula, one needs p(D) for Bayes&#39; theorem, which one can compute from the preceding values using  
$${\displaystyle p(D)=p(D|\mathrm {drunk} )\,p(\mathrm {drunk} )+p(D|\mathrm {sober} )\,p(\mathrm {sober} )} $$

 
which gives
$$
{\displaystyle p(D)=(1.00\times 0.001)+(0.05\times 0.999)=0.05095} $$

Plugging these numbers into Bayes&#39; theorem, one finds that
$$ {\displaystyle p(\mathrm {drunk} |D)={\frac {1.00\times 0.001}{0.05095}}=0.019627  \approx 0.02 } $$

---

A more intuitive explanation: on average, for every 1,000 drivers tested,
1 driver is drunk, and it is 100% certain that for that driver there is a true positive test result, so there is 1 true positive test result
999 drivers are not drunk, and among those drivers there are 5% false positive test results, so there are 49.95 false positive test results.  
Therefore, the probability that one of the drivers among the $$1 + 49.95 = 50.95 $$positive test results really is drunk is
$$ {\displaystyle p(\mathrm {drunk} |D)=1/50.95\approx 0.019627}  $$


  [1]: https://en.wikipedia.org/wiki/Base_rate_fallacy
  [2]: https://en.wikipedia.org/wiki/Bayes%27_theorem', u'owner': {u'user_id': 128946, u'user_type': u'registered', u'reputation': 509, u'link': u'https://math.stackexchange.com/users/128946/abcdexter', u'accept_rate': 100, u'display_name': u'ABcDexter', u'badge_counts': {u'bronze': 21, u'silver': 6, u'gold': 0}}, u'is_accepted': False, u'last_edit_date': 1486983433, u'share_link': u'https://math.stackexchange.com/a/2142067', u'answer_id': 2142067}, {u'up_vote_count': 5, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1486995027, u'comments': [{u'edited': False, u'comment_id': 4407597, u'creation_date': 1487013203, u'post_id': 2142261, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 377514, u'user_type': u'registered', u'reputation': 239, u'link': u'https://math.stackexchange.com/users/377514/ttw', u'display_name': u'ttw', u'badge_counts': {u'bronze': 2, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142261#comment4407597_2142261'}, {u'edited': False, u'reply_to_user': {u'user_id': 377514, u'user_type': u'registered', u'reputation': 239, u'link': u'https://math.stackexchange.com/users/377514/ttw', u'display_name': u'ttw', u'badge_counts': {u'bronze': 2, u'silver': 2, u'gold': 0}}, u'comment_id': 5794556, u'creation_date': 1528298365, u'post_id': 2142261, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 7933, u'user_type': u'registered', u'reputation': 127018, u'link': u'https://math.stackexchange.com/users/7933/thomas-andrews', u'accept_rate': 91, u'display_name': u'Thomas Andrews', u'badge_counts': {u'bronze': 283, u'silver': 143, u'gold': 10}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142261#comment5794556_2142261'}], u'creation_date': 1486985916, u'comment_count': 2, u'score': 5, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142261#2142261', u'body_markdown': u'In contract bridge, there is the principle of restricted choice.  It&#39;s always seemed counterintuitive to me.

https://en.m.wikipedia.org/wiki/Principle_of_restricted_choice', u'owner': {u'user_id': 191319, u'user_type': u'registered', u'reputation': 151, u'link': u'https://math.stackexchange.com/users/191319/walter-mitty', u'display_name': u'Walter Mitty', u'badge_counts': {u'bronze': 4, u'silver': 0, u'gold': 0}}, u'is_accepted': False, u'last_edit_date': 1486995027, u'share_link': u'https://math.stackexchange.com/a/2142261', u'answer_id': 2142261}, {u'up_vote_count': 5, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 2, u'last_activity_date': 1487112713, u'comments': [{u'edited': False, u'comment_id': 4407001, u'creation_date': 1487001439, u'post_id': 2142409, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 67842, u'user_type': u'registered', u'reputation': 8473, u'link': u'https://math.stackexchange.com/users/67842/glen-o', u'display_name': u'Glen O', u'badge_counts': {u'bronze': 28, u'silver': 14, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142409#comment4407001_2142409'}, {u'edited': False, u'comment_id': 4408407, u'creation_date': 1487028276, u'post_id': 2142409, u'score': 5, u'post_type': u'answer', u'owner': {u'user_id': 34930, u'user_type': u'registered', u'reputation': 27897, u'link': u'https://math.stackexchange.com/users/34930/celtschk', u'accept_rate': 78, u'display_name': u'celtschk', u'badge_counts': {u'bronze': 95, u'silver': 53, u'gold': 6}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142409#comment4408407_2142409'}], u'creation_date': 1486994263, u'comment_count': 2, u'score': 3, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2142409#2142409', u'body_markdown': u'One of the most puzzling results in probability is that the probability of randomly (and with uniform probability) picking a rational number among the set of reals is zero. This is nicely explained [here](http://mathforum.org/library/drmath/view/55676.html).

The set of rational numbers, for instance in the $\Omega=[0,1]$ interval is the *countable* union of disjoint singletons, and each one of these singletons has a probability of zero. Here is the proof:

---

A singleton, $\{b\}$, is a Borel measurable set with a Lebesgue measure of zero. The proof is as follows:

$$\Pr\left(\{b\}\right)=\Pr\left(\bigcap_{n=1}^\infty\left(b-\frac{1}{n},b + \frac{1}{n}\right]\cap \Omega\right)$$

is the probability of nested decreasing sets, allowing the use of the theorem of continuity of probability measures $(*)$ to re-write it as:

$$\Pr\left(\{b\}\right)=\lim_{n\rightarrow \infty}\,\Pr\left(\left(b-\frac{1}{n},b + \frac{1}{n}\right]\cap \Omega\right)$$

The probability of $$\Pr\left(b-\frac{1}{n},\,b + \frac{1}{n} \right)\leq \lim_{n\rightarrow \infty}\frac{2}{n}=0$$

---

Therefore, by countable additivity of measures $(**)$, the probability for the whole set of $\mathbb Q$ is zero:

$$\Pr(\mathbb Q\;\cap \Omega) = 0$$

The apparent paradox is that despite the infinity number of rational numbers in the $[0,1]$ interval, the probability of randomly choosing a rational is strictly zero.

The source is this great explanation [here](https://youtu.be/I3zwALG19Zk?list=PLbMVogVj5nJQqGHrpAloTec_lOKsG-foc).

---

$(*)$ If $B_j, j = 1, 2,\cdots,$ is a sequence of events decreasing to $B$, then
$\displaystyle\lim_{n\rightarrow \infty} \Pr \{B_n\} = \Pr \{B\} .$

$(**)$ For all countable collections $\{E_i\}_{i=1}^\infty$ of pairwise disjoint sets in a sigma algebra: $$\mu\left( \bigcup_{k=1}^\infty \, E_k \right)=\sum_{k=1}^\infty \mu(E_k).$$', u'owner': {u'user_id': 152225, u'user_type': u'registered', u'reputation': 2573, u'link': u'https://math.stackexchange.com/users/152225/mathasfun', u'accept_rate': 73, u'display_name': u'MathAsFun', u'badge_counts': {u'bronze': 32, u'silver': 11, u'gold': 1}}, u'is_accepted': False, u'last_edit_date': 1487112713, u'share_link': u'https://math.stackexchange.com/a/2142409', u'answer_id': 2142409}, {u'up_vote_count': 7, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1487057121, u'comments': [{u'edited': False, u'comment_id': 4408870, u'creation_date': 1487040987, u'post_id': 2143309, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 38671, u'user_type': u'registered', u'reputation': 293, u'link': u'https://math.stackexchange.com/users/38671/anders-kaseorg', u'display_name': u'Anders Kaseorg', u'badge_counts': {u'bronze': 6, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2143309#comment4408870_2143309'}, {u'edited': False, u'reply_to_user': {u'user_id': 38671, u'user_type': u'registered', u'reputation': 293, u'link': u'https://math.stackexchange.com/users/38671/anders-kaseorg', u'display_name': u'Anders Kaseorg', u'badge_counts': {u'bronze': 6, u'silver': 2, u'gold': 0}}, u'comment_id': 4409297, u'creation_date': 1487057034, u'post_id': 2143309, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 224454, u'user_type': u'registered', u'reputation': 24381, u'link': u'https://math.stackexchange.com/users/224454/brian-tung', u'display_name': u'Brian Tung', u'badge_counts': {u'bronze': 51, u'silver': 23, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2143309#comment4409297_2143309'}, {u'edited': False, u'comment_id': 4409302, u'creation_date': 1487057147, u'post_id': 2143309, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 195683, u'user_type': u'registered', u'reputation': 3349, u'link': u'https://math.stackexchange.com/users/195683/leila', u'accept_rate': 96, u'display_name': u'Leila', u'badge_counts': {u'bronze': 54, u'silver': 26, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2143309#comment4409302_2143309'}], u'creation_date': 1487032573, u'comment_count': 3, u'score': 7, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2143309#2143309', u'body_markdown': u'Someone mentioned non-transitive dice, and that reminded me of this one:

&gt; Suppose there are two unweighted six-sided dice that you cannot
&gt; examine, but which you can direct a machine to roll and inform you of
&gt; the sum.  You can do this as often as you like, and the distribution
&gt; of the sum is exactly what you would expect of a pair of ordinary
&gt; six-sided dice.
&gt; 
&gt; Are they, in fact, a pair of ordinary six-sided dice?

[Not necessarily](https://en.wikipedia.org/wiki/Sicherman_dice).

Then someone mentioned a secretary problem, which turned out to be about derangements.  I had in mind a different secretary&#39;s problem, which is also called the sultan&#39;s dowry:

&gt; You have $100$ candidates, upon which there exists a total order.  The
&gt; candidates have appointments with you, one at a
&gt; time, in a random order. 
&gt; From each interview, you can tell exactly how that candidate ranks
&gt; amongst those you have already examined.  At that point, you may
&gt; either accept or reject the candidate.  Any acceptance or rejection is
&gt; permanent; no candidate, once rejected, may be reconsidered.  Your
&gt; objective is solely to accept the best candidate.  What is the
&gt; strategy for maximizing your probability of doing so, and what is that
&gt; probability?

As often happens in probability puzzles, [the answer is $1/e$](https://en.wikipedia.org/wiki/Secretary_problem)*, which many people find surprisingly high.

---

*Approximately, with the approximation getting better and better as the number of candidates increases without bound.', u'owner': {u'user_id': 224454, u'user_type': u'registered', u'reputation': 24381, u'link': u'https://math.stackexchange.com/users/224454/brian-tung', u'display_name': u'Brian Tung', u'badge_counts': {u'bronze': 51, u'silver': 23, u'gold': 2}}, u'is_accepted': False, u'last_edit_date': 1487057121, u'share_link': u'https://math.stackexchange.com/a/2143309', u'answer_id': 2143309}, {u'up_vote_count': 6, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1487034799, u'comments': [{u'edited': False, u'comment_id': 4519882, u'creation_date': 1490110871, u'post_id': 2143336, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 224454, u'user_type': u'registered', u'reputation': 24381, u'link': u'https://math.stackexchange.com/users/224454/brian-tung', u'display_name': u'Brian Tung', u'badge_counts': {u'bronze': 51, u'silver': 23, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2143336#comment4519882_2143336'}, {u'edited': False, u'reply_to_user': {u'user_id': 224454, u'user_type': u'registered', u'reputation': 24381, u'link': u'https://math.stackexchange.com/users/224454/brian-tung', u'display_name': u'Brian Tung', u'badge_counts': {u'bronze': 51, u'silver': 23, u'gold': 2}}, u'comment_id': 4568097, u'creation_date': 1491495708, u'post_id': 2143336, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 210401, u'user_type': u'registered', u'reputation': 6836, u'link': u'https://math.stackexchange.com/users/210401/david-g-stork', u'accept_rate': 29, u'display_name': u'David G. Stork', u'badge_counts': {u'bronze': 27, u'silver': 7, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2143336#comment4568097_2143336'}], u'creation_date': 1487033892, u'comment_count': 2, u'score': 6, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2143336#2143336', u'body_markdown': u'**Lake Wobegon Dice**

Find a set of $n$ dice (each with $s$ sides, numbered appropriately), in which *each* die is more likely to roll above the set average on that roll than below the set average.  Given $n$, find the *Lake Wobegon Optimal* set, in which that probability is maximum.

&quot;[Lake Wobegon Dice][1],&quot; by Jorge Moraleda and David G. Stork, *College Mathematics Journal*, **43**(2):152--159 (2012)

Abstract:

 - We present sets of $n$ non-standard dice‚ÄîLake Wobegon dice‚Äîhaving the
   following paradoxical property: On every (random) roll of a set, each
   die is more likely to roll greater than the set average than less
   than the set average; in a specific statistical sense, then, each die
   is ‚Äúbetter than the set average.‚Äù
   
   We define the Lake Wobegon Dominance of a die in a set as the
   probability the die rolls greater than the set average minus the
   probability the die rolls less than the set average. We further
   define the Lake Wobegon Dominance *of the set* to be the dominance of
   the set‚Äôs least dominant die and prove that such paradoxical
   dominance is bounded above by $(n-2)/n$ regardless of the number of
   sides $s$ on each die and the maximum number of pips $p$ on each
   side.  A set achieving this bound is called *Lake Wobegon Optimal*.  We
   give a constructive proof that Lake Wobegon Optimal sets exist for
   all $n \ge 3$ if one is free to choose $s$ and $p$.  We also show how
   to construct minimal optimal sets, that is, that set that requires
   the smallest range in the number of pips on the faces.
   
   We determine the frequency of such Lake Wobegon sets in the $n = 3$
   case through exhaustive computer search and find the unique optimal
   $n = 3$ set having minimal $s$ and $p$. We investigate symmetry
   properties of such sets, and present equivalence classes having
   identical paradoxical dominance.  We construct inverse sets, in which
   on any roll each die is more likely to roll less than the set average
   than greater than the set average, and thus each die is ‚Äúworse than
   the set average.‚Äù  We show the unique extreme ‚Äúworst‚Äù case, the Lake
   Wobegon pessimal set.

[![enter image description here][2]][2]

  [1]: http://www.jstor.org/stable/10.4169/college.math.j.43.2.152?seq=1#page_scan_tab_contents
  [2]: https://i.stack.imgur.com/tCVHb.png', u'owner': {u'user_id': 210401, u'user_type': u'registered', u'reputation': 6836, u'link': u'https://math.stackexchange.com/users/210401/david-g-stork', u'accept_rate': 29, u'display_name': u'David G. Stork', u'badge_counts': {u'bronze': 27, u'silver': 7, u'gold': 2}}, u'is_accepted': False, u'last_edit_date': 1487034799, u'share_link': u'https://math.stackexchange.com/a/2143336', u'answer_id': 2143336}, {u'up_vote_count': 10, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1487418355, u'comments': [{u'edited': False, u'comment_id': 4416303, u'creation_date': 1487240465, u'post_id': 2146944, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 341019, u'user_type': u'registered', u'reputation': 18033, u'link': u'https://math.stackexchange.com/users/341019/especially-lime', u'display_name': u'Especially Lime', u'badge_counts': {u'bronze': 50, u'silver': 20, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2146944#comment4416303_2146944'}, {u'edited': False, u'comment_id': 4421827, u'creation_date': 1487409428, u'post_id': 2146944, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2146944#comment4421827_2146944'}, {u'edited': False, u'comment_id': 4422050, u'creation_date': 1487418497, u'post_id': 2146944, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 196523, u'user_type': u'registered', u'reputation': 1134, u'link': u'https://math.stackexchange.com/users/196523/mirek-ol%c5%a1%c3%a1k', u'display_name': u'Mirek Ol\u0161&#225;k', u'badge_counts': {u'bronze': 10, u'silver': 3, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2146944#comment4422050_2146944'}, {u'edited': False, u'comment_id': 4468963, u'creation_date': 1488715010, u'post_id': 2146944, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2146944#comment4468963_2146944'}], u'creation_date': 1487238378, u'comment_count': 4, u'score': 10, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2146944#2146944', u'body_markdown': u'I have also had a lecture on this excellent topic.

Unfortunately, my [lecture notes](http://mks.mff.cuni.cz/library/PravdepodobnostniParadoxyMO/PravdepodobnostniParadoxyMO.pdf) are in Czech, but I can translate some paradoxes from there:

**[Monty Hall](https://en.wikipedia.org/wiki/Monty_Hall_problem)**

Monty Hall is in my opinion the most famous probabilistic paradox. It is described here and on the Wiki well. So I just provide you a way how to make it feel intuitive, to persuade other people that the real probability is computed correctly. It is quite impressive, almost like a magician trick :-)

Take a pack of cards and let someone draw a random card. Tell him that he want to draw the ace of hearts and he should not look on the chosen card. Then show to audience all remaining cards but one which are not the ace of hearts. So then there are two hidden cards: One in your hand and one in his hand. Finally, he may change his first guess. Most people do it and they are most likely correct :-).

**Tennis-like game**

There are two players, Alice and Bob, playing a tennis-like game. Every time, one player serves the ball and winning probabilities of the ball depends on the player. Player who first reaches say 11 points wins the match.
Alice serves the first ball. Then there are three possible schemes:

 1. The winner of the previous ball serves the next.
 2. The loser of the previous ball serves the next.
 3. Service is regularly alternating.

One would expect that scheme 1. helps stronger players and scheme 2 helps weaker players. The paradox is that winning probabilities of the match do not depend on the chosen scheme.

Proof sketch: Pregenerate 11 cards with the winner of Alice services (pack A) and 10 cards with the winner of Bob&#39;s service (pack B). Then each Alice&#39;s (or Bob&#39;s) service can be modeled just by drawing a card from the pack A (or B). It can be shown that these 21 cards suffice for any of these 3 presented schemes. And the winner is determined by the cards: there is exactly one player written on at least 11 cards.

**Candies**

I have a bag of candies, there are 123 caramel candies and 321 mint candies. Every morning I randomly draw candies from the pack and eat them while they are all the same. When I take a different kind of candy, I return it back. What is the probability that the last eaten candy will be the caramel one?

Answer: 1/2. (one would expect that it is less than 1/2 since there are less caramel candies)

Proof: It suffices to show that every morning the probability that all caramel candies will be eaten is the same as the probability that all mint candies will be eaten. We can imagine that candies are randomly ordered every morning and I am drawing them from left to right. I eat all caramel candies if the order is &quot;First caramel candies, then mint ones.&quot;. I eat all mint candies if the order is the opposite.

**Wolf on a circle**

There is a wolf at one vertex of a regular n-gon. There is a sheep at every remaining vertex. Each step, the wolf moves to a randomly chosen adjacent vertex and if there is a sheep, the wolf eat it. The wolf ends when it eats n-2 sheep (so there remains just one sheep).

Intuitively, the sheep at the opposite vertex from the wolf is in the best position. The paradox is that all sheep have the same probability of survival.

Proof: Take one sheep S. The wolf will definitely get to an adjacent vertex to S for the first time. This time the sheep on the other adjacent vertex is still not eaten. So for S survival, the wolf have to go around the whole circle without eating S. The probability of going around the whole circle from one vertex adjacent to S to the other without visiting S does not depend on the position of S.

**[Simpson&#39;s Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox)**

There is a research on two medical cures A, B.

200 people tried the cure A, it helped to 110 people (50 men, 60 women) and did not helped to 90 people (60 men, 30 women).

210 people tried the cure B, it helped to 120 people (30 men and 90 women) and did not helped to 90 people (40 men, 50 women).

So in general, the cure B is better since 120:90 &gt; 110:90.

But if you are a man, you can consider just men statistics: 50:60 &gt; 30:40, so the cure A is more appropriate.

And if you are a woman, you can consider just women statistics: 60:30 &gt; 90:50, so the cure A is again more appropriate.

Shocking, isn&#39;t it? :-)', u'owner': {u'user_id': 196523, u'user_type': u'registered', u'reputation': 1134, u'link': u'https://math.stackexchange.com/users/196523/mirek-ol%c5%a1%c3%a1k', u'display_name': u'Mirek Ol≈°&#225;k', u'badge_counts': {u'bronze': 10, u'silver': 3, u'gold': 0}}, u'is_accepted': False, u'last_edit_date': 1487418355, u'share_link': u'https://math.stackexchange.com/a/2146944', u'answer_id': 2146944}, {u'up_vote_count': 6, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1487255741, u'creation_date': 1487255741, u'comment_count': 0, u'score': 6, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147248#2147248', u'body_markdown': u'There&#39;s the [**two envelopes paradox**](https://en.wikipedia.org/wiki/Two_envelopes_problem). Wikipedia states it as follows:

&gt; You are given two indistinguishable envelopes, each containing money, one contains twice as much as the other. You may pick one envelope and keep the money it contains. Having chosen an envelope at will, but before inspecting it, you are given the chance to switch envelopes. Should you switch?

The issue is that there is an amount $X$ of money in the envelope you have. If it&#39;s the lesser amount then switching gives you a reward of $2X$ and if you don&#39;t then you only get $X/2$. Since both cases are equally likely, it seems that you should switch, even though that is nonsensical since clearly your chance of getting the larger amount can only ever be 50%.

The Wikipedia article goes into great depth explaining various resolutions of this fallacy. It boils down to the fact that the sum of the two envelopes is the same in both cases, which means that the $X$s considered above aren&#39;t actually identical.

A related problem is the [**necktie paradox**](https://en.wikipedia.org/wiki/Necktie_paradox).', u'owner': {u'user_id': 50421, u'user_type': u'registered', u'reputation': 2852, u'link': u'https://math.stackexchange.com/users/50421/martin-ender', u'accept_rate': 60, u'display_name': u'Martin Ender', u'badge_counts': {u'bronze': 25, u'silver': 13, u'gold': 4}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2147248', u'answer_id': 2147248}, {u'up_vote_count': 4, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1487262178, u'comments': [{u'edited': False, u'comment_id': 4802322, u'creation_date': 1498155502, u'post_id': 2147403, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 256001, u'user_type': u'registered', u'reputation': 53185, u'link': u'https://math.stackexchange.com/users/256001/bram28', u'accept_rate': 75, u'display_name': u'Bram28', u'badge_counts': {u'bronze': 76, u'silver': 34, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147403#comment4802322_2147403'}, {u'edited': False, u'comment_id': 5794539, u'creation_date': 1528298126, u'post_id': 2147403, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 7933, u'user_type': u'registered', u'reputation': 127018, u'link': u'https://math.stackexchange.com/users/7933/thomas-andrews', u'accept_rate': 91, u'display_name': u'Thomas Andrews', u'badge_counts': {u'bronze': 283, u'silver': 143, u'gold': 10}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147403#comment5794539_2147403'}], u'creation_date': 1487262178, u'comment_count': 2, u'score': 4, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147403#2147403', u'body_markdown': u'I see the Monty Hall has been mentioned a couple of times, but I want to mention it again because I think the reason that it&#39;s interesting is missed in the other answers.  In particular, it demonstrates not only a counter-intuitive result for a given formulation, but it also demonstrates how sensitive the correct answer is to the formulation of the problem.  I especially like this NYT article as an illustration:

http://www.nytimes.com/1991/07/21/us/behind-monty-hall-s-doors-puzzle-debate-and-answer.html?pagewanted=all

From a teaching point of view, this is a fun exercise because Monty Hall (the real person) is part of the article, and he plays a role both in validating the math on the &quot;academic&quot; version of the problem and in showing the math is meaningless in the real game because he has controls that are not in academic version. Moreover, after years of doing the show, he&#39;s good at reading individual contestants, so probability is not really at play in a significant way.', u'owner': {u'user_id': 263389, u'user_type': u'registered', u'reputation': 1172, u'link': u'https://math.stackexchange.com/users/263389/brick', u'display_name': u'Brick', u'badge_counts': {u'bronze': 19, u'silver': 6, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2147403', u'answer_id': 2147403}, {u'up_vote_count': 7, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1528586078, u'creation_date': 1487284392, u'comment_count': 0, u'score': 7, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147927#2147927', u'body_markdown': u'This is one of my favorites:

[**100 prisoners problem**][1]


  [1]: https://en.wikipedia.org/wiki/100_prisoners_problem


&gt; The director of a prison offers 100 death row prisoners, who are
&gt; numbered from 1 to 100, a last chance. A room contains a cupboard with
&gt; 100 drawers. The director randomly puts one prisoner&#39;s number in each
&gt; closed drawer. The prisoners enter the room, one after another. Each
&gt; prisoner may open and look into 50 drawers in any order. The drawers
&gt; are closed again afterwards. If, during this search, every prisoner
&gt; finds his number in one of the drawers, all prisoners are pardoned. If
&gt; just one prisoner does not find his number, all prisoners die. Before
&gt; the first prisoner enters the room, the prisoners may discuss
&gt; strategy‚Äîbut may not communicate once the first prisoner enters to
&gt; look in the drawers.
&gt; 
&gt; If every prisoner selects $50$ drawers at random, the probability that
&gt; a single prisoner finds his number is $50\%$. Therefore, the
&gt; probability that all prisoners find their numbers is the product of
&gt; the single probabilities, which is $1/2^{100} \approx
 0.0000000000000000000000000000008$, a vanishingly small number. The situation appears hopeless.
&gt; 
&gt; Up to which value can prisoners improve the probability of being
&gt; pardoned using a good strategy?
  ', u'owner': {u'user_id': 190941, u'user_type': u'registered', u'reputation': 439, u'link': u'https://math.stackexchange.com/users/190941/suitangi', u'display_name': u'suitangi', u'badge_counts': {u'bronze': 6, u'silver': 2, u'gold': 0}}, u'is_accepted': False, u'last_edit_date': 1528586078, u'share_link': u'https://math.stackexchange.com/a/2147927', u'answer_id': 2147927}, {u'up_vote_count': 2, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 1, u'last_activity_date': 1487285780, u'comments': [{u'edited': False, u'comment_id': 4588046, u'creation_date': 1492026346, u'post_id': 2147953, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 190941, u'user_type': u'registered', u'reputation': 439, u'link': u'https://math.stackexchange.com/users/190941/suitangi', u'display_name': u'suitangi', u'badge_counts': {u'bronze': 6, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147953#comment4588046_2147953'}], u'creation_date': 1487285780, u'comment_count': 1, u'score': 1, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147953#2147953', u'body_markdown': u'I remember to be confused the first time this riddle was proposed to me:

&gt; What is the probability of getting a poker hand with at least two
&gt; aces, assuming that it contains at least one ace?
&gt; 
&gt; What if we know that it is indeed an ace of spades? does this
&gt; information change the probability?', u'owner': {u'user_id': 190941, u'user_type': u'registered', u'reputation': 439, u'link': u'https://math.stackexchange.com/users/190941/suitangi', u'display_name': u'suitangi', u'badge_counts': {u'bronze': 6, u'silver': 2, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2147953', u'answer_id': 2147953}, {u'up_vote_count': 7, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1487286522, u'creation_date': 1487286522, u'comment_count': 0, u'score': 7, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147967#2147967', u'body_markdown': u'**[The Shooting Room Paradox][1]**

&gt; A single person enters a room and two dice are rolled. If the result
&gt; is double sixes, he is shot. Otherwise he leaves the room and nine new
&gt; players enter. Again the dice are rolled, and if the result is double
&gt; sixes, all nine are shot. If not, they leave and 90 new players enter,
&gt; and so on (the number of players increasing tenfold with each round).
&gt; The game continues until double sixes are rolled and a group is
&gt; executed, which is certain to happen eventually (the room is
&gt; infinitely large, and there&#39;s an infinite supply of players).
&gt; 
&gt; If you&#39;re selected to enter the room, how worried should you be? Not
&gt; particularly: Your chance of dying is only 1 in 36. Later your mother
&gt; learns that you entered the room. How worried should she be?
&gt; Extremely: About 90 percent of the people who played this game were
&gt; shot. What does your mother know that you don&#39;t? Or vice versa?


  [1]: http://www.futilitycloset.com/2013/01/11/the-shooting-room/%20?utm_medium=referral&amp;utm_source=t.co', u'owner': {u'user_id': 190941, u'user_type': u'registered', u'reputation': 439, u'link': u'https://math.stackexchange.com/users/190941/suitangi', u'display_name': u'suitangi', u'badge_counts': {u'bronze': 6, u'silver': 2, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2147967', u'answer_id': 2147967}, {u'up_vote_count': 7, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1487334378, u'comments': [{u'edited': False, u'comment_id': 4419279, u'creation_date': 1487322288, u'post_id': 2147981, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 50421, u'user_type': u'registered', u'reputation': 2852, u'link': u'https://math.stackexchange.com/users/50421/martin-ender', u'accept_rate': 60, u'display_name': u'Martin Ender', u'badge_counts': {u'bronze': 25, u'silver': 13, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147981#comment4419279_2147981'}, {u'edited': False, u'reply_to_user': {u'user_id': 50421, u'user_type': u'registered', u'reputation': 2852, u'link': u'https://math.stackexchange.com/users/50421/martin-ender', u'accept_rate': 60, u'display_name': u'Martin Ender', u'badge_counts': {u'bronze': 25, u'silver': 13, u'gold': 4}}, u'comment_id': 4419588, u'creation_date': 1487334406, u'post_id': 2147981, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 30402, u'user_type': u'registered', u'reputation': 19192, u'link': u'https://math.stackexchange.com/users/30402/erick-wong', u'display_name': u'Erick Wong', u'badge_counts': {u'bronze': 65, u'silver': 24, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147981#comment4419588_2147981'}, {u'edited': False, u'comment_id': 4419599, u'creation_date': 1487334830, u'post_id': 2147981, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 50421, u'user_type': u'registered', u'reputation': 2852, u'link': u'https://math.stackexchange.com/users/50421/martin-ender', u'accept_rate': 60, u'display_name': u'Martin Ender', u'badge_counts': {u'bronze': 25, u'silver': 13, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147981#comment4419599_2147981'}, {u'edited': False, u'comment_id': 4421811, u'creation_date': 1487408523, u'post_id': 2147981, u'score': 3, u'post_type': u'answer', u'owner': {u'user_id': 29966, u'user_type': u'registered', u'reputation': 11036, u'link': u'https://math.stackexchange.com/users/29966/ben-millwood', u'accept_rate': 83, u'display_name': u'Ben Millwood', u'badge_counts': {u'bronze': 48, u'silver': 19, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147981#comment4421811_2147981'}, {u'edited': False, u'reply_to_user': {u'user_id': 29966, u'user_type': u'registered', u'reputation': 11036, u'link': u'https://math.stackexchange.com/users/29966/ben-millwood', u'accept_rate': 83, u'display_name': u'Ben Millwood', u'badge_counts': {u'bronze': 48, u'silver': 19, u'gold': 3}}, u'comment_id': 4421821, u'creation_date': 1487408963, u'post_id': 2147981, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147981#comment4421821_2147981'}], u'creation_date': 1487287208, u'comment_count': 5, u'score': 7, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2147981#2147981', u'body_markdown': u'One that I found surprising as a beginner was that three events (or random variables) can be independent pairwise, but not jointly independent.  Or to put it somewhat more strikingly, we can have $C$ independent of $A$ and independent of $B$, yet not independent of $A,B$.  Wording it this way shows that it does take care to state independence assumptions carefully, and it also illustrates some non-obvious subtleties in the definition of independence (one of them being that independence of two events does **not** mean that they don&#39;t interact and can&#39;t be influenced by a third factor).

One example of pairwise but non-mutual independence is given on the [Wikipedia page](https://en.wikipedia.org/wiki/Independence_(probability_theory)#Pairwise_and_mutual_independence).

The example that I typically use is to take $T$ to be a uniformly random angle in $[0,2\pi)$ and then consider the events $A = \{\sin T &gt; 0\}$, $B = \{ \cos T &gt; 0\}$ and $C = \{ \tan T &gt; 0 \}$ (effectively, this is just two independent $\pm 1$ variables and their product, but the trig formulation helps to visualize the events in terms of quadrants).

It&#39;s easy to see that $P(A)=P(B)=P(C) = \tfrac12$ and that $P(A\cap B) = P(A\cap C) = P(B\cap C) = \tfrac14$, but clearly $P(A\cap B\cap \overline C) = 0$.', u'owner': {u'user_id': 30402, u'user_type': u'registered', u'reputation': 19192, u'link': u'https://math.stackexchange.com/users/30402/erick-wong', u'display_name': u'Erick Wong', u'badge_counts': {u'bronze': 65, u'silver': 24, u'gold': 2}}, u'is_accepted': False, u'last_edit_date': 1487334378, u'share_link': u'https://math.stackexchange.com/a/2147981', u'answer_id': 2147981}, {u'up_vote_count': 5, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1505408705, u'comments': [{u'edited': False, u'comment_id': 5794576, u'creation_date': 1528298919, u'post_id': 2148225, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 7933, u'user_type': u'registered', u'reputation': 127018, u'link': u'https://math.stackexchange.com/users/7933/thomas-andrews', u'accept_rate': 91, u'display_name': u'Thomas Andrews', u'badge_counts': {u'bronze': 283, u'silver': 143, u'gold': 10}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2148225#comment5794576_2148225'}], u'creation_date': 1487302401, u'comment_count': 1, u'score': 5, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2148225#2148225', u'body_markdown': u'One I saw on Twitter recently, which is perhaps a clearer version of sex-of-children-type problems:

&gt; Three casino chips have a dot on each side: 

&gt; - on one chip the dots are both blue, 
- on the second there is a blue dot on one side and red on the other, and
- on the third the dots are both red. 

&gt; The chips are placed in a bag  and, without looking, you choose one and place it on the table. When you look at the chip, you see it has a blue dot on top. What is the probability that the dot on the other side is blue?

Many people will say $1/2$ - I did before I thought properly - but...

&gt;! you are blindly choosing both the chip, and which side to face up. So you have to consider that each dot has an equal chance of showing, making the chance $2/3$.', u'owner': {u'user_id': 206402, u'user_type': u'registered', u'reputation': 30832, u'link': u'https://math.stackexchange.com/users/206402/joffan', u'accept_rate': 82, u'display_name': u'Joffan', u'badge_counts': {u'bronze': 68, u'silver': 30, u'gold': 4}}, u'is_accepted': False, u'last_edit_date': 1505408705, u'share_link': u'https://math.stackexchange.com/a/2148225', u'answer_id': 2148225}, {u'up_vote_count': 5, u'title': u'Counterintuitive examples in probability', u'question_id': 2140493, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1487411276, u'comments': [{u'edited': False, u'comment_id': 4421847, u'creation_date': 1487410392, u'post_id': 2149806, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 29966, u'user_type': u'registered', u'reputation': 11036, u'link': u'https://math.stackexchange.com/users/29966/ben-millwood', u'accept_rate': 83, u'display_name': u'Ben Millwood', u'badge_counts': {u'bronze': 48, u'silver': 19, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2149806#comment4421847_2149806'}, {u'edited': False, u'comment_id': 4421856, u'creation_date': 1487410783, u'post_id': 2149806, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2149806#comment4421856_2149806'}, {u'edited': False, u'reply_to_user': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'comment_id': 4421864, u'creation_date': 1487411449, u'post_id': 2149806, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 29966, u'user_type': u'registered', u'reputation': 11036, u'link': u'https://math.stackexchange.com/users/29966/ben-millwood', u'accept_rate': 83, u'display_name': u'Ben Millwood', u'badge_counts': {u'bronze': 48, u'silver': 19, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2149806#comment4421864_2149806'}, {u'edited': False, u'comment_id': 4421870, u'creation_date': 1487411800, u'post_id': 2149806, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 21820, u'user_type': u'registered', u'reputation': 35101, u'link': u'https://math.stackexchange.com/users/21820/user21820', u'accept_rate': 48, u'display_name': u'user21820', u'badge_counts': {u'bronze': 134, u'silver': 38, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2149806#comment4421870_2149806'}], u'creation_date': 1487410152, u'comment_count': 4, u'score': 5, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability/2149806#2149806', u'body_markdown': u'**Optimizer&#39;s Curse:** suppose you have a number of options to choose from, each with some objective true value. You don&#39;t have access to the objective true value, but instead to a noisy estimate of it, say a value sampled from a normal distribution with mean the true value and variance $1$.

You, naturally, pick the choice whose estimate of true value is the highest. When you do so, you discover what the true value really was. Call the difference between the estimate and the true value your *post-decision surprise*.

Now, the error of your estimate was normally distributed with mean $0$, so you might also guess that your post-decision surprise will have mean $0$ ‚Äì sometimes you will be pleasantly surprised, sometimes disappointed. But in fact the post-decision surprise is usually negative, that is to say, you are usually disappointed by your choice!

In retrospect, this is perhaps not so surprising: certainly if all the true values were the same, you&#39;d simply pick the estimate with the highest inflation due to noise, and more generally, conditional on an estimate being the leader of a pack, it&#39;s more likely to be an overestimate than an underestimate.

More interestingly, if the variances *aren&#39;t* the same for all your estimates, it&#39;s no longer correct to just pick the highest estimate to maximise your expected true value. If the highest estimate is also high-variance, it may lead to a lower true value in expectation than a lower estimate with better precision, and so what looks superficially like some kind of risk-aversion (discounting the value of apparently high-variance options) is actually justifiable purely on expected-value grounds.

(Notice also that &quot;there a bunch of options with some true values, but you only get a noisy estimate of the true value, and you have to decide which to choose&quot; is a REALLY common situation to be in, so this problem is pretty pervasive in real life optimization scenarios)', u'owner': {u'user_id': 29966, u'user_type': u'registered', u'reputation': 11036, u'link': u'https://math.stackexchange.com/users/29966/ben-millwood', u'accept_rate': 83, u'display_name': u'Ben Millwood', u'badge_counts': {u'bronze': 48, u'silver': 19, u'gold': 3}}, u'is_accepted': False, u'last_edit_date': 1487411276, u'share_link': u'https://math.stackexchange.com/a/2149806', u'answer_id': 2149806}]","I want to teach a short course in probability and I&#39;m looking for some counterintuitive examples for it. Results that seems to be obviously false but they true or vice versa...

I already found some things. For example these two videos:

- [Penney&#39;s game][1]
- [How to win a guessing game][2]

In addition I have found some weird examples in random walks. For example this amazing theorem:

&gt; For a simple random walk, the mean number of visits to point $b$ before returning to  the origin is equal to $1$ for every $b \neq 0$.


Also I have found some advanced examples. such as [Do Longer Games Favor the Stronger Player][3] ?

Would you mind helping me to make a list of these phenomena? It&#39;s very exciting to read your examples...

  [1]: http://www.youtube.com/watch?v=Sa9jLWKrX0c
  [2]: https://www.youtube.com/watch?v=ud_frfkt1t0
  [3]: http://amstat.tandfonline.com/doi/abs/10.1080/00031305.1989.10475674","[The most famous counter-intuitive probability theory example is the [Monty Hall Problem](https://brilliant.org/wiki/monty-hall-problem/)

* In a game show, there are three doors behind which there are a car and two goats. However, which door conceals which is unknown to you, the player.
* Your aim is to select the door behind which the car is. So, you go and stand in front of a door of your choice.
* At this point, regardless of which door you selected, the game show host chooses and opens one of the remaining two doors. If you chose the door with the car, the host selects one of the two remaining doors at random (with equal probability) and opens that door. If you chose a door with a goat, the host selects and opens the other door with a goat.
* You are given the option of standing where you are and switching to the other closed door.

Does switching to the other door increase your chances of winning? Or does it not matter?

The answer is that it _does_ matter whether or not you switch. This is initially counter-intuitive for someone seeing this problem for the first time.

---

* If a family has two children, at least one of which is a daughter, what is the probability that both of them are daughters?
* If a family has two children, the elder of which is a daughter, what is the probability that both of them are the daughters?

A beginner in probability would expect the answers to both these questions to be the same, which they are not.

[Math with Bad Drawings](https://mathwithbaddrawings.com/2013/10/14/the-riddle-of-the-odorless-incense/) explains this paradox with a great story as a part of a seven-post series in Probability Theory

---

[Nontransitive Dice](https://en.wikipedia.org/wiki/Nontransitive_dice)

Let persons P, Q, R have three distinct dice.

If it is the case that P is more likely to win over Q, and Q is more likely to win over R, is it the case that P is likely to win over R?

The answer, strangely, is no. One such dice configuration is $(\left \{2,2,4,4,9,9 \right\},\left \{ 1,1,6,6,8,8\right \},\left \{ 3,3,5,5,7,7 \right \})$

---

[Sleeping Beauty Paradox](https://brilliant.org/discussions/thread/rationality-revisited-the-sleeping-beauty-paradox/)

(This is related to philosophy/epistemology and is more related to subjective probability/beliefs than objective interpretations of it.)


Today is Sunday. Sleeping Beauty drinks a powerful sleeping potion and falls asleep.

Her attendant tosses a [fair coin](https://en.wikipedia.org/wiki/Fair_coin) and records the result.

* The coin lands in **Heads**. Beauty is awakened only on **Monday** and interviewed. Her memory is erased and she is again put back to sleep.
* The coin lands in **Tails**. Beauty is awakened and interviewed on **Monday**. Her memory is erased and she&#39;s put back to sleep again. On **Tuesday**, she is once again awaken, interviewed and finally put back to sleep. 

In essence, the awakenings on Mondays and Tuesdays are indistinguishable to her.

The most important question she&#39;s asked in the interviews is

&gt; What is your credence (degree of belief) that the coin landed in heads?

Given that Sleeping Beauty is epistemologically rational and is aware of all the rules of the experiment on Sunday, what should be her answer?

This problem seems simple on the surface but there are both arguments for the answer $\frac{1}{2}$ and $\frac{1}{3}$ and there is no common consensus among modern epistemologists on this one.

---

[Ellsberg Paradox](https://brilliant.org/discussions/thread/rationality-revisited-the-ellsberg-paradox/)

Consider the following situation:

&gt; In an urn, you have 90 balls of 3 colors: red, blue and yellow.
&gt; 30 balls are known to be red. All the other balls are either blue or yellow.
&gt;
&gt; There are two lotteries:
&gt;
&gt; * **Lottery A:** A random ball is chosen. You win a prize if the ball is red.
&gt; * **Lottery B:** A random ball is chosen. You win a prize if the ball is blue.

Question: In which lottery would you want to participate?

&gt; * **Lottery X:** A random ball is chosen. You win a prize if the ball is either red or yellow.
&gt; * **Lottery Y:** A random ball is chosen. You win a prize if the ball is either blue or yellow.

Question: In which lottery would you want to participate?

If you are an average person, you&#39;d choose Lottery A over Lottery B and Lottery Y over Lottery X. 

However, it can be shown that there is no way to assign probabilities in a way that make this look rational. One way to deal with this is to extend the concept of probability to that of imprecise probabilities., A famous example is this one that is called St. Petersburg paradox:


Consider a game in which you earn $2^n\: \$ $  if you get $n$ consecutive **Heads** in a fair coin tosses. The fair entrance fee of this game is $\infty$, A while back, the xkcd blog posted [this problem][1], which I found fascinating. Usually when I re-tell it, I do so slightly differently from the original author:

&gt; I have selected two numbers from $\mathbb{R}$, following some unknown
&gt; and not necessarily independent distribution. I have written each
&gt; number in a separate envelope. By fair coin toss, I select one of
&gt; these two envelopes to open, revealing that number. I then ask the
&gt; question &quot;Is the number in the other envelope larger than this one?&quot;.
&gt; You win if you guess correctly.
&gt; 
&gt; Can you win this game with probability $&gt;\frac{1}{2}$? Note, that is a
&gt; strict inequality. Winning with probability $=\frac{1}{2}$ is
&gt; obviously easy.

Now, the solution to this starts out with a double-integral, so depending on the level of the class you&#39;re teaching it may not be appropriate.


  [1]: https://blog.xkcd.com/2010/02/09/math-puzzle/, Strongly related   with    OPs example  is this consequence of the *[Arc sine law for last visits](https://www.dartmouth.edu/~chance/teaching\_aids/books\_articles/probability\_book/Chapter12.pdf)*. Let&#39;s assume playing with a fair coin.

&gt;**Theorem (false)**
&gt;*In a long coin-tossing game each player will be on the winning side for about half the time, and the lead will pass not infrequently from one player to the other.*

The following text is from the classic *[An Introduction to Probability Theory and Its Applications, volume 1](https://www.amazon.com/Introduction-Probability-Theory-Applications-Vol/dp/8126518057)*, by William Feller.

&gt;- According to widespread beliefs a so-called law of averages should ensure the *Theorem* above. But, in fact this theorem is wrong and contrary to the *usual* belief the following holds:

&gt;   With probability $\frac{1}{2}$ *no equalization occurred in the second half of the game regardless of the length of the game.* Furthermore, the probabilities near the end point are *greatest*.
, Birthday Problem
==============
For me this was the first example of how counter intuitive the real world probability problems are due to the inherent underestimation/overestimation involved in mental maps for permutation and combination (which is an inverse multiplication problem in general), which form the basis for probability calculation. 
The question is:

&gt; How many people should be in a room so that the probability of at least
&gt; two people sharing the same birthday, is at least as high as the probability of
&gt; getting heads in a toss of an unbiased coin (i.e., $0.5$).

This is a good problem for students to hone their skills in estimating the permutations and combinations, the base for computation of _a priori probability_.


I still feel the number of persons for the answer to be surreal and hard to believe! (The real answer is $23$).

Pupils should at this juncture be told about quick and dirty mental maps for permutations and combinations calculations and should be encouraged  to inculcate a habit of mental computations, which will help them in forming intuition about probability. It will also serve them well in taking to the other higher level problems such as the Monty Hall problem or conditional probability problems mentioned above, such as:

&gt; $0.5\%$ of the total population out of a population of $10$ million is
&gt; supposed to be affected by a strange disease. A test has been
&gt; developed for that disease and it has a truth ratio of $99\%$ (i.e., its
&gt; true $99\%$ of the times). A random person from the population is
&gt; selected and is found to be tested positive for that disease. What is the real probability
&gt; of that person suffering from the strange disease.
&gt; The real answer here is approximately $33\%$.

Here strange disease can be replaced by any real world problems (such as HIV patients or a successful trading / betting strategy or number of terrorists in a country) and this example can be used to give students a feel, why in such cases (HIV patients or so) there are bound to be many false positives (as no real world tests, I believe for such cases are $99\%$ true) and how popular opinions are wrong in such cases most of the times.

This should be the starting point for introducing some of the work of **Daniel Kahneman** and **Amos Tversky** as no probability course in modern times can be complete without giving pupils a sense of how fragile one&#39;s intuitions and estimates are in estimating probabilities and uncertainties and how to deal with them.  $20\%$ of the course should be devoted to this aspect and it can be one of the final real world projects of students., The [boy or girl paradox][1] already mentioned by Agnishom has an interesting [variation][1]:

*&#39;&#39;Suppose we were told not only that Mr. Smith has two children, and one of them is a boy, but also that the boy was born on a Tuesday: does this change the previous analyses?&#39;&#39;* (for the question &#39;&#39;what is the probability that both children are boys&#39;&#39;)?

Using some elementary computations with Bayes formula, the seemingly useless information that a child was born on Tuesday, changes the results.

To understand the intuition behind, consider an extreme case where you knew that one boy was born on December $30$. Then it is very unlikely that the other child is born on that date too, so one child is &#39;&#39;specified&#39;&#39; by the date-information. This reduces the question to &#39;&#39;is the other child a boy&#39;&#39;? and changes the probability from $\frac13$ to approximately $\frac12$.

However, I do **not** recommend to use this example for teaching, as there are many interpretations of this paradox (that partially depend on language nuances of the formulation) and it can add more confusion then clarify something.


  [1]: https://en.wikipedia.org/wiki/Boy_or_Girl_paradox#Information_about_the_child, I particular like the **triple-or-nothing game**:

&gt; You start with $1$ sweet $^{[1]}$ in the pot. At each step, you can either choose to leave the game with all the sweets in the pot, or you can continue the game. If you continue, a fair coin is flipped, and if it comes up heads then the sweets in the pot are tripled, but if it comes up tails then the pot is emptied.

&gt; If you can play this game only once, how many sweets would you be willing to pay to play? And how should you play? (Assume that you want to get the most sweets possible.)

&gt; &lt;sub&gt;$^{[1]}$ Let&#39;s not be money-minded here...&lt;/sub&gt;

The naive (and incorrect) analysis is to compute that at any step if there are $x$ sweets in the pot and you continue the game then the expected number of sweets in the pot will become $1.5x$. Thus you should not stop. But that is stupid; if you never stop you will never get any sweets! So when to stop?

Worse still, a **correct** analysis will tell you that no matter how many sweets you pay, you can play in such a way that the expected number of sweets you leave with is more than what you paid! The (silly) conclusion is that you should be willing to pay any number of sweets to play!

If you think really carefully about it, you will realize that expectation is a very poor indicator of rationality of choice. Instead, everyone will have some risk aversity, more generally a mapping from probability distributions to favourability. One possibility is that a probability distribution is unfavourable iff its median is not positive (representing no net gain). Then clearly this game will never be favourable to anyone with this kind of risk aversity except if you commit to playing for exactly one step. In real life, people will evaluate distributions in a much more complicated way than just checking the median.

That said, a reasonable rule of thumb is that it is not worth to make a decision whose estimated benefit does not have both positive mean and positive median. Positive mean is necessary for rules of thumb, otherwise you will not benefit in the long run. Positive median will prevent other stupid decisions such as playing the triple-or-nothing game for more than one step or paying more than 1.5 sweets to play it. More risk-averse people will play for zero steps and just take the initial sweet and leave!

This rule will show (reasonably) not only that it is not worth to pay even 2 sweets to play the triple-or-nothing game only once, but also that it is not worth to offer the game for others to play! Any application of probability to real-life decisions should be able to deal with such situations.

---

[Further remarks...]

My claim about the rule of thumb being reasonable is that it should work quite well in **real life**. Whether it agrees with various mathematical models of human rationality is irrelevant. Secondly, my rule of thumb is merely for determining whether a **single** option is worth taking or not. To compare between **multiple** choices of which you must pick one, you would have to extend the rule of thumb. One possible way is to define the value of each choice to be the minimum of the mean and median benefit. Then you of course pick the choice with the maximum value. Thirdly, different people will of course have **different** ways to evaluate a choice based on its benefit&#39;s probability distribution (assuming it can even be translated to some real number). A very risk averse person might take the minimum of the 1st percentile (roughly speaking the minimum benefit you believe you will gain in 99% of the cases) and the mean (average benefit). Someone else may combine the percentiles and mean in a different fashion, such as taking $-\infty$ as the value if the 5th percentile is below some threshold (such as representing serious hurt), but taking the mean otherwise., I find that **almost anything** about probability is counter-intuitive to my college students on first encounter. Possibly this may depend on your audience. Here are a few examples:

$1.$ Question: &quot;If a certain event has a $40\%$ chance of success, and we run $50$ experiments, then how many would you expect to succeed?&quot; The most common responses I usually get are &quot;all of them&quot; and &quot;none of them&quot;. This is after an hour-long lecture on the subject. 

$2.$ Question: &quot;Interpret this probability statement: There is a $30\%$ chance of rain today in the New York area.&quot; I usually only get about a $65\%$ successful response rate on this on a multiple-choice quiz, even after the hour-long lecture on the subject. Once I had a student so bamboozled by it that she called up the national meteorology service for a consultation.

$3.$ Question: &quot;We have a hand of four cards $\{A, 2, 3, 4\}$, and pick out two at random; what is the probability we get the $A$ or $2$ ?&quot; Common responses are $25\%$, $50\%$, and $75\%$. I&#39;ve never had anyone in a class intuit the correct answer on first presentation. 

$4.$ Question: &quot;If you drive to school on a given day, you either get in an accident or you don&#39;t. Are these equally likely outcomes?&quot; At least half of any class answers &quot;yes&quot; on the first presentation. This can be repeated with the same result with similar follow-up questions. , **Bertrand&#39;s Paradox**

&gt; Given two concentric circles ($S_1$, $S_2$) with radii $R_1=r$ and $R_2=\frac{r}2$, what is the probability, upon choosing a chord $c$ of the circle $S_1$ at random, that $c\:\cap\: S_2 \neq \emptyset$ ?

Simply speaking, your task is to  
&gt;choose a
chord of the larger circle at random and find the probability that it will intersect the
smaller circle.




Surprisingly, Bertrand&#39;s Paradox offers **three distinct yet valid solutions**.

The same problem can also be stated as: 

&gt; Given an equilateral triangle inscribed in a circle, find the
&gt; probability of randomly choosing a chord of the circle greater than
&gt; the length of a side of the triangle.

The _counter-intuition_ steps in when you understand that the answer to the stated problem is $\frac12,\:\frac13,$ and even $\frac14$ at the same time, and all three answers are perfectly valid.

**The crucial reason why there are three solutions to this in different cases is that the methods of selection of `random variables` are different in each case.**

Here&#39;s the [Wikipedia page][1] for details on how each value is obtained and through what steps.

I remember that a professor had begun my high-school level probability class using Bertrand&#39;s Paradox as an introductory example.

  [1]: https://en.m.wikipedia.org/wiki/Bertrand_paradox_%28probability%29, Consider the $d-$dimensional sphere,  then as $d$ goes to infinity the mass concentrates on the equator $x_1=0$, **Airplane Seating**

$100$ people are boarding a plane in a line and each of them is assigned to one of the $100$ seats on a plane. However, the first person in line forgot his boarding pass and as a result decided to sit down in a random seat. The second person will do the following:

1. Sit in her seat if it still available.
2. If her seat is not available, choose a random seat among the seats remaining and sit there.

Each following person sits according to the same rules as the second person. What is the probability the $100^{th}$ person will be able to sit in her assigned seat?


Most people think the probability is very small and think there is a tiny chance of the 100th person&#39;s seat being left after all the people move around. But the actual probability ends up being $\frac{1}{2}$., I think the most stunning example are the [non-transitive dice.][1]

Take three cubic dice with the following numbers on their sides:

  * Die $A:$ 	$3 \:	3 \:	3 \:	3 \:	3 \:	6$
  * Die $B:$	$2 \:	2 \:	2 \:	5 \:	5 \:	5$
  * Die $C:$	$1 \:	4 	\:4 \:	4 \:	4 	\:4$

Now I offer you the following game: You choose a die as you like, then I choose another die, and then we are rolling and the highest number wins.

No matter which die you choose, I can choose another one that wins more often than loses against your choice.


  [1]: https://plus.maths.org/content/non-transitiv-dice, Perhaps Parrondo&#39;s Paradox would be interesting. One can combine losing propositions into a winning proposition.

Simpson&#39;s Paradox is also interesting. (And actually occurred in a court case.), I flip two coins. Given that one is heads, what&#39;s the probability the other one is heads?

Surprisingly, it&#39;s not $\frac12$., The secretary&#39;s problem (which has other names).The secretary has $n$ letters  ($0&lt;n&lt;\infty$) and $n$ pre-addressed envelopes but puts the letters into the envelopes randomly, one letter per envelope. What is the chance $C(n)$ that NO letter gets into the right envelope?

 The answer is $C(n)=\sum_{j=0}^n(-1)^j/j!,$ which converges to $1/e$ as $n\to \infty$. I think  the method of solution is instructive.

 One counter-intuitive result is that $C(n)$ is not monotonic in $n.$

 Also many people would be inclined to guess that $C(n)&gt;1/2$ for large $n.$ 

Another version of this is to take two  shuffled decks, each with $n$ playing cards,  and ask for the chance that no card occupies the same position in both decks.

I first saw this in &quot;101 Great Problems In  Elementary Mathematics&quot; by H. Dorrie., It&#39;s not counter intuitive  but it&#39;s amazing for teaching in class.

Pick $a,b \in [n]$ randomly. $\mathbb{P}[gcd(a,b)=1]$ tends to $\frac{6}{\pi^2}$ as $n$ goes to infinity.

Also, there is some other interesting problem whose answers have $\pi , e ,...$, [Base rate fallacy][1]
--
If presented with related base rate information (or generic information) and specific information (information only pertaining to a certain case), the mind tends to ignore the former and focus on the latter.

**Example**:  
A group of police officers have breathalyzers displaying false drunkenness in 5% of the cases in which the driver is sober. However, the breathalyzers never fail to detect a truly drunk person. One in a thousand drivers is driving drunk. Suppose the police officers then stop a driver at random, and force the driver to take a breathalyzer test. It indicates that the driver is drunk. We assume you don&#39;t know anything else about him or her. How high is the probability he or she really is drunk?  

Intuitive first answer might be as high as 0.95, but the correct probability is about 0.02.

Solution :
Using [Bayes&#39;s theorem][2].   

The goal is to find the probability that the driver is drunk given that the breathalyzer indicated he/she is drunk, which can be represented as
$${\displaystyle p(\mathrm {drunk} |D)}$$  
where &quot;**D**&quot; means that the breathalyzer indicates that the driver is drunk.    

Bayes&#39;s theorem tells us that
  
$$ {\displaystyle p(\mathrm {drunk} |D) = {\frac {p(D|\mathrm {drunk} )\,  
p(\mathrm {drunk} )}{p(D)}}}     
$$

We were told the following in the first paragraph:

$${\displaystyle p(\mathrm {drunk} )=0.001}   $$
$${\displaystyle p(\mathrm {sober} )=0.999}   $$
$${\displaystyle p(D|\mathrm {drunk} )=1.00}   $$
$${\displaystyle p(D|\mathrm {sober} )=0.05} $$


As you can see from the formula, one needs p(D) for Bayes&#39; theorem, which one can compute from the preceding values using  
$${\displaystyle p(D)=p(D|\mathrm {drunk} )\,p(\mathrm {drunk} )+p(D|\mathrm {sober} )\,p(\mathrm {sober} )} $$

 
which gives
$$
{\displaystyle p(D)=(1.00\times 0.001)+(0.05\times 0.999)=0.05095} $$

Plugging these numbers into Bayes&#39; theorem, one finds that
$$ {\displaystyle p(\mathrm {drunk} |D)={\frac {1.00\times 0.001}{0.05095}}=0.019627  \approx 0.02 } $$

---

A more intuitive explanation: on average, for every 1,000 drivers tested,
1 driver is drunk, and it is 100% certain that for that driver there is a true positive test result, so there is 1 true positive test result
999 drivers are not drunk, and among those drivers there are 5% false positive test results, so there are 49.95 false positive test results.  
Therefore, the probability that one of the drivers among the $$1 + 49.95 = 50.95 $$positive test results really is drunk is
$$ {\displaystyle p(\mathrm {drunk} |D)=1/50.95\approx 0.019627}  $$


  [1]: https://en.wikipedia.org/wiki/Base_rate_fallacy
  [2]: https://en.wikipedia.org/wiki/Bayes%27_theorem, In contract bridge, there is the principle of restricted choice.  It&#39;s always seemed counterintuitive to me.

https://en.m.wikipedia.org/wiki/Principle_of_restricted_choice, One of the most puzzling results in probability is that the probability of randomly (and with uniform probability) picking a rational number among the set of reals is zero. This is nicely explained [here](http://mathforum.org/library/drmath/view/55676.html).

The set of rational numbers, for instance in the $\Omega=[0,1]$ interval is the *countable* union of disjoint singletons, and each one of these singletons has a probability of zero. Here is the proof:

---

A singleton, $\{b\}$, is a Borel measurable set with a Lebesgue measure of zero. The proof is as follows:

$$\Pr\left(\{b\}\right)=\Pr\left(\bigcap_{n=1}^\infty\left(b-\frac{1}{n},b + \frac{1}{n}\right]\cap \Omega\right)$$

is the probability of nested decreasing sets, allowing the use of the theorem of continuity of probability measures $(*)$ to re-write it as:

$$\Pr\left(\{b\}\right)=\lim_{n\rightarrow \infty}\,\Pr\left(\left(b-\frac{1}{n},b + \frac{1}{n}\right]\cap \Omega\right)$$

The probability of $$\Pr\left(b-\frac{1}{n},\,b + \frac{1}{n} \right)\leq \lim_{n\rightarrow \infty}\frac{2}{n}=0$$

---

Therefore, by countable additivity of measures $(**)$, the probability for the whole set of $\mathbb Q$ is zero:

$$\Pr(\mathbb Q\;\cap \Omega) = 0$$

The apparent paradox is that despite the infinity number of rational numbers in the $[0,1]$ interval, the probability of randomly choosing a rational is strictly zero.

The source is this great explanation [here](https://youtu.be/I3zwALG19Zk?list=PLbMVogVj5nJQqGHrpAloTec_lOKsG-foc).

---

$(*)$ If $B_j, j = 1, 2,\cdots,$ is a sequence of events decreasing to $B$, then
$\displaystyle\lim_{n\rightarrow \infty} \Pr \{B_n\} = \Pr \{B\} .$

$(**)$ For all countable collections $\{E_i\}_{i=1}^\infty$ of pairwise disjoint sets in a sigma algebra: $$\mu\left( \bigcup_{k=1}^\infty \, E_k \right)=\sum_{k=1}^\infty \mu(E_k).$$, Someone mentioned non-transitive dice, and that reminded me of this one:

&gt; Suppose there are two unweighted six-sided dice that you cannot
&gt; examine, but which you can direct a machine to roll and inform you of
&gt; the sum.  You can do this as often as you like, and the distribution
&gt; of the sum is exactly what you would expect of a pair of ordinary
&gt; six-sided dice.
&gt; 
&gt; Are they, in fact, a pair of ordinary six-sided dice?

[Not necessarily](https://en.wikipedia.org/wiki/Sicherman_dice).

Then someone mentioned a secretary problem, which turned out to be about derangements.  I had in mind a different secretary&#39;s problem, which is also called the sultan&#39;s dowry:

&gt; You have $100$ candidates, upon which there exists a total order.  The
&gt; candidates have appointments with you, one at a
&gt; time, in a random order. 
&gt; From each interview, you can tell exactly how that candidate ranks
&gt; amongst those you have already examined.  At that point, you may
&gt; either accept or reject the candidate.  Any acceptance or rejection is
&gt; permanent; no candidate, once rejected, may be reconsidered.  Your
&gt; objective is solely to accept the best candidate.  What is the
&gt; strategy for maximizing your probability of doing so, and what is that
&gt; probability?

As often happens in probability puzzles, [the answer is $1/e$](https://en.wikipedia.org/wiki/Secretary_problem)*, which many people find surprisingly high.

---

*Approximately, with the approximation getting better and better as the number of candidates increases without bound., **Lake Wobegon Dice**

Find a set of $n$ dice (each with $s$ sides, numbered appropriately), in which *each* die is more likely to roll above the set average on that roll than below the set average.  Given $n$, find the *Lake Wobegon Optimal* set, in which that probability is maximum.

&quot;[Lake Wobegon Dice][1],&quot; by Jorge Moraleda and David G. Stork, *College Mathematics Journal*, **43**(2):152--159 (2012)

Abstract:

 - We present sets of $n$ non-standard dice‚ÄîLake Wobegon dice‚Äîhaving the
   following paradoxical property: On every (random) roll of a set, each
   die is more likely to roll greater than the set average than less
   than the set average; in a specific statistical sense, then, each die
   is ‚Äúbetter than the set average.‚Äù
   
   We define the Lake Wobegon Dominance of a die in a set as the
   probability the die rolls greater than the set average minus the
   probability the die rolls less than the set average. We further
   define the Lake Wobegon Dominance *of the set* to be the dominance of
   the set‚Äôs least dominant die and prove that such paradoxical
   dominance is bounded above by $(n-2)/n$ regardless of the number of
   sides $s$ on each die and the maximum number of pips $p$ on each
   side.  A set achieving this bound is called *Lake Wobegon Optimal*.  We
   give a constructive proof that Lake Wobegon Optimal sets exist for
   all $n \ge 3$ if one is free to choose $s$ and $p$.  We also show how
   to construct minimal optimal sets, that is, that set that requires
   the smallest range in the number of pips on the faces.
   
   We determine the frequency of such Lake Wobegon sets in the $n = 3$
   case through exhaustive computer search and find the unique optimal
   $n = 3$ set having minimal $s$ and $p$. We investigate symmetry
   properties of such sets, and present equivalence classes having
   identical paradoxical dominance.  We construct inverse sets, in which
   on any roll each die is more likely to roll less than the set average
   than greater than the set average, and thus each die is ‚Äúworse than
   the set average.‚Äù  We show the unique extreme ‚Äúworst‚Äù case, the Lake
   Wobegon pessimal set.

[![enter image description here][2]][2]

  [1]: http://www.jstor.org/stable/10.4169/college.math.j.43.2.152?seq=1#page_scan_tab_contents
  [2]: https://i.stack.imgur.com/tCVHb.png, I have also had a lecture on this excellent topic.

Unfortunately, my [lecture notes](http://mks.mff.cuni.cz/library/PravdepodobnostniParadoxyMO/PravdepodobnostniParadoxyMO.pdf) are in Czech, but I can translate some paradoxes from there:

**[Monty Hall](https://en.wikipedia.org/wiki/Monty_Hall_problem)**

Monty Hall is in my opinion the most famous probabilistic paradox. It is described here and on the Wiki well. So I just provide you a way how to make it feel intuitive, to persuade other people that the real probability is computed correctly. It is quite impressive, almost like a magician trick :-)

Take a pack of cards and let someone draw a random card. Tell him that he want to draw the ace of hearts and he should not look on the chosen card. Then show to audience all remaining cards but one which are not the ace of hearts. So then there are two hidden cards: One in your hand and one in his hand. Finally, he may change his first guess. Most people do it and they are most likely correct :-).

**Tennis-like game**

There are two players, Alice and Bob, playing a tennis-like game. Every time, one player serves the ball and winning probabilities of the ball depends on the player. Player who first reaches say 11 points wins the match.
Alice serves the first ball. Then there are three possible schemes:

 1. The winner of the previous ball serves the next.
 2. The loser of the previous ball serves the next.
 3. Service is regularly alternating.

One would expect that scheme 1. helps stronger players and scheme 2 helps weaker players. The paradox is that winning probabilities of the match do not depend on the chosen scheme.

Proof sketch: Pregenerate 11 cards with the winner of Alice services (pack A) and 10 cards with the winner of Bob&#39;s service (pack B). Then each Alice&#39;s (or Bob&#39;s) service can be modeled just by drawing a card from the pack A (or B). It can be shown that these 21 cards suffice for any of these 3 presented schemes. And the winner is determined by the cards: there is exactly one player written on at least 11 cards.

**Candies**

I have a bag of candies, there are 123 caramel candies and 321 mint candies. Every morning I randomly draw candies from the pack and eat them while they are all the same. When I take a different kind of candy, I return it back. What is the probability that the last eaten candy will be the caramel one?

Answer: 1/2. (one would expect that it is less than 1/2 since there are less caramel candies)

Proof: It suffices to show that every morning the probability that all caramel candies will be eaten is the same as the probability that all mint candies will be eaten. We can imagine that candies are randomly ordered every morning and I am drawing them from left to right. I eat all caramel candies if the order is &quot;First caramel candies, then mint ones.&quot;. I eat all mint candies if the order is the opposite.

**Wolf on a circle**

There is a wolf at one vertex of a regular n-gon. There is a sheep at every remaining vertex. Each step, the wolf moves to a randomly chosen adjacent vertex and if there is a sheep, the wolf eat it. The wolf ends when it eats n-2 sheep (so there remains just one sheep).

Intuitively, the sheep at the opposite vertex from the wolf is in the best position. The paradox is that all sheep have the same probability of survival.

Proof: Take one sheep S. The wolf will definitely get to an adjacent vertex to S for the first time. This time the sheep on the other adjacent vertex is still not eaten. So for S survival, the wolf have to go around the whole circle without eating S. The probability of going around the whole circle from one vertex adjacent to S to the other without visiting S does not depend on the position of S.

**[Simpson&#39;s Paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox)**

There is a research on two medical cures A, B.

200 people tried the cure A, it helped to 110 people (50 men, 60 women) and did not helped to 90 people (60 men, 30 women).

210 people tried the cure B, it helped to 120 people (30 men and 90 women) and did not helped to 90 people (40 men, 50 women).

So in general, the cure B is better since 120:90 &gt; 110:90.

But if you are a man, you can consider just men statistics: 50:60 &gt; 30:40, so the cure A is more appropriate.

And if you are a woman, you can consider just women statistics: 60:30 &gt; 90:50, so the cure A is again more appropriate.

Shocking, isn&#39;t it? :-), There&#39;s the [**two envelopes paradox**](https://en.wikipedia.org/wiki/Two_envelopes_problem). Wikipedia states it as follows:

&gt; You are given two indistinguishable envelopes, each containing money, one contains twice as much as the other. You may pick one envelope and keep the money it contains. Having chosen an envelope at will, but before inspecting it, you are given the chance to switch envelopes. Should you switch?

The issue is that there is an amount $X$ of money in the envelope you have. If it&#39;s the lesser amount then switching gives you a reward of $2X$ and if you don&#39;t then you only get $X/2$. Since both cases are equally likely, it seems that you should switch, even though that is nonsensical since clearly your chance of getting the larger amount can only ever be 50%.

The Wikipedia article goes into great depth explaining various resolutions of this fallacy. It boils down to the fact that the sum of the two envelopes is the same in both cases, which means that the $X$s considered above aren&#39;t actually identical.

A related problem is the [**necktie paradox**](https://en.wikipedia.org/wiki/Necktie_paradox)., I see the Monty Hall has been mentioned a couple of times, but I want to mention it again because I think the reason that it&#39;s interesting is missed in the other answers.  In particular, it demonstrates not only a counter-intuitive result for a given formulation, but it also demonstrates how sensitive the correct answer is to the formulation of the problem.  I especially like this NYT article as an illustration:

http://www.nytimes.com/1991/07/21/us/behind-monty-hall-s-doors-puzzle-debate-and-answer.html?pagewanted=all

From a teaching point of view, this is a fun exercise because Monty Hall (the real person) is part of the article, and he plays a role both in validating the math on the &quot;academic&quot; version of the problem and in showing the math is meaningless in the real game because he has controls that are not in academic version. Moreover, after years of doing the show, he&#39;s good at reading individual contestants, so probability is not really at play in a significant way., This is one of my favorites:

[**100 prisoners problem**][1]


  [1]: https://en.wikipedia.org/wiki/100_prisoners_problem


&gt; The director of a prison offers 100 death row prisoners, who are
&gt; numbered from 1 to 100, a last chance. A room contains a cupboard with
&gt; 100 drawers. The director randomly puts one prisoner&#39;s number in each
&gt; closed drawer. The prisoners enter the room, one after another. Each
&gt; prisoner may open and look into 50 drawers in any order. The drawers
&gt; are closed again afterwards. If, during this search, every prisoner
&gt; finds his number in one of the drawers, all prisoners are pardoned. If
&gt; just one prisoner does not find his number, all prisoners die. Before
&gt; the first prisoner enters the room, the prisoners may discuss
&gt; strategy‚Äîbut may not communicate once the first prisoner enters to
&gt; look in the drawers.
&gt; 
&gt; If every prisoner selects $50$ drawers at random, the probability that
&gt; a single prisoner finds his number is $50\%$. Therefore, the
&gt; probability that all prisoners find their numbers is the product of
&gt; the single probabilities, which is $1/2^{100} \approx
 0.0000000000000000000000000000008$, a vanishingly small number. The situation appears hopeless.
&gt; 
&gt; Up to which value can prisoners improve the probability of being
&gt; pardoned using a good strategy?
  , I remember to be confused the first time this riddle was proposed to me:

&gt; What is the probability of getting a poker hand with at least two
&gt; aces, assuming that it contains at least one ace?
&gt; 
&gt; What if we know that it is indeed an ace of spades? does this
&gt; information change the probability?, **[The Shooting Room Paradox][1]**

&gt; A single person enters a room and two dice are rolled. If the result
&gt; is double sixes, he is shot. Otherwise he leaves the room and nine new
&gt; players enter. Again the dice are rolled, and if the result is double
&gt; sixes, all nine are shot. If not, they leave and 90 new players enter,
&gt; and so on (the number of players increasing tenfold with each round).
&gt; The game continues until double sixes are rolled and a group is
&gt; executed, which is certain to happen eventually (the room is
&gt; infinitely large, and there&#39;s an infinite supply of players).
&gt; 
&gt; If you&#39;re selected to enter the room, how worried should you be? Not
&gt; particularly: Your chance of dying is only 1 in 36. Later your mother
&gt; learns that you entered the room. How worried should she be?
&gt; Extremely: About 90 percent of the people who played this game were
&gt; shot. What does your mother know that you don&#39;t? Or vice versa?


  [1]: http://www.futilitycloset.com/2013/01/11/the-shooting-room/%20?utm_medium=referral&amp;utm_source=t.co, One that I found surprising as a beginner was that three events (or random variables) can be independent pairwise, but not jointly independent.  Or to put it somewhat more strikingly, we can have $C$ independent of $A$ and independent of $B$, yet not independent of $A,B$.  Wording it this way shows that it does take care to state independence assumptions carefully, and it also illustrates some non-obvious subtleties in the definition of independence (one of them being that independence of two events does **not** mean that they don&#39;t interact and can&#39;t be influenced by a third factor).

One example of pairwise but non-mutual independence is given on the [Wikipedia page](https://en.wikipedia.org/wiki/Independence_(probability_theory)#Pairwise_and_mutual_independence).

The example that I typically use is to take $T$ to be a uniformly random angle in $[0,2\pi)$ and then consider the events $A = \{\sin T &gt; 0\}$, $B = \{ \cos T &gt; 0\}$ and $C = \{ \tan T &gt; 0 \}$ (effectively, this is just two independent $\pm 1$ variables and their product, but the trig formulation helps to visualize the events in terms of quadrants).

It&#39;s easy to see that $P(A)=P(B)=P(C) = \tfrac12$ and that $P(A\cap B) = P(A\cap C) = P(B\cap C) = \tfrac14$, but clearly $P(A\cap B\cap \overline C) = 0$., One I saw on Twitter recently, which is perhaps a clearer version of sex-of-children-type problems:

&gt; Three casino chips have a dot on each side: 

&gt; - on one chip the dots are both blue, 
- on the second there is a blue dot on one side and red on the other, and
- on the third the dots are both red. 

&gt; The chips are placed in a bag  and, without looking, you choose one and place it on the table. When you look at the chip, you see it has a blue dot on top. What is the probability that the dot on the other side is blue?

Many people will say $1/2$ - I did before I thought properly - but...

&gt;! you are blindly choosing both the chip, and which side to face up. So you have to consider that each dot has an equal chance of showing, making the chance $2/3$., **Optimizer&#39;s Curse:** suppose you have a number of options to choose from, each with some objective true value. You don&#39;t have access to the objective true value, but instead to a noisy estimate of it, say a value sampled from a normal distribution with mean the true value and variance $1$.

You, naturally, pick the choice whose estimate of true value is the highest. When you do so, you discover what the true value really was. Call the difference between the estimate and the true value your *post-decision surprise*.

Now, the error of your estimate was normally distributed with mean $0$, so you might also guess that your post-decision surprise will have mean $0$ ‚Äì sometimes you will be pleasantly surprised, sometimes disappointed. But in fact the post-decision surprise is usually negative, that is to say, you are usually disappointed by your choice!

In retrospect, this is perhaps not so surprising: certainly if all the true values were the same, you&#39;d simply pick the estimate with the highest inflation due to noise, and more generally, conditional on an estimate being the leader of a pack, it&#39;s more likely to be an overestimate than an underestimate.

More interestingly, if the variances *aren&#39;t* the same for all your estimates, it&#39;s no longer correct to just pick the highest estimate to maximise your expected true value. If the highest estimate is also high-variance, it may lead to a lower true value in expectation than a lower estimate with better precision, and so what looks superficially like some kind of risk-aversion (discounting the value of apparently high-variance options) is actually justifiable purely on expected-value grounds.

(Notice also that &quot;there a bunch of options with some true values, but you only get a noisy estimate of the true value, and you have to decide which to choose&quot; is a REALLY common situation to be in, so this problem is pretty pervasive in real life optimization scenarios)]",,,,,,3,"[{u'edited': False, u'comment_id': 4417156, u'creation_date': 1487263550, u'post_id': 2140493, u'score': 2, u'post_type': u'question', u'owner': {u'user_id': 247327, u'user_type': u'registered', u'reputation': 9363, u'link': u'https://math.stackexchange.com/users/247327/user247327', u'display_name': u'user247327', u'badge_counts': {u'bronze': 14, u'silver': 5, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability#comment4417156_2140493'}, {u'edited': False, u'reply_to_user': {u'user_id': 247327, u'user_type': u'registered', u'reputation': 9363, u'link': u'https://math.stackexchange.com/users/247327/user247327', u'display_name': u'user247327', u'badge_counts': {u'bronze': 14, u'silver': 5, u'gold': 1}}, u'comment_id': 4419403, u'creation_date': 1487327497, u'post_id': 2140493, u'score': 1, u'post_type': u'question', u'owner': {u'user_id': 382396, u'user_type': u'registered', u'reputation': 111, u'link': u'https://math.stackexchange.com/users/382396/kami-kaze', u'display_name': u'Kami Kaze', u'badge_counts': {u'bronze': 4, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability#comment4419403_2140493'}, {u'edited': False, u'comment_id': 4421513, u'creation_date': 1487392724, u'post_id': 2140493, u'score': 2, u'post_type': u'question', u'owner': {u'user_id': 156999, u'user_type': u'registered', u'reputation': 16103, u'link': u'https://math.stackexchange.com/users/156999/anomaly', u'accept_rate': 67, u'display_name': u'anomaly', u'badge_counts': {u'bronze': 60, u'silver': 25, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability#comment4421513_2140493'}]",1486884556,3,160,True,1528586078,1491767769.0,https://math.stackexchange.com/questions/2140493/counterintuitive-examples-in-probability,96.0,54.0,4.0,26.0,Leila,https://math.stackexchange.com/users/195683/leila,3349.0,195683.0,registered,1486994058.0,2140493,152,https://math.stackexchange.com/q/2140493,"[probability, soft-question, examples-counterexamples, intuition, big-list]",Counterintuitive examples in probability,155,22226
13,,5,"[{u'up_vote_count': 1, u'title': u'Some interesting counter-examples to things with probability of $0$ occuring', u'question_id': 2101029, u'tags': [], u'down_vote_count': 1, u'last_activity_date': 1484617733, u'comments': [{u'edited': False, u'comment_id': 4320020, u'creation_date': 1484617895, u'post_id': 2101050, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 272831, u'user_type': u'registered', u'reputation': 48612, u'link': u'https://math.stackexchange.com/users/272831/simply-beautiful-art', u'accept_rate': 74, u'display_name': u'Simply Beautiful Art', u'badge_counts': {u'bronze': 167, u'silver': 70, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101050#comment4320020_2101050'}], u'creation_date': 1484617733, u'comment_count': 1, u'score': 0, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101050#2101050', u'body_markdown': u'There is no way to choose a random integer with a probability distribution uniform on the integers: the probability of any particular integer will be $0$.

https://math.stackexchange.com/questions/1880140/is-getting-a-random-integer-even-possible', u'owner': {u'user_id': 72858, u'user_type': u'registered', u'reputation': 34363, u'link': u'https://math.stackexchange.com/users/72858/ethan-bolker', u'display_name': u'Ethan Bolker', u'badge_counts': {u'bronze': 95, u'silver': 37, u'gold': 5}}, u'is_accepted': False, u'last_edit_date': 1492086024, u'share_link': u'https://math.stackexchange.com/a/2101050', u'answer_id': 2101050}, {u'up_vote_count': 1, u'title': u'Some interesting counter-examples to things with probability of $0$ occuring', u'question_id': 2101029, u'tags': [], u'down_vote_count': 1, u'last_activity_date': 1484617759, u'comments': [{u'edited': False, u'comment_id': 4320017, u'creation_date': 1484617834, u'post_id': 2101052, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 272831, u'user_type': u'registered', u'reputation': 48612, u'link': u'https://math.stackexchange.com/users/272831/simply-beautiful-art', u'accept_rate': 74, u'display_name': u'Simply Beautiful Art', u'badge_counts': {u'bronze': 167, u'silver': 70, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101052#comment4320017_2101052'}, {u'edited': False, u'reply_to_user': {u'user_id': 272831, u'user_type': u'registered', u'reputation': 48612, u'link': u'https://math.stackexchange.com/users/272831/simply-beautiful-art', u'accept_rate': 74, u'display_name': u'Simply Beautiful Art', u'badge_counts': {u'bronze': 167, u'silver': 70, u'gold': 5}}, u'comment_id': 4320027, u'creation_date': 1484617996, u'post_id': 2101052, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 206546, u'user_type': u'registered', u'reputation': 1810, u'link': u'https://math.stackexchange.com/users/206546/matt', u'display_name': u'Matt', u'badge_counts': {u'bronze': 15, u'silver': 6, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101052#comment4320027_2101052'}, {u'edited': False, u'comment_id': 4320028, u'creation_date': 1484617996, u'post_id': 2101052, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 75808, u'user_type': u'registered', u'reputation': 45230, u'link': u'https://math.stackexchange.com/users/75808/clement-c', u'accept_rate': 75, u'display_name': u'Clement C.', u'badge_counts': {u'bronze': 80, u'silver': 35, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101052#comment4320028_2101052'}, {u'edited': False, u'reply_to_user': {u'user_id': 75808, u'user_type': u'registered', u'reputation': 45230, u'link': u'https://math.stackexchange.com/users/75808/clement-c', u'accept_rate': 75, u'display_name': u'Clement C.', u'badge_counts': {u'bronze': 80, u'silver': 35, u'gold': 2}}, u'comment_id': 4320062, u'creation_date': 1484618811, u'post_id': 2101052, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 206546, u'user_type': u'registered', u'reputation': 1810, u'link': u'https://math.stackexchange.com/users/206546/matt', u'display_name': u'Matt', u'badge_counts': {u'bronze': 15, u'silver': 6, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101052#comment4320062_2101052'}, {u'edited': False, u'comment_id': 4320064, u'creation_date': 1484618947, u'post_id': 2101052, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 75808, u'user_type': u'registered', u'reputation': 45230, u'link': u'https://math.stackexchange.com/users/75808/clement-c', u'accept_rate': 75, u'display_name': u'Clement C.', u'badge_counts': {u'bronze': 80, u'silver': 35, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101052#comment4320064_2101052'}, {u'edited': False, u'reply_to_user': {u'user_id': 75808, u'user_type': u'registered', u'reputation': 45230, u'link': u'https://math.stackexchange.com/users/75808/clement-c', u'accept_rate': 75, u'display_name': u'Clement C.', u'badge_counts': {u'bronze': 80, u'silver': 35, u'gold': 2}}, u'comment_id': 4320072, u'creation_date': 1484619158, u'post_id': 2101052, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 206546, u'user_type': u'registered', u'reputation': 1810, u'link': u'https://math.stackexchange.com/users/206546/matt', u'display_name': u'Matt', u'badge_counts': {u'bronze': 15, u'silver': 6, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101052#comment4320072_2101052'}], u'creation_date': 1484617759, u'comment_count': 6, u'score': 0, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101052#2101052', u'body_markdown': u'Maybe an interesting example you have not seen: a Wiener process is a continuous version of a random walk. If I generate a Wiener process for $T$ seconds then the probability of generating exactly this process is 0.', u'owner': {u'user_id': 206546, u'user_type': u'registered', u'reputation': 1810, u'link': u'https://math.stackexchange.com/users/206546/matt', u'display_name': u'Matt', u'badge_counts': {u'bronze': 15, u'silver': 6, u'gold': 2}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2101052', u'answer_id': 2101052}, {u'up_vote_count': 6, u'title': u'Some interesting counter-examples to things with probability of $0$ occuring', u'question_id': 2101029, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1484618223, u'comments': [{u'edited': False, u'comment_id': 4320045, u'creation_date': 1484618334, u'post_id': 2101060, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 272831, u'user_type': u'registered', u'reputation': 48612, u'link': u'https://math.stackexchange.com/users/272831/simply-beautiful-art', u'accept_rate': 74, u'display_name': u'Simply Beautiful Art', u'badge_counts': {u'bronze': 167, u'silver': 70, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101060#comment4320045_2101060'}, {u'edited': False, u'reply_to_user': {u'user_id': 272831, u'user_type': u'registered', u'reputation': 48612, u'link': u'https://math.stackexchange.com/users/272831/simply-beautiful-art', u'accept_rate': 74, u'display_name': u'Simply Beautiful Art', u'badge_counts': {u'bronze': 167, u'silver': 70, u'gold': 5}}, u'comment_id': 4320048, u'creation_date': 1484618449, u'post_id': 2101060, u'score': 3, u'post_type': u'answer', u'owner': {u'user_id': 75808, u'user_type': u'registered', u'reputation': 45230, u'link': u'https://math.stackexchange.com/users/75808/clement-c', u'accept_rate': 75, u'display_name': u'Clement C.', u'badge_counts': {u'bronze': 80, u'silver': 35, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101060#comment4320048_2101060'}, {u'edited': False, u'reply_to_user': {u'user_id': 272831, u'user_type': u'registered', u'reputation': 48612, u'link': u'https://math.stackexchange.com/users/272831/simply-beautiful-art', u'accept_rate': 74, u'display_name': u'Simply Beautiful Art', u'badge_counts': {u'bronze': 167, u'silver': 70, u'gold': 5}}, u'comment_id': 4320054, u'creation_date': 1484618585, u'post_id': 2101060, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 83396, u'user_type': u'registered', u'reputation': 64295, u'link': u'https://math.stackexchange.com/users/83396/ian', u'accept_rate': 71, u'display_name': u'Ian', u'badge_counts': {u'bronze': 79, u'silver': 44, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101060#comment4320054_2101060'}, {u'edited': False, u'comment_id': 4320067, u'creation_date': 1484619055, u'post_id': 2101060, u'score': 2, u'post_type': u'answer', u'owner': {u'user_id': 260904, u'user_type': u'registered', u'reputation': 4001, u'link': u'https://math.stackexchange.com/users/260904/aduh', u'accept_rate': 83, u'display_name': u'aduh', u'badge_counts': {u'bronze': 36, u'silver': 11, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101060#comment4320067_2101060'}, {u'edited': False, u'reply_to_user': {u'user_id': 260904, u'user_type': u'registered', u'reputation': 4001, u'link': u'https://math.stackexchange.com/users/260904/aduh', u'accept_rate': 83, u'display_name': u'aduh', u'badge_counts': {u'bronze': 36, u'silver': 11, u'gold': 2}}, u'comment_id': 4320084, u'creation_date': 1484619620, u'post_id': 2101060, u'score': 3, u'post_type': u'answer', u'owner': {u'user_id': 111012, u'user_type': u'registered', u'reputation': 45472, u'link': u'https://math.stackexchange.com/users/111012/bof', u'accept_rate': 100, u'display_name': u'bof', u'badge_counts': {u'bronze': 110, u'silver': 48, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101060#comment4320084_2101060'}, {u'edited': False, u'comment_id': 4320828, u'creation_date': 1484654298, u'post_id': 2101060, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 272831, u'user_type': u'registered', u'reputation': 48612, u'link': u'https://math.stackexchange.com/users/272831/simply-beautiful-art', u'accept_rate': 74, u'display_name': u'Simply Beautiful Art', u'badge_counts': {u'bronze': 167, u'silver': 70, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101060#comment4320828_2101060'}], u'creation_date': 1484618223, u'comment_count': 6, u'score': 6, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101060#2101060', u'body_markdown': u'If you&#39;re looking for an example of a nonempty set of measure zero, that&#39;s easy: take the set $\{2,5,8\},$ or the Cantor set.

If you&#39;re looking for an example of a &quot;real life&quot; event which has probability zero and happens anyway, forget it: probability zero events don&#39;t happen. Here are a couple of fake examples:

&quot;Toss a coin an infinite number of times; whatever sequence of heads and tails comes up is a probability zero event.&quot;

Nope. In the real world, there is no such thing as an infinite sequence of coin tosses.

&quot;A continuous random variable has to take some real value, but the probability of any real number is zero.&quot;

Nope. In real life, a continuous random variable is never observed to take a real number as its value, it is only observed to land in an interval, which has positive measure.
', u'owner': {u'user_id': 111012, u'user_type': u'registered', u'reputation': 45472, u'link': u'https://math.stackexchange.com/users/111012/bof', u'accept_rate': 100, u'display_name': u'bof', u'badge_counts': {u'bronze': 110, u'silver': 48, u'gold': 3}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2101060', u'answer_id': 2101060}, {u'up_vote_count': 3, u'title': u'Some interesting counter-examples to things with probability of $0$ occuring', u'question_id': 2101029, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1484618525, u'comments': [{u'edited': False, u'comment_id': 4320059, u'creation_date': 1484618738, u'post_id': 2101067, u'score': 0, u'post_type': u'answer', u'owner': {u'display_name': u'user384138', u'user_type': u'does_not_exist'}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101067#comment4320059_2101067'}, {u'edited': False, u'comment_id': 4320087, u'creation_date': 1484619673, u'post_id': 2101067, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 229023, u'user_type': u'registered', u'reputation': 13755, u'link': u'https://math.stackexchange.com/users/229023/ahmed-s-attaalla', u'accept_rate': 77, u'display_name': u'Ahmed S. Attaalla', u'badge_counts': {u'bronze': 44, u'silver': 15, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101067#comment4320087_2101067'}, {u'edited': False, u'comment_id': 4320090, u'creation_date': 1484619848, u'post_id': 2101067, u'score': 0, u'post_type': u'answer', u'owner': {u'display_name': u'user384138', u'user_type': u'does_not_exist'}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101067#comment4320090_2101067'}], u'creation_date': 1484618525, u'comment_count': 3, u'score': 3, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101067#2101067', u'body_markdown': u'If the probability of an event a random variable is $0$ and the event is surely in the set of possible outcomes, then the only way this is possible is if there are an infinite amount of possibilities. 

As it seems to me you are not interested in any cases where there are an infinite amount of outcomes, then nothing &quot;non-trivial&quot; can be found.', u'owner': {u'user_id': 229023, u'user_type': u'registered', u'reputation': 13755, u'link': u'https://math.stackexchange.com/users/229023/ahmed-s-attaalla', u'accept_rate': 77, u'display_name': u'Ahmed S. Attaalla', u'badge_counts': {u'bronze': 44, u'silver': 15, u'gold': 1}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2101067', u'answer_id': 2101067}, {u'up_vote_count': 0, u'title': u'Some interesting counter-examples to things with probability of $0$ occuring', u'question_id': 2101029, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1484619489, u'creation_date': 1484619489, u'comment_count': 0, u'score': 0, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring/2101078#2101078', u'body_markdown': u'A paradox may provide an example. 

The unexpected hanging paradox ([described here, for example][1]) describes a process for determining that an event has zero probability of occurring, yet the event still occurs.

This, and similar paradoxes, doesn&#39;t require an infinite range of probabilities.  

But given the self-contradictory nature of your premise,  I doubt that you will discover any example that isn&#39;t paradoxical.



  [1]: https://en.wikipedia.org/wiki/Unexpected_hanging_paradox', u'owner': {u'user_id': 23117, u'user_type': u'registered', u'reputation': 507, u'link': u'https://math.stackexchange.com/users/23117/jim', u'accept_rate': 45, u'display_name': u'Jim', u'badge_counts': {u'bronze': 10, u'silver': 2, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2101078', u'answer_id': 2101078}]","Due to [this question][1], I&#39;m wondering about a list of some interesting examples of when the probability that something was going to occur was $0$ and occurs anyways.

I suppose a really basic example could be that the probability that a random number picked between $1$ and $n$ is prime tends to be $0$ as $n\to\infty$, but there are still an infinite amount of primes.

However, I&#39;m interested in less trivial cases (preferably a list) that might very well blow my mind.

Notice: This is not the same as something impossible to occur nor is it the same as something unlikely to occur.  Please see [Zero probability and impossibility][2] for some explanation.


  [1]: https://math.stackexchange.com/questions/2062960/there-exist-infinite-many-n-in-mathbbn-such-that-s-n-s-n-frac1n2
  [2]: https://math.stackexchange.com/questions/41107/zero-probability-and-impossibility","[There is no way to choose a random integer with a probability distribution uniform on the integers: the probability of any particular integer will be $0$.

https://math.stackexchange.com/questions/1880140/is-getting-a-random-integer-even-possible, Maybe an interesting example you have not seen: a Wiener process is a continuous version of a random walk. If I generate a Wiener process for $T$ seconds then the probability of generating exactly this process is 0., If you&#39;re looking for an example of a nonempty set of measure zero, that&#39;s easy: take the set $\{2,5,8\},$ or the Cantor set.

If you&#39;re looking for an example of a &quot;real life&quot; event which has probability zero and happens anyway, forget it: probability zero events don&#39;t happen. Here are a couple of fake examples:

&quot;Toss a coin an infinite number of times; whatever sequence of heads and tails comes up is a probability zero event.&quot;

Nope. In the real world, there is no such thing as an infinite sequence of coin tosses.

&quot;A continuous random variable has to take some real value, but the probability of any real number is zero.&quot;

Nope. In real life, a continuous random variable is never observed to take a real number as its value, it is only observed to land in an interval, which has positive measure.
, If the probability of an event a random variable is $0$ and the event is surely in the set of possible outcomes, then the only way this is possible is if there are an infinite amount of possibilities. 

As it seems to me you are not interested in any cases where there are an infinite amount of outcomes, then nothing &quot;non-trivial&quot; can be found., A paradox may provide an example. 

The unexpected hanging paradox ([described here, for example][1]) describes a process for determining that an event has zero probability of occurring, yet the event still occurs.

This, and similar paradoxes, doesn&#39;t require an infinite range of probabilities.  

But given the self-contradictory nature of your premise,  I doubt that you will discover any example that isn&#39;t paradoxical.



  [1]: https://en.wikipedia.org/wiki/Unexpected_hanging_paradox]",1484659241.0,"Please clarify your specific problem or add additional details to highlight exactly what you need.   As it&#39;s currently written, it‚Äôs hard to tell exactly what you&#39;re asking. See the <a href=""https://math.stackexchange.com/help/how-to-ask"">How to Ask</a> page for help clarifying this question.",False,unclear what you're asking,unclear what you&#39;re asking,14,"[{u'edited': False, u'comment_id': 4319960, u'creation_date': 1484616590, u'post_id': 2101029, u'score': 0, u'post_type': u'question', u'owner': {u'display_name': u'user384138', u'user_type': u'does_not_exist'}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4319960_2101029'}, {u'edited': False, u'comment_id': 4319966, u'creation_date': 1484616673, u'post_id': 2101029, u'score': 3, u'post_type': u'question', u'owner': {u'user_id': 15140, u'user_type': u'registered', u'reputation': 1677, u'link': u'https://math.stackexchange.com/users/15140/dair', u'accept_rate': 86, u'display_name': u'Dair', u'badge_counts': {u'bronze': 23, u'silver': 8, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4319966_2101029'}, {u'edited': False, u'reply_to_user': {u'user_id': 15140, u'user_type': u'registered', u'reputation': 1677, u'link': u'https://math.stackexchange.com/users/15140/dair', u'accept_rate': 86, u'display_name': u'Dair', u'badge_counts': {u'bronze': 23, u'silver': 8, u'gold': 1}}, u'comment_id': 4319974, u'creation_date': 1484616848, u'post_id': 2101029, u'score': 0, u'post_type': u'question', u'owner': {u'display_name': u'user384138', u'user_type': u'does_not_exist'}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4319974_2101029'}, {u'edited': False, u'comment_id': 4319994, u'creation_date': 1484617299, u'post_id': 2101029, u'score': 2, u'post_type': u'question', u'owner': {u'user_id': 114036, u'user_type': u'registered', u'reputation': 58729, u'link': u'https://math.stackexchange.com/users/114036/john-hughes', u'accept_rate': 67, u'display_name': u'John Hughes', u'badge_counts': {u'bronze': 82, u'silver': 36, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4319994_2101029'}, {u'edited': False, u'reply_to_user': {u'user_id': 114036, u'user_type': u'registered', u'reputation': 58729, u'link': u'https://math.stackexchange.com/users/114036/john-hughes', u'accept_rate': 67, u'display_name': u'John Hughes', u'badge_counts': {u'bronze': 82, u'silver': 36, u'gold': 2}}, u'comment_id': 4320000, u'creation_date': 1484617362, u'post_id': 2101029, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 272831, u'user_type': u'registered', u'reputation': 48612, u'link': u'https://math.stackexchange.com/users/272831/simply-beautiful-art', u'accept_rate': 74, u'display_name': u'Simply Beautiful Art', u'badge_counts': {u'bronze': 167, u'silver': 70, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4320000_2101029'}, {u'edited': False, u'comment_id': 4320016, u'creation_date': 1484617833, u'post_id': 2101029, u'score': 0, u'post_type': u'question', u'owner': {u'display_name': u'user378947', u'user_type': u'does_not_exist'}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4320016_2101029'}, {u'edited': False, u'comment_id': 4320018, u'creation_date': 1484617846, u'post_id': 2101029, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 272831, u'user_type': u'registered', u'reputation': 48612, u'link': u'https://math.stackexchange.com/users/272831/simply-beautiful-art', u'accept_rate': 74, u'display_name': u'Simply Beautiful Art', u'badge_counts': {u'bronze': 167, u'silver': 70, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4320018_2101029'}, {u'edited': False, u'comment_id': 4320026, u'creation_date': 1484617995, u'post_id': 2101029, u'score': 1, u'post_type': u'question', u'owner': {u'user_id': 272831, u'user_type': u'registered', u'reputation': 48612, u'link': u'https://math.stackexchange.com/users/272831/simply-beautiful-art', u'accept_rate': 74, u'display_name': u'Simply Beautiful Art', u'badge_counts': {u'bronze': 167, u'silver': 70, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4320026_2101029'}, {u'edited': False, u'comment_id': 4320055, u'creation_date': 1484618596, u'post_id': 2101029, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 75808, u'user_type': u'registered', u'reputation': 45230, u'link': u'https://math.stackexchange.com/users/75808/clement-c', u'accept_rate': 75, u'display_name': u'Clement C.', u'badge_counts': {u'bronze': 80, u'silver': 35, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4320055_2101029'}, {u'edited': False, u'comment_id': 4320061, u'creation_date': 1484618807, u'post_id': 2101029, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 252194, u'user_type': u'registered', u'reputation': 8974, u'link': u'https://math.stackexchange.com/users/252194/morgan-rodgers', u'accept_rate': 75, u'display_name': u'Morgan Rodgers', u'badge_counts': {u'bronze': 37, u'silver': 11, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4320061_2101029'}, {u'edited': False, u'reply_to_user': {u'user_id': 252194, u'user_type': u'registered', u'reputation': 8974, u'link': u'https://math.stackexchange.com/users/252194/morgan-rodgers', u'accept_rate': 75, u'display_name': u'Morgan Rodgers', u'badge_counts': {u'bronze': 37, u'silver': 11, u'gold': 2}}, u'comment_id': 4320857, u'creation_date': 1484655739, u'post_id': 2101029, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 272831, u'user_type': u'registered', u'reputation': 48612, u'link': u'https://math.stackexchange.com/users/272831/simply-beautiful-art', u'accept_rate': 74, u'display_name': u'Simply Beautiful Art', u'badge_counts': {u'bronze': 167, u'silver': 70, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4320857_2101029'}, {u'edited': False, u'comment_id': 4321372, u'creation_date': 1484666759, u'post_id': 2101029, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 252194, u'user_type': u'registered', u'reputation': 8974, u'link': u'https://math.stackexchange.com/users/252194/morgan-rodgers', u'accept_rate': 75, u'display_name': u'Morgan Rodgers', u'badge_counts': {u'bronze': 37, u'silver': 11, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4321372_2101029'}, {u'edited': False, u'reply_to_user': {u'user_id': 252194, u'user_type': u'registered', u'reputation': 8974, u'link': u'https://math.stackexchange.com/users/252194/morgan-rodgers', u'accept_rate': 75, u'display_name': u'Morgan Rodgers', u'badge_counts': {u'bronze': 37, u'silver': 11, u'gold': 2}}, u'comment_id': 4321378, u'creation_date': 1484666838, u'post_id': 2101029, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 272831, u'user_type': u'registered', u'reputation': 48612, u'link': u'https://math.stackexchange.com/users/272831/simply-beautiful-art', u'accept_rate': 74, u'display_name': u'Simply Beautiful Art', u'badge_counts': {u'bronze': 167, u'silver': 70, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4321378_2101029'}, {u'edited': False, u'comment_id': 4321380, u'creation_date': 1484666858, u'post_id': 2101029, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 252194, u'user_type': u'registered', u'reputation': 8974, u'link': u'https://math.stackexchange.com/users/252194/morgan-rodgers', u'accept_rate': 75, u'display_name': u'Morgan Rodgers', u'badge_counts': {u'bronze': 37, u'silver': 11, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring#comment4321380_2101029'}]",1484616089,3,0,True,1484622916,1492086060.0,https://math.stackexchange.com/questions/2101029/some-interesting-counter-examples-to-things-with-probability-of-0-occuring,74.0,167.0,5.0,70.0,Simply Beautiful Art,https://math.stackexchange.com/users/272831/simply-beautiful-art,48612.0,272831.0,registered,,2101029,0,https://math.stackexchange.com/q/2101029,"[probability, examples-counterexamples, big-list]",Some interesting counter-examples to things with probability of $0$ occuring,3,189
14,2062022.0,2,"[{u'up_vote_count': 2, u'title': u'Independent with a vector v.s. independent with its components', u'question_id': 2061930, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1481964941, u'creation_date': 1481958980, u'comment_count': 0, u'score': 2, u'link': u'https://math.stackexchange.com/questions/2061930/independent-with-a-vector-v-s-independent-with-its-components/2062022#2062022', u'body_markdown': u'Yes, in general the converse is not correct. The reason is, essentially, that pairwise independence does not imply independence.

**Example** Let $\Omega := \{0,1\}^2$ and $\mathbb{P}(\{\omega\}) := 1/4$, $\omega \in \Omega$. For $\omega = (\omega_1,\omega_2)$ define

$$X_1(\omega) := \omega_1 \qquad X_2(\omega) := \omega_2 \qquad Z(\omega) :=1_{\{\omega_1=\omega_2\}}.$$

Then it is not difficult to see that

$$ \mathbb{P}(X_1 = i, Z=j) = \frac{1}{4} = \mathbb{P}(X_1=i) \mathbb{P}(Z=j)$$

for any $i,j \in \{0,1\}$ which shows that $X_1$ and $Z$ are independent. In an analogous way we find that $X_2$ and $Z$ are independent. However, $Z$ and $X:=(X_1,X_2)$ are not independent since

$$\mathbb{P}(Z=1, X=(1,1)) = \frac{1}{4} \neq \frac{1}{8} = \mathbb{P}(Z=1) \mathbb{P}(X=(1,1)).$$


', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'is_accepted': True, u'last_edit_date': 1481964941, u'share_link': u'https://math.stackexchange.com/a/2062022', u'answer_id': 2062022}, {u'up_vote_count': 1, u'title': u'Independent with a vector v.s. independent with its components', u'question_id': 2061930, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1481961308, u'comments': [{u'edited': False, u'comment_id': 4233372, u'creation_date': 1481977888, u'post_id': 2062037, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 178464, u'user_type': u'registered', u'reputation': 6751, u'link': u'https://math.stackexchange.com/users/178464/yurnero', u'accept_rate': 65, u'display_name': u'yurnero', u'badge_counts': {u'bronze': 23, u'silver': 8, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/2061930/independent-with-a-vector-v-s-independent-with-its-components/2062037#comment4233372_2062037'}], u'creation_date': 1481960957, u'comment_count': 1, u'score': 1, u'link': u'https://math.stackexchange.com/questions/2061930/independent-with-a-vector-v-s-independent-with-its-components/2062037#2062037', u'body_markdown': u'I is not only about the joint distribution of $(X_1, \dots, X_n)$.
It is possible that all components of $X$, namely  $(X_1, \dots, X_n)$ are independent and that all pairs $(Z,X_i)$ are independent, but $Z$ is not independent from $X$. 

My favorite example to illustrate this is from Bauer&#39;s book *Wahrscheinlichkeitstheorie* (it&#39;s a german book):
Suppose you throw a fair dice two times and let $Y_i$ denote the outcome of the $i$-th throw. We define:
$$
X_1= \begin{cases}1, &amp; \text{if} \ Y_1 \ \text{is odd} \\ 0, &amp; \text{if} \ Y_1 \ \text{is even} \end{cases}, \quad
X_2= \begin{cases}1, &amp; \text{if} \ Y_2 \ \text{is odd} \\ 0, &amp; \text{if} \ Y_2 \ \text{is even} \end{cases}, \quad 
Z= \begin{cases}1, &amp; \text{if} \ Y_1+Y_2 \ \text{is odd} \\ 0, &amp; \text{if} \ Y_1+Y_2 \ \text{is even} \end{cases}, 
$$ 
Clearly $X_1$ and $X_2$ are indpendent and it is also easily verified that $Z$ is independent from $X_1$ and that $Z$ is independent from $X_2$. However $Z$ is not independent from $X$.

This easily generalizes to $n \geq 2$: you throw a fair dice $n$ times and define $X_i$ as above and $Z$ is again defined via the sum of $Y_1, \dots, Y_n$.
The intuition is that knowing the results of all $X_i$ except one, say $X_n$, the outcome of $Z$ and the outcome of $X_n$ contain the same information.', u'owner': {u'user_id': 397540, u'user_type': u'registered', u'reputation': 1737, u'link': u'https://math.stackexchange.com/users/397540/cettt', u'display_name': u'Cettt', u'badge_counts': {u'bronze': 20, u'silver': 4, u'gold': 0}}, u'is_accepted': False, u'last_edit_date': 1481961308, u'share_link': u'https://math.stackexchange.com/a/2062037', u'answer_id': 2062037}]","Suppose that $Z$ (a scalar) is independent with $X=(X_1,\ldots,X_n)$, $n&gt;1$. Then, $Z$ is independent with $X_1,\ldots,X_n$ because each of the latter is a function of $X$.

I suspect the reverse direction: $Z$ being independent with $X_1,\ldots,X_n$ implying $Z$ being independent with $X$ is **not** true. Most likely because we would need some info about the joint distribution of $X_1,\ldots,X_n$. But I can&#39;t think of a counter example. So could you please provide one as well as some intuition on how you arrive at it?","[Yes, in general the converse is not correct. The reason is, essentially, that pairwise independence does not imply independence.

**Example** Let $\Omega := \{0,1\}^2$ and $\mathbb{P}(\{\omega\}) := 1/4$, $\omega \in \Omega$. For $\omega = (\omega_1,\omega_2)$ define

$$X_1(\omega) := \omega_1 \qquad X_2(\omega) := \omega_2 \qquad Z(\omega) :=1_{\{\omega_1=\omega_2\}}.$$

Then it is not difficult to see that

$$ \mathbb{P}(X_1 = i, Z=j) = \frac{1}{4} = \mathbb{P}(X_1=i) \mathbb{P}(Z=j)$$

for any $i,j \in \{0,1\}$ which shows that $X_1$ and $Z$ are independent. In an analogous way we find that $X_2$ and $Z$ are independent. However, $Z$ and $X:=(X_1,X_2)$ are not independent since

$$\mathbb{P}(Z=1, X=(1,1)) = \frac{1}{4} \neq \frac{1}{8} = \mathbb{P}(Z=1) \mathbb{P}(X=(1,1)).$$


, I is not only about the joint distribution of $(X_1, \dots, X_n)$.
It is possible that all components of $X$, namely  $(X_1, \dots, X_n)$ are independent and that all pairs $(Z,X_i)$ are independent, but $Z$ is not independent from $X$. 

My favorite example to illustrate this is from Bauer&#39;s book *Wahrscheinlichkeitstheorie* (it&#39;s a german book):
Suppose you throw a fair dice two times and let $Y_i$ denote the outcome of the $i$-th throw. We define:
$$
X_1= \begin{cases}1, &amp; \text{if} \ Y_1 \ \text{is odd} \\ 0, &amp; \text{if} \ Y_1 \ \text{is even} \end{cases}, \quad
X_2= \begin{cases}1, &amp; \text{if} \ Y_2 \ \text{is odd} \\ 0, &amp; \text{if} \ Y_2 \ \text{is even} \end{cases}, \quad 
Z= \begin{cases}1, &amp; \text{if} \ Y_1+Y_2 \ \text{is odd} \\ 0, &amp; \text{if} \ Y_1+Y_2 \ \text{is even} \end{cases}, 
$$ 
Clearly $X_1$ and $X_2$ are indpendent and it is also easily verified that $Z$ is independent from $X_1$ and that $Z$ is independent from $X_2$. However $Z$ is not independent from $X$.

This easily generalizes to $n \geq 2$: you throw a fair dice $n$ times and define $X_i$ as above and $Z$ is again defined via the sum of $Y_1, \dots, Y_n$.
The intuition is that knowing the results of all $X_i$ except one, say $X_n$, the outcome of $Z$ and the outcome of $X_n$ contain the same information.]",,,,,,0,,1481944779,0,2,True,1481964941,1481945186.0,https://math.stackexchange.com/questions/2061930/independent-with-a-vector-v-s-independent-with-its-components,65.0,23.0,1.0,8.0,yurnero,https://math.stackexchange.com/users/178464/yurnero,6751.0,178464.0,registered,,2061930,0,https://math.stackexchange.com/q/2061930,"[probability, examples-counterexamples, independence]",Independent with a vector v.s. independent with its components,0,46
15,,3,"[{u'up_vote_count': 4, u'title': u'Looking for counter-intuitive example for independence of random variables', u'question_id': 1929717, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1474062657, u'creation_date': 1474062657, u'comment_count': 0, u'score': 4, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables/1929725#1929725', u'body_markdown': u'[Gambler&#39;s Fallacy][1] is a pretty good example. People often expect past events to interfere with future independent events. For instance, if you flipped a coin ten times and got heads all ten times, you would expect to get tails the next time, even though the last ten flips have no effect on the next flip.

[1]: https://en.m.wikipedia.org/wiki/Gambler%27s_fallacy', u'owner': {u'user_id': 355874, u'user_type': u'registered', u'reputation': 4107, u'link': u'https://math.stackexchange.com/users/355874/algorithmsx', u'accept_rate': 71, u'display_name': u'AlgorithmsX', u'badge_counts': {u'bronze': 28, u'silver': 7, u'gold': 1}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/1929725', u'answer_id': 1929725}, {u'up_vote_count': 5, u'title': u'Looking for counter-intuitive example for independence of random variables', u'question_id': 1929717, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1474153910, u'comments': [{u'edited': False, u'comment_id': 3962479, u'creation_date': 1474112576, u'post_id': 1929740, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 183815, u'user_type': u'registered', u'reputation': 1268, u'link': u'https://math.stackexchange.com/users/183815/hamsterrific', u'accept_rate': 77, u'display_name': u'Hamsterrific', u'badge_counts': {u'bronze': 21, u'silver': 6, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables/1929740#comment3962479_1929740'}, {u'edited': False, u'reply_to_user': {u'user_id': 183815, u'user_type': u'registered', u'reputation': 1268, u'link': u'https://math.stackexchange.com/users/183815/hamsterrific', u'accept_rate': 77, u'display_name': u'Hamsterrific', u'badge_counts': {u'bronze': 21, u'silver': 6, u'gold': 1}}, u'comment_id': 3962511, u'creation_date': 1474114417, u'post_id': 1929740, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 70849, u'user_type': u'registered', u'reputation': 111, u'link': u'https://math.stackexchange.com/users/70849/bakuriu', u'display_name': u'Bakuriu', u'badge_counts': {u'bronze': 5, u'silver': 1, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables/1929740#comment3962511_1929740'}, {u'edited': False, u'reply_to_user': {u'user_id': 70849, u'user_type': u'registered', u'reputation': 111, u'link': u'https://math.stackexchange.com/users/70849/bakuriu', u'display_name': u'Bakuriu', u'badge_counts': {u'bronze': 5, u'silver': 1, u'gold': 0}}, u'comment_id': 3963803, u'creation_date': 1474153867, u'post_id': 1929740, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 224454, u'user_type': u'registered', u'reputation': 24381, u'link': u'https://math.stackexchange.com/users/224454/brian-tung', u'display_name': u'Brian Tung', u'badge_counts': {u'bronze': 51, u'silver': 23, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables/1929740#comment3963803_1929740'}], u'creation_date': 1474064194, u'comment_count': 3, u'score': 5, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables/1929740#1929740', u'body_markdown': u'Along the lines of Michael&#39;s suggestion in the comments, we have the finger game of &quot;odds and evens&quot;.  Assuming each person&#39;s play is i.i.d.* at $50$-$50$ (by no means a guarantee, to be sure), the result is *statistically* independent of either person&#39;s play in isolation, but of course is completely determined by their joint play.

---

*i.i.d. = identically and independently distributed (thanks to Bakuriu for clarifying this for the OP in the comments)', u'owner': {u'user_id': 224454, u'user_type': u'registered', u'reputation': 24381, u'link': u'https://math.stackexchange.com/users/224454/brian-tung', u'display_name': u'Brian Tung', u'badge_counts': {u'bronze': 51, u'silver': 23, u'gold': 2}}, u'is_accepted': False, u'last_edit_date': 1474153910, u'share_link': u'https://math.stackexchange.com/a/1929740', u'answer_id': 1929740}, {u'up_vote_count': 11, u'title': u'Looking for counter-intuitive example for independence of random variables', u'question_id': 1929717, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1474069644, u'creation_date': 1474064200, u'comment_count': 0, u'score': 11, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables/1929741#1929741', u'body_markdown': u'A classic basic example of events that seem dependent, but aren&#39;t, is when flipping two coins:

- $A$ is the event that coin 1 is heads.

- $B$ is the event that coin 1 and coin 2 are the same.

If you don&#39;t think about it too hard, it seems like the value of coin 1 is important or relevant when determining if coins 1 and 2 are equal, and therefore it is intuitively tempting to say $A$ is relevant to $B$ or in other words they are not independent.
', u'owner': {u'user_id': 68107, u'user_type': u'registered', u'reputation': 34303, u'link': u'https://math.stackexchange.com/users/68107/6005', u'accept_rate': 80, u'display_name': u'6005', u'badge_counts': {u'bronze': 119, u'silver': 47, u'gold': 7}}, u'is_accepted': False, u'last_edit_date': 1474069644, u'share_link': u'https://math.stackexchange.com/a/1929741', u'answer_id': 1929741}]",I am looking for a simple example of two independent discrete random variables that one would not expect to be independent because one knows that these two quantities have a causal relationship in real life.,"[[Gambler&#39;s Fallacy][1] is a pretty good example. People often expect past events to interfere with future independent events. For instance, if you flipped a coin ten times and got heads all ten times, you would expect to get tails the next time, even though the last ten flips have no effect on the next flip.

[1]: https://en.m.wikipedia.org/wiki/Gambler%27s_fallacy, Along the lines of Michael&#39;s suggestion in the comments, we have the finger game of &quot;odds and evens&quot;.  Assuming each person&#39;s play is i.i.d.* at $50$-$50$ (by no means a guarantee, to be sure), the result is *statistically* independent of either person&#39;s play in isolation, but of course is completely determined by their joint play.

---

*i.i.d. = identically and independently distributed (thanks to Bakuriu for clarifying this for the OP in the comments), A classic basic example of events that seem dependent, but aren&#39;t, is when flipping two coins:

- $A$ is the event that coin 1 is heads.

- $B$ is the event that coin 1 and coin 2 are the same.

If you don&#39;t think about it too hard, it seems like the value of coin 1 is important or relevant when determining if coins 1 and 2 are equal, and therefore it is intuitively tempting to say $A$ is relevant to $B$ or in other words they are not independent.
]",,,,,,8,"[{u'edited': False, u'comment_id': 3961564, u'creation_date': 1474062376, u'post_id': 1929717, u'score': 2, u'post_type': u'question', u'owner': {u'user_id': 355874, u'user_type': u'registered', u'reputation': 4107, u'link': u'https://math.stackexchange.com/users/355874/algorithmsx', u'accept_rate': 71, u'display_name': u'AlgorithmsX', u'badge_counts': {u'bronze': 28, u'silver': 7, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables#comment3961564_1929717'}, {u'edited': False, u'comment_id': 3961569, u'creation_date': 1474062776, u'post_id': 1929717, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 355874, u'user_type': u'registered', u'reputation': 4107, u'link': u'https://math.stackexchange.com/users/355874/algorithmsx', u'accept_rate': 71, u'display_name': u'AlgorithmsX', u'badge_counts': {u'bronze': 28, u'silver': 7, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables#comment3961569_1929717'}, {u'edited': False, u'comment_id': 3961575, u'creation_date': 1474063022, u'post_id': 1929717, u'score': 3, u'post_type': u'question', u'owner': {u'user_id': 291201, u'user_type': u'registered', u'reputation': 49455, u'link': u'https://math.stackexchange.com/users/291201/dxiv', u'display_name': u'dxiv', u'badge_counts': {u'bronze': 87, u'silver': 39, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables#comment3961575_1929717'}, {u'edited': False, u'comment_id': 3961582, u'creation_date': 1474063477, u'post_id': 1929717, u'score': 2, u'post_type': u'question', u'owner': {u'user_id': 155065, u'user_type': u'registered', u'reputation': 11879, u'link': u'https://math.stackexchange.com/users/155065/michael', u'display_name': u'Michael', u'badge_counts': {u'bronze': 23, u'silver': 11, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables#comment3961582_1929717'}, {u'edited': False, u'reply_to_user': {u'user_id': 355874, u'user_type': u'registered', u'reputation': 4107, u'link': u'https://math.stackexchange.com/users/355874/algorithmsx', u'accept_rate': 71, u'display_name': u'AlgorithmsX', u'badge_counts': {u'bronze': 28, u'silver': 7, u'gold': 1}}, u'comment_id': 3961589, u'creation_date': 1474064052, u'post_id': 1929717, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 68107, u'user_type': u'registered', u'reputation': 34303, u'link': u'https://math.stackexchange.com/users/68107/6005', u'accept_rate': 80, u'display_name': u'6005', u'badge_counts': {u'bronze': 119, u'silver': 47, u'gold': 7}}, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables#comment3961589_1929717'}, {u'edited': False, u'comment_id': 3961591, u'creation_date': 1474064183, u'post_id': 1929717, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 68107, u'user_type': u'registered', u'reputation': 34303, u'link': u'https://math.stackexchange.com/users/68107/6005', u'accept_rate': 80, u'display_name': u'6005', u'badge_counts': {u'bronze': 119, u'silver': 47, u'gold': 7}}, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables#comment3961591_1929717'}, {u'edited': False, u'comment_id': 3962047, u'creation_date': 1474090656, u'post_id': 1929717, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 30836, u'user_type': u'registered', u'reputation': 27447, u'link': u'https://math.stackexchange.com/users/30836/micah', u'accept_rate': 75, u'display_name': u'Micah', u'badge_counts': {u'bronze': 96, u'silver': 56, u'gold': 13}}, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables#comment3962047_1929717'}, {u'edited': False, u'comment_id': 3962137, u'creation_date': 1474095702, u'post_id': 1929717, u'score': 2, u'post_type': u'question', u'owner': {u'user_id': 2439, u'user_type': u'registered', u'reputation': 4109, u'link': u'https://math.stackexchange.com/users/2439/peter-lefanu-lumsdaine', u'display_name': u'Peter LeFanu Lumsdaine', u'badge_counts': {u'bronze': 39, u'silver': 15, u'gold': 3}}, u'link': u'https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables#comment3962137_1929717'}]",1474062045,3,2,True,1474153910,,https://math.stackexchange.com/questions/1929717/looking-for-counter-intuitive-example-for-independence-of-random-variables,,1.0,0.0,0.0,Salamander,https://math.stackexchange.com/users/369621/salamander,32.0,369621.0,unregistered,,1929717,4,https://math.stackexchange.com/q/1929717,"[probability, examples-counterexamples, independence]",Looking for counter-intuitive example for independence of random variables,7,325
16,,2,"[{u'up_vote_count': 2, u'title': u'Change of measure to make things &quot;easier&quot;?', u'question_id': 1928251, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1473962812, u'comments': [{u'edited': False, u'comment_id': 3958816, u'creation_date': 1473962885, u'post_id': 1928267, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 79950, u'user_type': u'registered', u'reputation': 144, u'link': u'https://math.stackexchange.com/users/79950/user79950', u'accept_rate': 56, u'display_name': u'user79950', u'badge_counts': {u'bronze': 8, u'silver': 1, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1928251/change-of-measure-to-make-things-easier/1928267#comment3958816_1928267'}, {u'edited': False, u'reply_to_user': {u'user_id': 79950, u'user_type': u'registered', u'reputation': 144, u'link': u'https://math.stackexchange.com/users/79950/user79950', u'accept_rate': 56, u'display_name': u'user79950', u'badge_counts': {u'bronze': 8, u'silver': 1, u'gold': 0}}, u'comment_id': 3958895, u'creation_date': 1473964368, u'post_id': 1928267, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 271624, u'user_type': u'registered', u'reputation': 669, u'link': u'https://math.stackexchange.com/users/271624/measure-theory', u'display_name': u'measure_theory', u'badge_counts': {u'bronze': 11, u'silver': 2, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1928251/change-of-measure-to-make-things-easier/1928267#comment3958895_1928267'}, {u'edited': False, u'comment_id': 3959075, u'creation_date': 1473969732, u'post_id': 1928267, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 79950, u'user_type': u'registered', u'reputation': 144, u'link': u'https://math.stackexchange.com/users/79950/user79950', u'accept_rate': 56, u'display_name': u'user79950', u'badge_counts': {u'bronze': 8, u'silver': 1, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1928251/change-of-measure-to-make-things-easier/1928267#comment3959075_1928267'}, {u'edited': False, u'comment_id': 3961406, u'creation_date': 1474056933, u'post_id': 1928267, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 79950, u'user_type': u'registered', u'reputation': 144, u'link': u'https://math.stackexchange.com/users/79950/user79950', u'accept_rate': 56, u'display_name': u'user79950', u'badge_counts': {u'bronze': 8, u'silver': 1, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1928251/change-of-measure-to-make-things-easier/1928267#comment3961406_1928267'}], u'creation_date': 1473962812, u'comment_count': 4, u'score': 2, u'link': u'https://math.stackexchange.com/questions/1928251/change-of-measure-to-make-things-easier/1928267#1928267', u'body_markdown': u'One example where a change of measure can make calculations simpler is the [risk-neutral measure](https://en.wikipedia.org/wiki/Risk-neutral_measure) used commonly in finance.

Assume the price of a stock, $S_t$ satisfies the following SDE:

$$dS_t = \mu S_t + \sigma S_t dW_t$$

where $W_t$ is Brownian Motion. Using Girsonv&#39;s theorem, you can express the discounted stock price, $\tilde{S_t} = e^{-rt}S_t$ as 

$$d\tilde{S_t} = \sigma \tilde{S_t}d\tilde{W_t}$$

Where $\tilde{W_t} = W_t + \frac{\mu - r}{\sigma} t$ is a martingale under a change of measure, $\mathbb{Q}$.

Under the original probability measure, $\mathbb{P}$, $\tilde{W_t}$ is *not* a martingale nor Brownian motion, but under the risk neutral measure, $\mathbb{Q}$, it is.

Since martingales have a lot of useful properties and are typically easier to manipulate than non-martingales, this is an example where the change-of-measure makes things easier.', u'owner': {u'user_id': 271624, u'user_type': u'registered', u'reputation': 669, u'link': u'https://math.stackexchange.com/users/271624/measure-theory', u'display_name': u'measure_theory', u'badge_counts': {u'bronze': 11, u'silver': 2, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/1928267', u'answer_id': 1928267}, {u'up_vote_count': 0, u'title': u'Change of measure to make things &quot;easier&quot;?', u'question_id': 1928251, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1481891629, u'creation_date': 1481891629, u'comment_count': 0, u'score': 0, u'link': u'https://math.stackexchange.com/questions/1928251/change-of-measure-to-make-things-easier/2061157#2061157', u'body_markdown': u'Here are two examples from filtering and estimation theory:

 1. In filtering theory, the reference measure approach makes it easier to find equations for the conditional expectations $E_P[\varphi(X_t)|\mathcal{F}^Y_t]$. The idea is to pick a reference measure $Q$ under which the state and observation processes decouple (become independent), and the observation process is some way simple. In the classical filtering problem, where the state and observation processes are diffusion process driven by independent Brownian motions and the observation noise is additive, the Girsanov theorem guarantees that we can pick a reference measure under which $Y$ becomes a Brownian motion independent of the parameters and the state $X$. We can then use the Kallianpur-Striebel formula in order to express the conditional expectations with respect to the original measure in terms of the reference measure, i.e.
$$E_P[\varphi(X_t)|\mathcal{F}^Y_t]=\frac{E_Q[\tfrac{dP}{dQ}\varphi(X_t)|\mathcal{F}^Y_t]}{E_Q[\tfrac{dP}{dQ}|\mathcal{F}^Y_t]}.$$
It turns out that the expectations on the RHS are much easier to work with. This idea generalizes to a wide class of filtering problems.

 2. If you have a partially observed system for which you want to estimate some parameters, you can try to find a reference measure under which the observed process is simple. To do maximum likelihood estimation, you have to restrict the measure to the observed process. For a finite number of random variables, some of which are hidden and some of which are observed, we would integrate over the hidden variables (marginalization) in order to get the probability of observed states. In the continuous-time case, this would mean that we need to integrate over all possible trajectories of the hidden process. By picking a reference measure that is independent of the parameters, we can write down a likelihood function as the Radon-Nikodym derivative of the original measure wrt. the reference measure. For the case of partially observed diffusion processes, more details can be found in [Online Maximum Likelihood Estimation of the Parameters of Partially Observed Diffusion Processes][1].


  [1]: https://arxiv.org/abs/1611.00170', u'owner': {u'user_id': 227280, u'user_type': u'registered', u'reputation': 322, u'link': u'https://math.stackexchange.com/users/227280/s-surace', u'display_name': u'S.Surace', u'badge_counts': {u'bronze': 9, u'silver': 2, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/2061157', u'answer_id': 2061157}]","I am familiar with the Radon-Nikodym Theorem and an R/N Derivative, but while reading a set of lecture notes on: [Stochastic Calculus, Filtering, and Stochastic Control][1] in section 1.6: &quot;Induced measures, independence, and absolute continuity&quot;, (bottom of page 42, emphasis mine):

&gt; **Absolutely continuous measures and the Radon-Nikodym theorem**
&gt; 
&gt; Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a given probability space.
&gt; It is often interesting to try to find other measures on $\mathcal{F}$
&gt; with different properties. We may have gone through some trouble to
&gt; construct a measure $\mathbb{P}$, but once we have such a measure, we
&gt; can generate a large family of related measures using a rather simple
&gt; technique. This idea will come in very handy in many situations;
&gt; **calculations which are difficult under one measure can often become
&gt; very simple if we change to a suitably modiÔ¨Åed measure** (for example,
&gt; if $\{X_n\}$ is a collection of random variables with some complicated
&gt; dependencies under $\mathbb{P}$, it may be advantageous to compute
&gt; using a modiÔ¨Åed measure $\mathbb{Q}$ under which the $X_n$ are
&gt; independent. Later on, the change of measure concept will form the basis form one of the most basic tools in our stochastic toolbox, the Girsanov theorem.

I&#39;m having trouble conceptualizing the idea that &quot;calculations which are difficult under one measure can often become very simple if we change to a suitably modiÔ¨Åed measure&quot;. Can someone further explain, perhaps by a couple examples, how this is the case? How can $X_n$ have complicated dependencies under $\mathbb{P}$, but simple (independent) dependencies under a $\mathbb{Q}$? 

  [1]: https://www.princeton.edu/~rvan/acm217/ACM217.pdf","[One example where a change of measure can make calculations simpler is the [risk-neutral measure](https://en.wikipedia.org/wiki/Risk-neutral_measure) used commonly in finance.

Assume the price of a stock, $S_t$ satisfies the following SDE:

$$dS_t = \mu S_t + \sigma S_t dW_t$$

where $W_t$ is Brownian Motion. Using Girsonv&#39;s theorem, you can express the discounted stock price, $\tilde{S_t} = e^{-rt}S_t$ as 

$$d\tilde{S_t} = \sigma \tilde{S_t}d\tilde{W_t}$$

Where $\tilde{W_t} = W_t + \frac{\mu - r}{\sigma} t$ is a martingale under a change of measure, $\mathbb{Q}$.

Under the original probability measure, $\mathbb{P}$, $\tilde{W_t}$ is *not* a martingale nor Brownian motion, but under the risk neutral measure, $\mathbb{Q}$, it is.

Since martingales have a lot of useful properties and are typically easier to manipulate than non-martingales, this is an example where the change-of-measure makes things easier., Here are two examples from filtering and estimation theory:

 1. In filtering theory, the reference measure approach makes it easier to find equations for the conditional expectations $E_P[\varphi(X_t)|\mathcal{F}^Y_t]$. The idea is to pick a reference measure $Q$ under which the state and observation processes decouple (become independent), and the observation process is some way simple. In the classical filtering problem, where the state and observation processes are diffusion process driven by independent Brownian motions and the observation noise is additive, the Girsanov theorem guarantees that we can pick a reference measure under which $Y$ becomes a Brownian motion independent of the parameters and the state $X$. We can then use the Kallianpur-Striebel formula in order to express the conditional expectations with respect to the original measure in terms of the reference measure, i.e.
$$E_P[\varphi(X_t)|\mathcal{F}^Y_t]=\frac{E_Q[\tfrac{dP}{dQ}\varphi(X_t)|\mathcal{F}^Y_t]}{E_Q[\tfrac{dP}{dQ}|\mathcal{F}^Y_t]}.$$
It turns out that the expectations on the RHS are much easier to work with. This idea generalizes to a wide class of filtering problems.

 2. If you have a partially observed system for which you want to estimate some parameters, you can try to find a reference measure under which the observed process is simple. To do maximum likelihood estimation, you have to restrict the measure to the observed process. For a finite number of random variables, some of which are hidden and some of which are observed, we would integrate over the hidden variables (marginalization) in order to get the probability of observed states. In the continuous-time case, this would mean that we need to integrate over all possible trajectories of the hidden process. By picking a reference measure that is independent of the parameters, we can write down a likelihood function as the Radon-Nikodym derivative of the original measure wrt. the reference measure. For the case of partially observed diffusion processes, more details can be found in [Online Maximum Likelihood Estimation of the Parameters of Partially Observed Diffusion Processes][1].


  [1]: https://arxiv.org/abs/1611.00170]",,,,,,0,,1473962126,0,2,True,1481891629,1474043906.0,https://math.stackexchange.com/questions/1928251/change-of-measure-to-make-things-easier,56.0,8.0,0.0,1.0,user79950,https://math.stackexchange.com/users/79950/user79950,144.0,79950.0,registered,,1928251,3,https://math.stackexchange.com/q/1928251,"[probability, probability-theory, measure-theory, examples-counterexamples]",Change of measure to make things &quot;easier&quot;?,3,122
17,1791887.0,1,"[{u'up_vote_count': 5, u'title': u'Counterexample that a measurable function does not guarantee almost sure convergence', u'question_id': 1791882, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1463675505, u'comments': [{u'edited': False, u'comment_id': 3658388, u'creation_date': 1463690267, u'post_id': 1791887, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 189130, u'user_type': u'registered', u'reputation': 12038, u'link': u'https://math.stackexchange.com/users/189130/john-dawkins', u'display_name': u'John Dawkins', u'badge_counts': {u'bronze': 16, u'silver': 9, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1791882/counterexample-that-a-measurable-function-does-not-guarantee-almost-sure-converg/1791887#comment3658388_1791887'}], u'creation_date': 1463675505, u'comment_count': 1, u'score': 5, u'link': u'https://math.stackexchange.com/questions/1791882/counterexample-that-a-measurable-function-does-not-guarantee-almost-sure-converg/1791887#1791887', u'body_markdown': u'This would be true if $g$ were continuous with no other assumptions. If you make $g$ discontinuous then &quot;generically&quot; this convergence fails.

To be more specific, here is a simple approach: assume $X_n$ converges a.s. to some fixed constant $c$, but that the $X_n$ are never equal to $c$. Then define $g(c)$ to have one value and $g(x)$ to have some other value when $x \neq c$.', u'owner': {u'user_id': 83396, u'user_type': u'registered', u'reputation': 64295, u'link': u'https://math.stackexchange.com/users/83396/ian', u'accept_rate': 71, u'display_name': u'Ian', u'badge_counts': {u'bronze': 79, u'silver': 44, u'gold': 2}}, u'is_accepted': True, u'share_link': u'https://math.stackexchange.com/a/1791887', u'answer_id': 1791887}]","I try to find a counterexample that if $X_n\xrightarrow{\text{a.s.}}X$ then for a measurable function $g:\mathbb{R}\to \mathbb{R}$ this does not imply that $$g(X_n)\xrightarrow{\text{a.s.}}g(X)$$

Unfortunately I have no idea.","[This would be true if $g$ were continuous with no other assumptions. If you make $g$ discontinuous then &quot;generically&quot; this convergence fails.

To be more specific, here is a simple approach: assume $X_n$ converges a.s. to some fixed constant $c$, but that the $X_n$ are never equal to $c$. Then define $g(c)$ to have one value and $g(x)$ to have some other value when $x \neq c$.]",,,,,,0,,1463675203,0,0,True,1463747836,1463747836.0,https://math.stackexchange.com/questions/1791882/counterexample-that-a-measurable-function-does-not-guarantee-almost-sure-converg,94.0,12.0,0.0,5.0,Matriz,https://math.stackexchange.com/users/185346/matriz,838.0,185346.0,registered,,1791882,1,https://math.stackexchange.com/q/1791882,"[probability, probability-theory, convergence, examples-counterexamples]",Counterexample that a measurable function does not guarantee almost sure convergence,1,79
18,1706496.0,1,"[{u'up_vote_count': 3, u'title': u'A positive square integrable random variable whit non square integrable inverse', u'question_id': 1706485, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1459257369, u'comments': [{u'edited': False, u'comment_id': 3507872, u'creation_date': 1459248778, u'post_id': 1706496, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 62973, u'user_type': u'registered', u'reputation': 23, u'link': u'https://math.stackexchange.com/users/62973/j-c', u'display_name': u'J.C.', u'badge_counts': {u'bronze': 5, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1706485/a-positive-square-integrable-random-variable-whit-non-square-integrable-inverse/1706496#comment3507872_1706496'}, {u'edited': False, u'reply_to_user': {u'user_id': 62973, u'user_type': u'registered', u'reputation': 23, u'link': u'https://math.stackexchange.com/users/62973/j-c', u'display_name': u'J.C.', u'badge_counts': {u'bronze': 5, u'silver': 0, u'gold': 0}}, u'comment_id': 3508167, u'creation_date': 1459257403, u'post_id': 1706496, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 189130, u'user_type': u'registered', u'reputation': 12038, u'link': u'https://math.stackexchange.com/users/189130/john-dawkins', u'display_name': u'John Dawkins', u'badge_counts': {u'bronze': 16, u'silver': 9, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1706485/a-positive-square-integrable-random-variable-whit-non-square-integrable-inverse/1706496#comment3508167_1706496'}], u'creation_date': 1458517148, u'comment_count': 2, u'score': 3, u'link': u'https://math.stackexchange.com/questions/1706485/a-positive-square-integrable-random-variable-whit-non-square-integrable-inverse/1706496#1706496', u'body_markdown': u'How about an exponential random variable? (Or any other positive square-integrable random variable with a density function that is bounded away from $0$ in a neighborhood of $0$.)

**More detail:** Let $X$ be a positive random variable with $\Bbb E[X^2]&lt;\infty$ and density $f_X$ such that $f_X(x)\ge\delta&gt;$ for $0&lt;x&lt;x_0$. (An exponential random variable is a specific example.) Then
$$
\eqalign{
\Bbb E[X^{-2}]
&amp;=\int_0^\infty x^{-2} f_X(x)\,dx
=\int_0^\infty f_X(t^{-1})\,dt\cr
&amp;\ge\int_{1/x_0}^\infty f_X(t^{-1})\,dt
\ge\int_{1/x_0}^\infty \delta\,dt=\infty.\cr
}
$$', u'owner': {u'user_id': 189130, u'user_type': u'registered', u'reputation': 12038, u'link': u'https://math.stackexchange.com/users/189130/john-dawkins', u'display_name': u'John Dawkins', u'badge_counts': {u'bronze': 16, u'silver': 9, u'gold': 1}}, u'is_accepted': True, u'last_edit_date': 1459257369, u'share_link': u'https://math.stackexchange.com/a/1706496', u'answer_id': 1706496}]","I&#39;m looking for an example of a Square Integrable Random Variable, whose [multiplicative inverse](https://en.wikipedia.org/wiki/Multiplicative_inverse) is **not** Square Integrable.","[How about an exponential random variable? (Or any other positive square-integrable random variable with a density function that is bounded away from $0$ in a neighborhood of $0$.)

**More detail:** Let $X$ be a positive random variable with $\Bbb E[X^2]&lt;\infty$ and density $f_X$ such that $f_X(x)\ge\delta&gt;$ for $0&lt;x&lt;x_0$. (An exponential random variable is a specific example.) Then
$$
\eqalign{
\Bbb E[X^{-2}]
&amp;=\int_0^\infty x^{-2} f_X(x)\,dx
=\int_0^\infty f_X(t^{-1})\,dt\cr
&amp;\ge\int_{1/x_0}^\infty f_X(t^{-1})\,dt
\ge\int_{1/x_0}^\infty \delta\,dt=\infty.\cr
}
$$]",,,,,,0,,1458516808,0,0,True,1459257369,1458517105.0,https://math.stackexchange.com/questions/1706485/a-positive-square-integrable-random-variable-whit-non-square-integrable-inverse,,5.0,0.0,0.0,J.C.,https://math.stackexchange.com/users/62973/j-c,23.0,62973.0,registered,,1706485,1,https://math.stackexchange.com/q/1706485,"[real-analysis, probability, random-variables, examples-counterexamples]",A positive square integrable random variable whit non square integrable inverse,1,95
19,1625985.0,1,"[{u'up_vote_count': 1, u'title': u'Questions on symmetric difference of events', u'question_id': 1625960, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1453703374, u'comments': [{u'edited': False, u'comment_id': 3329368, u'creation_date': 1454139157, u'post_id': 1625985, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 140308, u'user_type': u'registered', u'reputation': 6899, u'link': u'https://math.stackexchange.com/users/140308/bclc', u'accept_rate': 78, u'display_name': u'BCLC', u'badge_counts': {u'bronze': 72, u'silver': 19, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/1625960/questions-on-symmetric-difference-of-events/1625985#comment3329368_1625985'}], u'creation_date': 1453702713, u'comment_count': 1, u'score': 1, u'link': u'https://math.stackexchange.com/questions/1625960/questions-on-symmetric-difference-of-events/1625985#1625985', u'body_markdown': u'For (1), take $A,B$ disjoints with $A\cup B=\Omega$. Then $P(A)=P(B)=1/2$ and $P(A\Delta B)=P(\Omega)=1$.

For (2), $P(A\Delta B)=P(A\cup B)-P(A\cap B)=P(A)+P(B)-P(A\cap B)-P(A\cap B)=2p-2p=0$ if $P(A)=P(B)=P(A\cap B)$ (please note that we don&#39;t use $0&lt;p&lt;1$).

For (3), we only have $P(A\Delta B)=P(A)+P(B)-2P(A\cap B)$. Thus, we need $\frac{P(A)+P(B)}{2}=P(A\cap B)$', u'owner': {u'user_id': 277566, u'user_type': u'registered', u'reputation': 6262, u'link': u'https://math.stackexchange.com/users/277566/sinbadh', u'accept_rate': 29, u'display_name': u'sinbadh', u'badge_counts': {u'bronze': 24, u'silver': 7, u'gold': 0}}, u'is_accepted': True, u'last_edit_date': 1453703374, u'share_link': u'https://math.stackexchange.com/a/1625985', u'answer_id': 1625985}]","From a comment on my math overflow question:

&gt; No, $P(A\bigtriangleup B)=0$ means $A$ and $B$ are essentially the same except in situations that almost surely do not happen. $P(A)=P(B)$ says much less.

I lost my notes, but I think I was able to show symm difference has prob 0 if $A=B$ or if $P(A) = P(B) = 0$ or $1$. I recall I wasn&#39;t able to show it if $P(A) = P(B)$. So apparently

$$ P(A)=P(B) \to P(A\bigtriangleup B)=0 \tag{*}$$

is false.

1. It&#39;s possible A and B are disjoint. That&#39;s a counterexample to $(*)$?

2. What if $1 &gt; P(A) = P(B) = p &gt; 0$ but $P(A \cap B) = p$? That proves $(*)$?

3. What if merely that A and B are not disjoint?","[For (1), take $A,B$ disjoints with $A\cup B=\Omega$. Then $P(A)=P(B)=1/2$ and $P(A\Delta B)=P(\Omega)=1$.

For (2), $P(A\Delta B)=P(A\cup B)-P(A\cap B)=P(A)+P(B)-P(A\cap B)-P(A\cap B)=2p-2p=0$ if $P(A)=P(B)=P(A\cap B)$ (please note that we don&#39;t use $0&lt;p&lt;1$).

For (3), we only have $P(A\Delta B)=P(A)+P(B)-2P(A\cap B)$. Thus, we need $\frac{P(A)+P(B)}{2}=P(A\cap B)$]",,,,,,0,,1453700508,1,0,True,1453703374,,https://math.stackexchange.com/questions/1625960/questions-on-symmetric-difference-of-events,78.0,72.0,2.0,19.0,BCLC,https://math.stackexchange.com/users/140308/bclc,6899.0,140308.0,registered,,1625960,-1,https://math.stackexchange.com/q/1625960,"[probability, probability-theory, measure-theory, elementary-set-theory, examples-counterexamples]",Questions on symmetric difference of events,0,274
20,,1,"[{u'up_vote_count': 1, u'title': u'conjecture in probability, assume conjecture to be true', u'question_id': 1497409, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1445811991, u'comments': [{u'edited': False, u'comment_id': 3051526, u'creation_date': 1445847485, u'post_id': 1497470, u'score': 0, u'post_type': u'answer', u'owner': {u'display_name': u'user248188', u'user_type': u'does_not_exist'}, u'link': u'https://math.stackexchange.com/questions/1497409/conjecture-in-probability-assume-conjecture-to-be-true/1497470#comment3051526_1497470'}], u'creation_date': 1445809038, u'comment_count': 1, u'score': 1, u'link': u'https://math.stackexchange.com/questions/1497409/conjecture-in-probability-assume-conjecture-to-be-true/1497470#1497470', u'body_markdown': u'The list of disproved statements on wiki is misleading!

I mention only one example which is important in the light of one of your questions. (&quot;Consider a disproved conjecture, however, assume it to be true. What are the consequence for a mathematical theory apart from obvious counterexamples?&quot;)

Wiki says

&gt;&quot;Euclid&#39;s parallel postulate stated that if two lines cross a third in a plane in such a way that the sum of the &quot;interior angles&quot; is not 180&#176; then the two lines meet.&quot;

According to Wiki the statement above was believed to be true for 2000 years.

The quoted statement was found to be independent from the other axioms of geometry; **it was not disproved**. (An axiom cannot be disproved unless it turns out that it leads to a contradiction together with the rest of the axioms.)

So negating (and **not disproving**) the statement above had led to the invention of hyperbolic geometry, the greatest impact on mathematics ever.

Also, note that the author of the Wiki article mistakes certain mathematical statements for certain physical things.

', u'owner': {u'user_id': 203663, u'user_type': u'registered', u'reputation': 16182, u'link': u'https://math.stackexchange.com/users/203663/zoli', u'accept_rate': 95, u'display_name': u'zoli', u'badge_counts': {u'bronze': 40, u'silver': 15, u'gold': 4}}, u'is_accepted': False, u'last_edit_date': 1445811991, u'share_link': u'https://math.stackexchange.com/a/1497470', u'answer_id': 1497470}]","there is a list of disproved mathematical ideas

https://en.wikipedia.org/wiki/List_of_disproved_mathematical_ideas

does anyone know a conjecture in probability theory which was first thought to be true but was eventually disproved? (i really like this zeeman episode)

consider a disproved conjecture, however, assume it to be true. what are the consequence for a mathematical theory apart from obvious counterexamples? i know that mathmatics does not work this way, but can anyone think of a proven false conjecture which, if it was true, would have a great impact?

---

the last example in the wikipedia article says

&gt; A &quot;theorem&quot; of Jan-Erik Roos in 1961 stated that in an [AB4*] abelian
&gt; category, lim1 vanishes on Mittag-Leffler sequences. This &quot;theorem&quot;
&gt; was used by many people since then, but it was disproved by
&gt; counterexample in 2002 by Amnon Neeman.

this eventually false theorem was indeed disproved. what nice results could one obtain provided that a false theorem is considered to be true?","[The list of disproved statements on wiki is misleading!

I mention only one example which is important in the light of one of your questions. (&quot;Consider a disproved conjecture, however, assume it to be true. What are the consequence for a mathematical theory apart from obvious counterexamples?&quot;)

Wiki says

&gt;&quot;Euclid&#39;s parallel postulate stated that if two lines cross a third in a plane in such a way that the sum of the &quot;interior angles&quot; is not 180&#176; then the two lines meet.&quot;

According to Wiki the statement above was believed to be true for 2000 years.

The quoted statement was found to be independent from the other axioms of geometry; **it was not disproved**. (An axiom cannot be disproved unless it turns out that it leads to a contradiction together with the rest of the axioms.)

So negating (and **not disproving**) the statement above had led to the invention of hyperbolic geometry, the greatest impact on mathematics ever.

Also, note that the author of the Wiki article mistakes certain mathematical statements for certain physical things.

]",,,,,,0,,1445807335,0,0,True,1445847405,1445847405.0,https://math.stackexchange.com/questions/1497409/conjecture-in-probability-assume-conjecture-to-be-true,,,,,user248188,,,,does_not_exist,,1497409,0,https://math.stackexchange.com/q/1497409,"[probability, logic, soft-question, examples-counterexamples]","conjecture in probability, assume conjecture to be true",0,195
21,1442618.0,2,"[{u'up_vote_count': 2, u'title': u'When is $\Pr(U\leq v|V=v)$ not an increasing function of $v$?', u'question_id': 1442599, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1442691525, u'comments': [{u'edited': False, u'comment_id': 2938641, u'creation_date': 1442691206, u'post_id': 1442618, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 252750, u'user_type': u'registered', u'reputation': 3365, u'link': u'https://math.stackexchange.com/users/252750/hetebrij', u'display_name': u'Hetebrij', u'badge_counts': {u'bronze': 15, u'silver': 4, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1442599/when-is-pru-leq-vv-v-not-an-increasing-function-of-v/1442618#comment2938641_1442618'}, {u'edited': False, u'comment_id': 2938644, u'creation_date': 1442691271, u'post_id': 1442618, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 83396, u'user_type': u'registered', u'reputation': 64295, u'link': u'https://math.stackexchange.com/users/83396/ian', u'accept_rate': 71, u'display_name': u'Ian', u'badge_counts': {u'bronze': 79, u'silver': 44, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/1442599/when-is-pru-leq-vv-v-not-an-increasing-function-of-v/1442618#comment2938644_1442618'}, {u'edited': False, u'comment_id': 2938648, u'creation_date': 1442691361, u'post_id': 1442618, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 178464, u'user_type': u'registered', u'reputation': 6751, u'link': u'https://math.stackexchange.com/users/178464/yurnero', u'accept_rate': 65, u'display_name': u'yurnero', u'badge_counts': {u'bronze': 23, u'silver': 8, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1442599/when-is-pru-leq-vv-v-not-an-increasing-function-of-v/1442618#comment2938648_1442618'}, {u'edited': False, u'reply_to_user': {u'user_id': 83396, u'user_type': u'registered', u'reputation': 64295, u'link': u'https://math.stackexchange.com/users/83396/ian', u'accept_rate': 71, u'display_name': u'Ian', u'badge_counts': {u'bronze': 79, u'silver': 44, u'gold': 2}}, u'comment_id': 2938654, u'creation_date': 1442691561, u'post_id': 1442618, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 252750, u'user_type': u'registered', u'reputation': 3365, u'link': u'https://math.stackexchange.com/users/252750/hetebrij', u'display_name': u'Hetebrij', u'badge_counts': {u'bronze': 15, u'silver': 4, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1442599/when-is-pru-leq-vv-v-not-an-increasing-function-of-v/1442618#comment2938654_1442618'}], u'creation_date': 1442690460, u'comment_count': 4, u'score': 2, u'link': u'https://math.stackexchange.com/questions/1442599/when-is-pru-leq-vv-v-not-an-increasing-function-of-v/1442618#1442618', u'body_markdown': u'Let $\Omega = \{1,2,3,4\}$, with $\mathbb{P}(\{v\} ) = \frac{1}{4}$.  
Now define $U (v) = v$ and $V(v) = \left\{ \begin{matrix} 2 &amp; v \le 2 \\ 3 &amp; v \ge 3 \end{matrix} \right.$. Then we have 
\begin{eqnarray}
\mathbb{P}(U \le 2 \mid V =2) &amp;=&amp; \frac{ \mathbb{P}(\{1,2\})}{\mathbb{P}(\{1,2\})} &amp;=&amp; 1 \\
\mathbb{P}(U \le 3 \mid V =3) &amp;=&amp; \frac{ \mathbb{P}(\{3\})}{\mathbb{P}(\{3,4\})} &amp;=&amp;  \frac{1}{2}
\end{eqnarray}

For simplicity, let $\Omega = \{1,2,3\}$ with equal probability.  
Now, let $U(v) = v $ and $V(v) = \left\{ \begin{matrix} 1 &amp; v \le 2 \\ 2 &amp;v=3\end{matrix} \right. $, then we have
\begin{eqnarray}
\mathbb{P}(U \le 1 \mid V =1) &amp;=&amp; \frac{ \mathbb{P}(\{1\})}{\mathbb{P}(\{1,2\})} &amp;=&amp; \frac{1}{2} \\
\mathbb{P}(U \le 2 \mid V =2) &amp;=&amp; \frac{ \mathbb{P}(\emptyset)}{\mathbb{P}(\{3\})} &amp;=&amp;  0
\end{eqnarray}', u'owner': {u'user_id': 252750, u'user_type': u'registered', u'reputation': 3365, u'link': u'https://math.stackexchange.com/users/252750/hetebrij', u'display_name': u'Hetebrij', u'badge_counts': {u'bronze': 15, u'silver': 4, u'gold': 1}}, u'is_accepted': True, u'last_edit_date': 1442691525, u'share_link': u'https://math.stackexchange.com/a/1442618', u'answer_id': 1442618}, {u'up_vote_count': 1, u'title': u'When is $\Pr(U\leq v|V=v)$ not an increasing function of $v$?', u'question_id': 1442599, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1442691423, u'creation_date': 1442691423, u'comment_count': 0, u'score': 1, u'link': u'https://math.stackexchange.com/questions/1442599/when-is-pru-leq-vv-v-not-an-increasing-function-of-v/1442636#1442636', u'body_markdown': u'All you need is that $U$ is upward biased away from $V$ more and more as $V$ increases. If $V$ is uniform on $[0,1]$, then for example you could let $P(U|V = v)$ be uniform on $[2v-1/2,2v+1/2]$.', u'owner': {u'user_id': 87313, u'user_type': u'registered', u'reputation': 21246, u'link': u'https://math.stackexchange.com/users/87313/user2566092', u'accept_rate': 45, u'display_name': u'user2566092', u'badge_counts': {u'bronze': 45, u'silver': 18, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/1442636', u'answer_id': 1442636}]","Suppose $U$ and $V$ are random variables. I&#39;m trying to find an example for which $\Pr(U\leq v|V=v)$ it *not* an increasing function of $v$.

**Current thoughts**: when $U$ and $V$ are independent, $\Pr(U\leq v|V=v)=\Pr(U\leq v)$, which is increasing in $v$. So this doesn&#39;t work. I have also considered the case in which
$$
\begin{pmatrix}U\\V\end{pmatrix}\sim N\left(\begin{pmatrix}0\\0\end{pmatrix},\begin{pmatrix}1 &amp; \rho \\ \rho &amp; 1\end{pmatrix}\right)
$$
and it turns out that regardless of what $\rho$ is in $[-1,1]$, the conditional probability $\Pr(U\leq v|V=v)$ is increasing in $v$. Thus this doesn&#39;t work either.

So next, I assume $U$ and $V$ have joint density $f$ and $V$ has marginal density $g$. Then the Leibniz&#39;s Rule gives:
$$
\frac{\partial}{\partial v}\int_{-\infty}^v\frac{f(u,v)}{g(v)}du=\int_{-\infty}^v\frac{\partial}{\partial v}\frac{f(u,v)}{g(v)}du+\frac{f(v,v)}{g(v)}.
$$
The second term above is non negative whereas the first term, I think, can take on either sign. So it seems I should look at cases for which the first term above is negative, but I haven&#39;t been able to come up with a concrete example.","[Let $\Omega = \{1,2,3,4\}$, with $\mathbb{P}(\{v\} ) = \frac{1}{4}$.  
Now define $U (v) = v$ and $V(v) = \left\{ \begin{matrix} 2 &amp; v \le 2 \\ 3 &amp; v \ge 3 \end{matrix} \right.$. Then we have 
\begin{eqnarray}
\mathbb{P}(U \le 2 \mid V =2) &amp;=&amp; \frac{ \mathbb{P}(\{1,2\})}{\mathbb{P}(\{1,2\})} &amp;=&amp; 1 \\
\mathbb{P}(U \le 3 \mid V =3) &amp;=&amp; \frac{ \mathbb{P}(\{3\})}{\mathbb{P}(\{3,4\})} &amp;=&amp;  \frac{1}{2}
\end{eqnarray}

For simplicity, let $\Omega = \{1,2,3\}$ with equal probability.  
Now, let $U(v) = v $ and $V(v) = \left\{ \begin{matrix} 1 &amp; v \le 2 \\ 2 &amp;v=3\end{matrix} \right. $, then we have
\begin{eqnarray}
\mathbb{P}(U \le 1 \mid V =1) &amp;=&amp; \frac{ \mathbb{P}(\{1\})}{\mathbb{P}(\{1,2\})} &amp;=&amp; \frac{1}{2} \\
\mathbb{P}(U \le 2 \mid V =2) &amp;=&amp; \frac{ \mathbb{P}(\emptyset)}{\mathbb{P}(\{3\})} &amp;=&amp;  0
\end{eqnarray}, All you need is that $U$ is upward biased away from $V$ more and more as $V$ increases. If $V$ is uniform on $[0,1]$, then for example you could let $P(U|V = v)$ be uniform on $[2v-1/2,2v+1/2]$.]",,,,,,2,"[{u'edited': False, u'reply_to_user': {u'user_id': 252750, u'user_type': u'registered', u'reputation': 3365, u'link': u'https://math.stackexchange.com/users/252750/hetebrij', u'display_name': u'Hetebrij', u'badge_counts': {u'bronze': 15, u'silver': 4, u'gold': 1}}, u'comment_id': 2938622, u'creation_date': 1442690571, u'post_id': 1442599, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 178464, u'user_type': u'registered', u'reputation': 6751, u'link': u'https://math.stackexchange.com/users/178464/yurnero', u'accept_rate': 65, u'display_name': u'yurnero', u'badge_counts': {u'bronze': 23, u'silver': 8, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1442599/when-is-pru-leq-vv-v-not-an-increasing-function-of-v#comment2938622_1442599'}, {u'edited': False, u'comment_id': 2938626, u'creation_date': 1442690719, u'post_id': 1442599, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 252750, u'user_type': u'registered', u'reputation': 3365, u'link': u'https://math.stackexchange.com/users/252750/hetebrij', u'display_name': u'Hetebrij', u'badge_counts': {u'bronze': 15, u'silver': 4, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1442599/when-is-pru-leq-vv-v-not-an-increasing-function-of-v#comment2938626_1442599'}]",1442689746,0,0,True,1442691525,,https://math.stackexchange.com/questions/1442599/when-is-pru-leq-vv-v-not-an-increasing-function-of-v,65.0,23.0,1.0,8.0,yurnero,https://math.stackexchange.com/users/178464/yurnero,6751.0,178464.0,registered,,1442599,1,https://math.stackexchange.com/q/1442599,"[calculus, probability, probability-theory, examples-counterexamples]",When is $\Pr(U\leq v|V=v)$ not an increasing function of $v$?,1,22
22,1435940.0,2,"[{u'up_vote_count': 3, u'title': u'Distribution with two (or more) medians', u'question_id': 1435936, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1442289330, u'creation_date': 1442289330, u'comment_count': 0, u'score': 3, u'link': u'https://math.stackexchange.com/questions/1435936/distribution-with-two-or-more-medians/1435940#1435940', u'body_markdown': u'Let random variable $X$ take on values $0$ and $1$, each with probability $\frac{1}{2}$. Then any $b$ with $0\lt b\lt 1$ is a median of $X$.', u'owner': {u'user_id': 6312, u'user_type': u'registered', u'reputation': 444311, u'link': u'https://math.stackexchange.com/users/6312/andr%c3%a9-nicolas', u'display_name': u'Andr&#233; Nicolas', u'badge_counts': {u'bronze': 786, u'silver': 411, u'gold': 36}}, u'is_accepted': True, u'share_link': u'https://math.stackexchange.com/a/1435940', u'answer_id': 1435940}, {u'up_vote_count': 0, u'title': u'Distribution with two (or more) medians', u'question_id': 1435936, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1442289576, u'comments': [{u'edited': False, u'comment_id': 5247977, u'creation_date': 1511902234, u'post_id': 1435942, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 495390, u'user_type': u'registered', u'reputation': 101, u'link': u'https://math.stackexchange.com/users/495390/obromios', u'display_name': u'Obromios', u'badge_counts': {u'bronze': 2, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1435936/distribution-with-two-or-more-medians/1435942#comment5247977_1435942'}], u'creation_date': 1442289576, u'comment_count': 1, u'score': 0, u'link': u'https://math.stackexchange.com/questions/1435936/distribution-with-two-or-more-medians/1435942#1435942', u'body_markdown': u'It doesn&#39;t say there may be more than one median value for the distribution.

It says there may be more than one *sample* value that is the median.

Thus if our sample is $\{2, 3, 1, 2, 1, 2\}$, $2$ is the median, and there are more than one of them in the sample.', u'owner': {u'user_id': 135106, u'user_type': u'registered', u'reputation': 77587, u'link': u'https://math.stackexchange.com/users/135106/graham-kemp', u'display_name': u'Graham Kemp', u'badge_counts': {u'bronze': 71, u'silver': 32, u'gold': 4}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/1435942', u'answer_id': 1435942}]","Is there any example with a distribution with two or more medians? I was reading about the median on wikipedia: https://en.wikipedia.org/wiki/Median and here it says that there may be more than one median, but I haven&#180;t been able to give such an example. I would really appreciate if you can help me ","[Let random variable $X$ take on values $0$ and $1$, each with probability $\frac{1}{2}$. Then any $b$ with $0\lt b\lt 1$ is a median of $X$., It doesn&#39;t say there may be more than one median value for the distribution.

It says there may be more than one *sample* value that is the median.

Thus if our sample is $\{2, 3, 1, 2, 1, 2\}$, $2$ is the median, and there are more than one of them in the sample.]",,,,,,0,,1442289149,0,0,True,1442289576,,https://math.stackexchange.com/questions/1435936/distribution-with-two-or-more-medians,42.0,21.0,0.0,8.0,user128422,https://math.stackexchange.com/users/128422/user128422,1162.0,128422.0,registered,,1435936,2,https://math.stackexchange.com/q/1435936,"[probability, probability-distributions, random-variables, examples-counterexamples, median]",Distribution with two (or more) medians,2,395
23,1365588.0,1,"[{u'up_vote_count': 5, u'title': u'When the sum of independent Markov chains is a Markov chain?', u'question_id': 1365430, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1445891396, u'comments': [{u'edited': False, u'comment_id': 2778509, u'creation_date': 1437229512, u'post_id': 1365588, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 231012, u'user_type': u'registered', u'reputation': 654, u'link': u'https://math.stackexchange.com/users/231012/slowpoke', u'accept_rate': 100, u'display_name': u'Slowpoke', u'badge_counts': {u'bronze': 22, u'silver': 8, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1365430/when-the-sum-of-independent-markov-chains-is-a-markov-chain/1365588#comment2778509_1365588'}, {u'edited': False, u'reply_to_user': {u'user_id': 231012, u'user_type': u'registered', u'reputation': 654, u'link': u'https://math.stackexchange.com/users/231012/slowpoke', u'accept_rate': 100, u'display_name': u'Slowpoke', u'badge_counts': {u'bronze': 22, u'silver': 8, u'gold': 0}}, u'comment_id': 2779402, u'creation_date': 1437255404, u'post_id': 1365588, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/1365430/when-the-sum-of-independent-markov-chains-is-a-markov-chain/1365588#comment2779402_1365588'}, {u'edited': False, u'comment_id': 2800097, u'creation_date': 1437986122, u'post_id': 1365588, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 231012, u'user_type': u'registered', u'reputation': 654, u'link': u'https://math.stackexchange.com/users/231012/slowpoke', u'accept_rate': 100, u'display_name': u'Slowpoke', u'badge_counts': {u'bronze': 22, u'silver': 8, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1365430/when-the-sum-of-independent-markov-chains-is-a-markov-chain/1365588#comment2800097_1365588'}], u'creation_date': 1437227941, u'comment_count': 3, u'score': 5, u'link': u'https://math.stackexchange.com/questions/1365430/when-the-sum-of-independent-markov-chains-is-a-markov-chain/1365588#1365588', u'body_markdown': u'In general, the sum of two independent Markov chains is not a Markov chain.

Let $X$ be a random variable such that $\mathbb{P}(X=0) = \mathbb{P}(X=1) = \frac{1}{2}$ and set $X_n := X$ for all $n \in \mathbb{N}$. Obviously, $(X_n)_{n \in \mathbb{N}}$ is a Markov chain. Moreover, let $(Y_n)_{n \in \mathbb{N}_0}$, $Y_0 := 0$, be a Markov chain independent from $X$ with state space $\{-1,0,1\}$ and transition matrix

$$P := \begin{pmatrix} \frac{1}{4} &amp; \frac{3}{4} &amp; 0 \\ \frac{1}{4} &amp; \frac{1}{2} &amp; \frac{1}{4} \\ 0 &amp; \frac{3}{4} &amp; \frac{1}{4} \end{pmatrix}.$$

Now set $Z_n := X_n+Y_n$. Then, by the independence of $X$ and $(Y_n)_{n \in \mathbb{N}_0}$, we have

$$\begin{align*} \mathbb{P}(Z_2 = 0 \mid Z_1 = 1, Z_0 = 1) &amp;= \frac{\mathbb{P}(Z_2 = 0, Z_1 = 1,  Z_0 = 1)}{\mathbb{P}(Z_1 =1, Z_0=1)} \\ &amp;=\frac{\mathbb{P}(Y_2 = -1, Y_1 = 0,  X= 1)}{\mathbb{P}(Y_1 =0, X=1)} \\ &amp;= \frac{\mathbb{P}(Y_2 = -1, Y_1 = 1)}{\mathbb{P}(Y_1 = 0)} \frac{\mathbb{P}(X=1)}{\mathbb{P}(X=1)} \\ &amp;= \mathbb{P}(Y_2 = -1 \mid Y_1 = 0) = \frac{1}{4}. \end{align*}$$

On the other hand, a very similar calculation shows that

$$\begin{align*} \mathbb{P}(Z_2 = 0 \mid Z_1 = 1) &amp;= \frac{\mathbb{P}(Y_2 = -1, Y_1=0) \mathbb{P}(X=1) + \mathbb{P}(Y_2 = 0, Y_1=1) \mathbb{P}(X=0)}{\mathbb{P}(Y_1 = 0) \mathbb{P}(X=1) + \mathbb{P}(Y_1=1) \mathbb{P}(X=0)} \\ &amp;= \frac{5}{12} \neq \frac{1}{4}. \end{align*}$$

This means that $(Z_n)_{n \in \mathbb{N}_0}$ is not a Markov chain. ', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'is_accepted': True, u'last_edit_date': 1445891396, u'share_link': u'https://math.stackexchange.com/a/1365588', u'answer_id': 1365588}]","I try to find as much as possible cases, when the chain $Z(t) = |X_1(t)-X_2(t)|$ is Markov, where $X_1(t)$ and $X_2(t)$ are independent, discrete-time and space, preferably non-homogeneous Markov chains.
I started to search for the sum of independent Markov chains and I found this statement in Stoyanov J. - Counterexamples in Probability (2ed., Wiley, 1997)(p.229, one can google it and find in google books):

&gt; ... the sum of two Markov processes need not be a Markov process. Note, however, that that the sum of two independent Markov processes preserves this property.

That seems very strange to me and I wish to find the proof or at least the statement elsewhere.



----------
EDIT: The way of thinking how it may look like for a sum of two independent Markov chains (If I want to prove that the sum of two independent Markov chains is again a Markov chain):

Let $Y(n) = X_1(n)+X_2(n)$. Then

$P(Y(n+1) = i_{n+1} \ | \ Y(n) = i_n, ..., Y(0)=i_0) =$

$= P(X_1(n+1)+X_2(n+1)=i_{n+1}\ | \ X_1(n)+X_2(n)=i_n,...,X_1(0)+X_2(0)=i_0)=$

$=/ (?) / = \sum_{j+k=i_{n+1}}P(X_1(n+1)=j,X_2(n+1)=k \ | \ \cdot)=$

$=/\text{X&#39;s are independent}/ = \sum_{j+k=i_{n+1}}P(X_1(n+1)=j \ | \ \cdot)\cdot P(X_2(n+1)=k \ | \ \cdot) = $

$= /\text{Markov property + (??) } / =  \sum_{j+k=i_{n+1}}P(X_1(n+1)=j \ | \ X_1(n)+X_2(n)=i_n)\cdot P(X_2(n+1)=k \ | \ X_1(n)+X_2(n)=i_n)=$

$=P(X_1(n+1)+X_2(n+1)=i_{n+1} \ | \ X_1(n)+X_2(n)=i_n) = P(Y(n+1)=i_{n+1}\ | \ Y(n)=i_n)$.

Here I am uncertain about (?) and (??) steps.","[In general, the sum of two independent Markov chains is not a Markov chain.

Let $X$ be a random variable such that $\mathbb{P}(X=0) = \mathbb{P}(X=1) = \frac{1}{2}$ and set $X_n := X$ for all $n \in \mathbb{N}$. Obviously, $(X_n)_{n \in \mathbb{N}}$ is a Markov chain. Moreover, let $(Y_n)_{n \in \mathbb{N}_0}$, $Y_0 := 0$, be a Markov chain independent from $X$ with state space $\{-1,0,1\}$ and transition matrix

$$P := \begin{pmatrix} \frac{1}{4} &amp; \frac{3}{4} &amp; 0 \\ \frac{1}{4} &amp; \frac{1}{2} &amp; \frac{1}{4} \\ 0 &amp; \frac{3}{4} &amp; \frac{1}{4} \end{pmatrix}.$$

Now set $Z_n := X_n+Y_n$. Then, by the independence of $X$ and $(Y_n)_{n \in \mathbb{N}_0}$, we have

$$\begin{align*} \mathbb{P}(Z_2 = 0 \mid Z_1 = 1, Z_0 = 1) &amp;= \frac{\mathbb{P}(Z_2 = 0, Z_1 = 1,  Z_0 = 1)}{\mathbb{P}(Z_1 =1, Z_0=1)} \\ &amp;=\frac{\mathbb{P}(Y_2 = -1, Y_1 = 0,  X= 1)}{\mathbb{P}(Y_1 =0, X=1)} \\ &amp;= \frac{\mathbb{P}(Y_2 = -1, Y_1 = 1)}{\mathbb{P}(Y_1 = 0)} \frac{\mathbb{P}(X=1)}{\mathbb{P}(X=1)} \\ &amp;= \mathbb{P}(Y_2 = -1 \mid Y_1 = 0) = \frac{1}{4}. \end{align*}$$

On the other hand, a very similar calculation shows that

$$\begin{align*} \mathbb{P}(Z_2 = 0 \mid Z_1 = 1) &amp;= \frac{\mathbb{P}(Y_2 = -1, Y_1=0) \mathbb{P}(X=1) + \mathbb{P}(Y_2 = 0, Y_1=1) \mathbb{P}(X=0)}{\mathbb{P}(Y_1 = 0) \mathbb{P}(X=1) + \mathbb{P}(Y_1=1) \mathbb{P}(X=0)} \\ &amp;= \frac{5}{12} \neq \frac{1}{4}. \end{align*}$$

This means that $(Z_n)_{n \in \mathbb{N}_0}$ is not a Markov chain. ]",,,,,,5,"[{u'edited': False, u'comment_id': 2778254, u'creation_date': 1437219352, u'post_id': 1365430, u'score': 1, u'post_type': u'question', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/1365430/when-the-sum-of-independent-markov-chains-is-a-markov-chain#comment2778254_1365430'}, {u'edited': False, u'reply_to_user': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'comment_id': 2778269, u'creation_date': 1437220177, u'post_id': 1365430, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 231012, u'user_type': u'registered', u'reputation': 654, u'link': u'https://math.stackexchange.com/users/231012/slowpoke', u'accept_rate': 100, u'display_name': u'Slowpoke', u'badge_counts': {u'bronze': 22, u'silver': 8, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1365430/when-the-sum-of-independent-markov-chains-is-a-markov-chain#comment2778269_1365430'}, {u'edited': False, u'reply_to_user': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'comment_id': 2778287, u'creation_date': 1437220722, u'post_id': 1365430, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 231012, u'user_type': u'registered', u'reputation': 654, u'link': u'https://math.stackexchange.com/users/231012/slowpoke', u'accept_rate': 100, u'display_name': u'Slowpoke', u'badge_counts': {u'bronze': 22, u'silver': 8, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1365430/when-the-sum-of-independent-markov-chains-is-a-markov-chain#comment2778287_1365430'}, {u'edited': False, u'comment_id': 3055228, u'creation_date': 1445941267, u'post_id': 1365430, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 6179, u'user_type': u'registered', u'reputation': 240775, u'link': u'https://math.stackexchange.com/users/6179/did', u'accept_rate': 78, u'display_name': u'Did', u'badge_counts': {u'bronze': 437, u'silver': 204, u'gold': 23}}, u'link': u'https://math.stackexchange.com/questions/1365430/when-the-sum-of-independent-markov-chains-is-a-markov-chain#comment3055228_1365430'}, {u'edited': False, u'reply_to_user': {u'user_id': 6179, u'user_type': u'registered', u'reputation': 240775, u'link': u'https://math.stackexchange.com/users/6179/did', u'accept_rate': 78, u'display_name': u'Did', u'badge_counts': {u'bronze': 437, u'silver': 204, u'gold': 23}}, u'comment_id': 3055543, u'creation_date': 1445950441, u'post_id': 1365430, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 231012, u'user_type': u'registered', u'reputation': 654, u'link': u'https://math.stackexchange.com/users/231012/slowpoke', u'accept_rate': 100, u'display_name': u'Slowpoke', u'badge_counts': {u'bronze': 22, u'silver': 8, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1365430/when-the-sum-of-independent-markov-chains-is-a-markov-chain#comment3055543_1365430'}]",1437214512,0,1,True,1445891503,1445891503.0,https://math.stackexchange.com/questions/1365430/when-the-sum-of-independent-markov-chains-is-a-markov-chain,100.0,22.0,0.0,8.0,Slowpoke,https://math.stackexchange.com/users/231012/slowpoke,654.0,231012.0,registered,,1365430,5,https://math.stackexchange.com/q/1365430,"[probability, probability-theory, examples-counterexamples, markov-chains]",When the sum of independent Markov chains is a Markov chain?,5,2709
24,1333595.0,1,"[{u'up_vote_count': 1, u'title': u'If the $(n-1)$th moment exists does the $n$th moment necessarily exist?', u'question_id': 1333571, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1434885252, u'creation_date': 1434885252, u'comment_count': 0, u'score': 1, u'link': u'https://math.stackexchange.com/questions/1333571/if-the-n-1th-moment-exists-does-the-nth-moment-necessarily-exist/1333595#1333595', u'body_markdown': u'No, not at all. The decay is exponential if exponential moments exist, but we cannot expect exponential decay if the second moment exists. Just consider e.g. a random variabl $X$ with density

$$f(x) := c \frac{1}{x^4} 1_{(1,\infty)}(x)$$

(where $c&gt;0$ is chosen such that $\int f(x) \, dx =1$). Then the random variable has second moments, but $\mathbb{E}(|X|^3)= \infty$.', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'is_accepted': True, u'share_link': u'https://math.stackexchange.com/a/1333595', u'answer_id': 1333595}]",Let&#39;s suppose the distribution is unknown but that the second moment is known to be finite. Doesn&#39;t this imply that the distribution should fall off exponentially fast and therefore higher moments must also exist?,"[No, not at all. The decay is exponential if exponential moments exist, but we cannot expect exponential decay if the second moment exists. Just consider e.g. a random variabl $X$ with density

$$f(x) := c \frac{1}{x^4} 1_{(1,\infty)}(x)$$

(where $c&gt;0$ is chosen such that $\int f(x) \, dx =1$). Then the random variable has second moments, but $\mathbb{E}(|X|^3)= \infty$.]",,,,,,0,,1434883648,0,0,True,1434886022,1434886022.0,https://math.stackexchange.com/questions/1333571/if-the-n-1th-moment-exists-does-the-nth-moment-necessarily-exist,88.0,20.0,0.0,10.0,Aidan Rocke,https://math.stackexchange.com/users/93511/aidan-rocke,1128.0,93511.0,registered,,1333571,0,https://math.stackexchange.com/q/1333571,"[probability, examples-counterexamples, expectation]",If the $(n-1)$th moment exists does the $n$th moment necessarily exist?,0,86
25,1184183.0,1,"[{u'up_vote_count': 1, u'title': u'Infinite sum of random variables is infinite', u'question_id': 1184170, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1426013027, u'creation_date': 1426013027, u'comment_count': 0, u'score': 1, u'link': u'https://math.stackexchange.com/questions/1184170/infinite-sum-of-random-variables-is-infinite/1184183#1184183', u'body_markdown': u'1. Let $X$ be an arbitrary non-negative random variable such that $\mathbb{P}(X&gt;0) \in (0,1)$. Define $$X_i := X \qquad \text{for all} \, \, i \in \mathbb{N}.$$ Then the sequence is identically distributed (but not independent) and $$\mathbb{P} \left( \sum_{i=1}^{\infty} X_i = \infty \right) = \mathbb{P}(X&gt;0) \in (0,1).$$ 
2. The sequence $(X_i)_{i \in \mathbb{N}}$ defined by $$X_i = \frac{1}{i^2}$$  is a sequence of independent random variables and $$\mathbb{P} \left( \sum_{i=1}^{\infty} X_i = \infty \right)=0.$$', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'is_accepted': True, u'share_link': u'https://math.stackexchange.com/a/1184183', u'answer_id': 1184183}]","I am trying to better understand this statement and the assumptions made:
&lt;blockquote&gt;
If $X_1,X_2,\ldots$ are non-negative independently and identically distributed random variables with $P(X_i&gt;0)&gt;0$, then $\displaystyle P\left(\sum_{i=1}^\infty X_i=\infty\right)=1$.&lt;/p&gt;
&lt;/blockquote&gt;

Could someone provide simple examples showing that the statement would not hold if: 1) the $X_i$ were identically distributed but not independent and 2) the $X_i$ were independent but not identically distributed? 
Thanks!","[1. Let $X$ be an arbitrary non-negative random variable such that $\mathbb{P}(X&gt;0) \in (0,1)$. Define $$X_i := X \qquad \text{for all} \, \, i \in \mathbb{N}.$$ Then the sequence is identically distributed (but not independent) and $$\mathbb{P} \left( \sum_{i=1}^{\infty} X_i = \infty \right) = \mathbb{P}(X&gt;0) \in (0,1).$$ 
2. The sequence $(X_i)_{i \in \mathbb{N}}$ defined by $$X_i = \frac{1}{i^2}$$  is a sequence of independent random variables and $$\mathbb{P} \left( \sum_{i=1}^{\infty} X_i = \infty \right)=0.$$]",,,,,,0,,1426012577,1,1,True,1426014879,1426014879.0,https://math.stackexchange.com/questions/1184170/infinite-sum-of-random-variables-is-infinite,,4.0,0.0,0.0,Hueber,https://math.stackexchange.com/users/191979/hueber,26.0,191979.0,registered,,1184170,1,https://math.stackexchange.com/q/1184170,"[probability, measure-theory, probability-theory, examples-counterexamples]",Infinite sum of random variables is infinite,2,574
26,,1,"[{u'up_vote_count': 0, u'title': u'Counterexample in optional stopping martingale', u'question_id': 1176922, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1425670941, u'comments': [{u'edited': False, u'comment_id': 2398645, u'creation_date': 1425623339, u'post_id': 1177358, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/1176922/counterexample-in-optional-stopping-martingale/1177358#comment2398645_1177358'}, {u'edited': False, u'comment_id': 2399109, u'creation_date': 1425643168, u'post_id': 1177358, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 195480, u'user_type': u'registered', u'reputation': 149, u'link': u'https://math.stackexchange.com/users/195480/john', u'accept_rate': 38, u'display_name': u'john', u'badge_counts': {u'bronze': 9, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1176922/counterexample-in-optional-stopping-martingale/1177358#comment2399109_1177358'}, {u'edited': False, u'reply_to_user': {u'user_id': 195480, u'user_type': u'registered', u'reputation': 149, u'link': u'https://math.stackexchange.com/users/195480/john', u'accept_rate': 38, u'display_name': u'john', u'badge_counts': {u'bronze': 9, u'silver': 0, u'gold': 0}}, u'comment_id': 2399888, u'creation_date': 1425665068, u'post_id': 1177358, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/1176922/counterexample-in-optional-stopping-martingale/1177358#comment2399888_1177358'}, {u'edited': False, u'reply_to_user': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'comment_id': 2400172, u'creation_date': 1425670916, u'post_id': 1177358, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 220299, u'user_type': u'registered', u'reputation': 156, u'link': u'https://math.stackexchange.com/users/220299/j-stewart', u'display_name': u'J. Stewart', u'badge_counts': {u'bronze': 3, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1176922/counterexample-in-optional-stopping-martingale/1177358#comment2400172_1177358'}], u'creation_date': 1425593520, u'comment_count': 4, u'score': 0, u'link': u'https://math.stackexchange.com/questions/1176922/counterexample-in-optional-stopping-martingale/1177358#1177358', u'body_markdown': u'Are you sure you have the assumptions correct? This link [Here][1] has a Theorem 4.7.5 which states that if $\{X_n\}_{n\geq0}$ is a sub-martingale and $\mathbb{E}\big[|X_{n+1} - X_n|\; \big| \; \mathcal{F}_n\big] &lt; B &lt; \infty$ and $\mathbb{E}[N] &lt; \infty$ then $\{X_{n \wedge N}\}_{n \geq 0}$ is uniformly integrable. 

Taking expectations $\mathbb{E}\Big[\mathbb{E}\big[|X_{n+1} - X_n| \; \big| \; \mathcal{F}_n\big]\Big] = \mathbb{E}\big[|X_{n+1} - X_n|\big] &lt; B$. Therefore, it must be that $\{X_n\}_{n\geq1}$ cannot have almost surely uniformly bounded increments for your result to hold.

If you have uniformly bounded increments, then the Theorem suggests that such an example by proof is not possible. 

  [1]: https://math.la.asu.edu/~jtaylor/teaching/Spring2011/APM504/lectures/lecture28/lecture28.pdf', u'owner': {u'user_id': 220299, u'user_type': u'registered', u'reputation': 156, u'link': u'https://math.stackexchange.com/users/220299/j-stewart', u'display_name': u'J. Stewart', u'badge_counts': {u'bronze': 3, u'silver': 0, u'gold': 0}}, u'is_accepted': False, u'last_edit_date': 1425670941, u'share_link': u'https://math.stackexchange.com/a/1177358', u'answer_id': 1177358}]","**Problem:** Give an example of submartingale $\{X_n\}$ with $\sup_nE |X_{n-1}-X_n|&lt;\infty$ and stopping time $N$ with $E[N]&lt;\infty$ such that $\{X_{n\wedge N}\}$ is not uniformly integrable.


**Attempt:** I think this asks us to give a counterexample to the optional stopping theorem with bounded increments. Since we have a finite a.s. stopping time condition, I think the example maybe some kind of low dimensional random walk. But I am not really sure..","[Are you sure you have the assumptions correct? This link [Here][1] has a Theorem 4.7.5 which states that if $\{X_n\}_{n\geq0}$ is a sub-martingale and $\mathbb{E}\big[|X_{n+1} - X_n|\; \big| \; \mathcal{F}_n\big] &lt; B &lt; \infty$ and $\mathbb{E}[N] &lt; \infty$ then $\{X_{n \wedge N}\}_{n \geq 0}$ is uniformly integrable. 

Taking expectations $\mathbb{E}\Big[\mathbb{E}\big[|X_{n+1} - X_n| \; \big| \; \mathcal{F}_n\big]\Big] = \mathbb{E}\big[|X_{n+1} - X_n|\big] &lt; B$. Therefore, it must be that $\{X_n\}_{n\geq1}$ cannot have almost surely uniformly bounded increments for your result to hold.

If you have uniformly bounded increments, then the Theorem suggests that such an example by proof is not possible. 

  [1]: https://math.la.asu.edu/~jtaylor/teaching/Spring2011/APM504/lectures/lecture28/lecture28.pdf]",,,,,,0,,1425576988,0,1,False,1425670941,1425578975.0,https://math.stackexchange.com/questions/1176922/counterexample-in-optional-stopping-martingale,38.0,9.0,0.0,0.0,john,https://math.stackexchange.com/users/195480/john,149.0,195480.0,registered,,1176922,1,https://math.stackexchange.com/q/1176922,"[probability, probability-theory, examples-counterexamples, martingales]",Counterexample in optional stopping martingale,1,388
27,1120343.0,1,"[{u'up_vote_count': 2, u'title': u'Relation between convergence in distribution and in probability', u'question_id': 1120338, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1422281071, u'comments': [{u'edited': False, u'comment_id': 2285783, u'creation_date': 1422281667, u'post_id': 1120343, u'score': 1, u'post_type': u'answer', u'owner': {u'user_id': 11069, u'user_type': u'registered', u'reputation': 59415, u'link': u'https://math.stackexchange.com/users/11069/sasha', u'accept_rate': 94, u'display_name': u'Sasha', u'badge_counts': {u'bronze': 177, u'silver': 105, u'gold': 5}}, u'link': u'https://math.stackexchange.com/questions/1120338/relation-between-convergence-in-distribution-and-in-probability/1120343#comment2285783_1120343'}], u'creation_date': 1422280459, u'comment_count': 1, u'score': 2, u'link': u'https://math.stackexchange.com/questions/1120338/relation-between-convergence-in-distribution-and-in-probability/1120343#1120343', u'body_markdown': u'Consider the probability space $((0,1),\mathcal{B}(0,1))$ endowed with the Lebesgue measure  $\lambda$ and the random variables $$X(\omega) := 1_{(0,1/2)}(\omega) \qquad \qquad Y(\omega) := 1_{(1/2,1)}(\omega), \qquad \omega \in (0,1).$$ Then $X \sim Y$. Set $X_n(\omega) := Y(\omega)$ for all $n \in \mathbb{N}, \omega \in (0,1)$.

1.  $X_n \to X$ in distribution since $X_n \sim X$ for any $n \in \mathbb{N}$
2. $X_n$ does not converge in probability to $X$ since $$\lambda(|X_n-X|&gt;1/2)= \lambda(|X-Y|&gt;1/2) = 1.$$', u'owner': {u'user_id': 36150, u'user_type': u'registered', u'reputation': 71703, u'link': u'https://math.stackexchange.com/users/36150/saz', u'accept_rate': 95, u'display_name': u'saz', u'badge_counts': {u'bronze': 109, u'silver': 49, u'gold': 5}}, u'is_accepted': True, u'last_edit_date': 1422281071, u'share_link': u'https://math.stackexchange.com/a/1120343', u'answer_id': 1120343}]","Does convergence in distribution imply convergence in probability ? 

I suppose no, but I need a counterexample. Does anyone know any counterexamples ?","[Consider the probability space $((0,1),\mathcal{B}(0,1))$ endowed with the Lebesgue measure  $\lambda$ and the random variables $$X(\omega) := 1_{(0,1/2)}(\omega) \qquad \qquad Y(\omega) := 1_{(1/2,1)}(\omega), \qquad \omega \in (0,1).$$ Then $X \sim Y$. Set $X_n(\omega) := Y(\omega)$ for all $n \in \mathbb{N}, \omega \in (0,1)$.

1.  $X_n \to X$ in distribution since $X_n \sim X$ for any $n \in \mathbb{N}$
2. $X_n$ does not converge in probability to $X$ since $$\lambda(|X_n-X|&gt;1/2)= \lambda(|X-Y|&gt;1/2) = 1.$$]",,,,,,0,,1422280056,0,1,True,1422281071,,https://math.stackexchange.com/questions/1120338/relation-between-convergence-in-distribution-and-in-probability,99.0,53.0,3.0,20.0,WLOG,https://math.stackexchange.com/users/21024/wlog,7044.0,21024.0,registered,,1120338,1,https://math.stackexchange.com/q/1120338,"[probability, probability-theory, convergence, examples-counterexamples]",Relation between convergence in distribution and in probability,1,54
28,,1,"[{u'up_vote_count': 0, u'title': u'An example of covergence to an exponential distribution, the role of continuity', u'question_id': 1114119, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1422120042, u'comments': [{u'edited': False, u'comment_id': 2280661, u'creation_date': 1422121160, u'post_id': 1117888, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 100051, u'user_type': u'registered', u'reputation': 1268, u'link': u'https://math.stackexchange.com/users/100051/sergey-zykov', u'accept_rate': 72, u'display_name': u'Sergey Zykov', u'badge_counts': {u'bronze': 16, u'silver': 5, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1114119/an-example-of-covergence-to-an-exponential-distribution-the-role-of-continuity/1117888#comment2280661_1117888'}, {u'edited': False, u'reply_to_user': {u'user_id': 100051, u'user_type': u'registered', u'reputation': 1268, u'link': u'https://math.stackexchange.com/users/100051/sergey-zykov', u'accept_rate': 72, u'display_name': u'Sergey Zykov', u'badge_counts': {u'bronze': 16, u'silver': 5, u'gold': 0}}, u'comment_id': 2280669, u'creation_date': 1422121277, u'post_id': 1117888, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 202257, u'user_type': u'registered', u'reputation': 4359, u'link': u'https://math.stackexchange.com/users/202257/ki3i', u'display_name': u'ki3i', u'badge_counts': {u'bronze': 16, u'silver': 7, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1114119/an-example-of-covergence-to-an-exponential-distribution-the-role-of-continuity/1117888#comment2280669_1117888'}, {u'edited': False, u'comment_id': 2280679, u'creation_date': 1422121463, u'post_id': 1117888, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 100051, u'user_type': u'registered', u'reputation': 1268, u'link': u'https://math.stackexchange.com/users/100051/sergey-zykov', u'accept_rate': 72, u'display_name': u'Sergey Zykov', u'badge_counts': {u'bronze': 16, u'silver': 5, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1114119/an-example-of-covergence-to-an-exponential-distribution-the-role-of-continuity/1117888#comment2280679_1117888'}, {u'edited': False, u'reply_to_user': {u'user_id': 100051, u'user_type': u'registered', u'reputation': 1268, u'link': u'https://math.stackexchange.com/users/100051/sergey-zykov', u'accept_rate': 72, u'display_name': u'Sergey Zykov', u'badge_counts': {u'bronze': 16, u'silver': 5, u'gold': 0}}, u'comment_id': 2280885, u'creation_date': 1422126582, u'post_id': 1117888, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 202257, u'user_type': u'registered', u'reputation': 4359, u'link': u'https://math.stackexchange.com/users/202257/ki3i', u'display_name': u'ki3i', u'badge_counts': {u'bronze': 16, u'silver': 7, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1114119/an-example-of-covergence-to-an-exponential-distribution-the-role-of-continuity/1117888#comment2280885_1117888'}, {u'edited': False, u'comment_id': 2281439, u'creation_date': 1422141171, u'post_id': 1117888, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 100051, u'user_type': u'registered', u'reputation': 1268, u'link': u'https://math.stackexchange.com/users/100051/sergey-zykov', u'accept_rate': 72, u'display_name': u'Sergey Zykov', u'badge_counts': {u'bronze': 16, u'silver': 5, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1114119/an-example-of-covergence-to-an-exponential-distribution-the-role-of-continuity/1117888#comment2281439_1117888'}, {u'edited': False, u'comment_id': 2281453, u'creation_date': 1422141582, u'post_id': 1117888, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 100051, u'user_type': u'registered', u'reputation': 1268, u'link': u'https://math.stackexchange.com/users/100051/sergey-zykov', u'accept_rate': 72, u'display_name': u'Sergey Zykov', u'badge_counts': {u'bronze': 16, u'silver': 5, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1114119/an-example-of-covergence-to-an-exponential-distribution-the-role-of-continuity/1117888#comment2281453_1117888'}, {u'edited': False, u'reply_to_user': {u'user_id': 100051, u'user_type': u'registered', u'reputation': 1268, u'link': u'https://math.stackexchange.com/users/100051/sergey-zykov', u'accept_rate': 72, u'display_name': u'Sergey Zykov', u'badge_counts': {u'bronze': 16, u'silver': 5, u'gold': 0}}, u'comment_id': 2281627, u'creation_date': 1422147649, u'post_id': 1117888, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 202257, u'user_type': u'registered', u'reputation': 4359, u'link': u'https://math.stackexchange.com/users/202257/ki3i', u'display_name': u'ki3i', u'badge_counts': {u'bronze': 16, u'silver': 7, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1114119/an-example-of-covergence-to-an-exponential-distribution-the-role-of-continuity/1117888#comment2281627_1117888'}, {u'edited': False, u'reply_to_user': {u'user_id': 100051, u'user_type': u'registered', u'reputation': 1268, u'link': u'https://math.stackexchange.com/users/100051/sergey-zykov', u'accept_rate': 72, u'display_name': u'Sergey Zykov', u'badge_counts': {u'bronze': 16, u'silver': 5, u'gold': 0}}, u'comment_id': 2281646, u'creation_date': 1422148314, u'post_id': 1117888, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 202257, u'user_type': u'registered', u'reputation': 4359, u'link': u'https://math.stackexchange.com/users/202257/ki3i', u'display_name': u'ki3i', u'badge_counts': {u'bronze': 16, u'silver': 7, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1114119/an-example-of-covergence-to-an-exponential-distribution-the-role-of-continuity/1117888#comment2281646_1117888'}], u'creation_date': 1422120042, u'comment_count': 8, u'score': 0, u'link': u'https://math.stackexchange.com/questions/1114119/an-example-of-covergence-to-an-exponential-distribution-the-role-of-continuity/1117888#1117888', u'body_markdown': u'**Hint:**

Assuming [Riemann integration][1], how do you justify the existence of integrals like
$$
\int\limits_{0}^{x/n}f(t)\,\mathrm{d}t\,?
$$


  [1]: http://en.wikipedia.org/wiki/Riemann_integral#Integrability', u'owner': {u'user_id': 202257, u'user_type': u'registered', u'reputation': 4359, u'link': u'https://math.stackexchange.com/users/202257/ki3i', u'display_name': u'ki3i', u'badge_counts': {u'bronze': 16, u'silver': 7, u'gold': 1}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/1117888', u'answer_id': 1117888}]","I got a probability problem I can solve, but my solution does not use an assumption which is given in the formulation of the problem. I am afraid that this is might be a sign that my solution is incorrect. Could you please take a look and let me know whether the assumption is indeed needed.

$X_1, X_2,...$ are i.i.d. random variables, $X_1$ has a continuous pdf $f(x)$ such that $\lambda = \lim_{0 \leftarrow x}f(x)&gt;0$ and $f(x)&gt;0$ $\forall x \in (0, \infty)$, $Z_n=n* \min(X_1,...,X_n)$, show that $Z_n \rightarrow Z$ in distribution and $Z$ is exponentially distributed with parameter $\lambda$. My concern that I can show it without using the continuity of $f$.

We consider $x&gt;0$, because for $x \le 0$ $P(Z_n&gt;x)=1$. 

$P(Z_n&gt;x)=P(n* \min(X_1,...,X_n)&gt;x)=P(X_1&gt;\frac{x}{n})^n=(1-F_{X_1}(\frac{x}{n}))^n=(1-\int_0^{\frac{x}{n}}f(t)dt)^n$

I show that $\lim_{n \to \infty}P(Z_n&gt;x)=e^{-\lambda x}$ $\forall x&gt;0$.

I change value of $f$ just at point $0$, I say $f(0)=\lambda$. The changed $f$ is still pdf for $X_1$, and the changed pdf is right continuous, i.e. $\lim_{0 \leftarrow x}f(x)=\lambda=f(0)$. 

Then $\forall\epsilon&gt;0$ $\exists \delta$ such that $\forall$ $0&lt;t&lt;\delta$ $|\lambda - f(t)|&lt;\epsilon$ $\Rightarrow$ $\lambda - \epsilon &lt; f(t) &lt; \lambda + \epsilon$. I find $n_0$ such that $\frac{x}{n_0}&lt;\delta$, then $\forall n&gt;n_0$:

$\int_{0}^{x/n}(\lambda - \epsilon)dt &lt; \int_{0}^{x/n}f(t)dt&lt;\int_{0}^{x/n}(\lambda + \epsilon)dt$.

Thus:

$\frac{(\lambda - \epsilon)x}{n}&lt;F(\frac{x}{n})&lt;\frac{(\lambda + \epsilon)x}{n}$,

and 

($1-\frac{(\lambda - \epsilon)x}{n})^n&gt;(1-F(\frac{x}{n}))^n&gt;(1-\frac{(\lambda + \epsilon)x}{n})^n$.

It follows that:

$e^{-(\lambda - \epsilon)x} \ge \lim_{n \to \infty}P(Z_n&gt;x) \ge e^{-(\lambda +\epsilon)x}$.


Because $\epsilon$ can be as close to $0$ as we wish, $\lim_{n \to \infty}P(Z_n&gt;x)=e^{-\lambda x}$ and $Z$ is exponentially distributed with parameter $\lambda$.

As you see I nowhere use the continuity of $f$, what I am doing wrong?

  ","[**Hint:**

Assuming [Riemann integration][1], how do you justify the existence of integrals like
$$
\int\limits_{0}^{x/n}f(t)\,\mathrm{d}t\,?
$$


  [1]: http://en.wikipedia.org/wiki/Riemann_integral#Integrability]",,,,,,0,,1421874908,0,0,False,1422120042,,https://math.stackexchange.com/questions/1114119/an-example-of-covergence-to-an-exponential-distribution-the-role-of-continuity,72.0,16.0,0.0,5.0,Sergey Zykov,https://math.stackexchange.com/users/100051/sergey-zykov,1268.0,100051.0,registered,,1114119,0,https://math.stackexchange.com/q/1114119,"[probability, probability-theory, probability-distributions, examples-counterexamples]","An example of covergence to an exponential distribution, the role of continuity",0,32
29,,1,"[{u'up_vote_count': 0, u'title': u'Example: convergence in distributions', u'question_id': 1111276, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1421771649, u'creation_date': 1421771649, u'comment_count': 0, u'score': 0, u'link': u'https://math.stackexchange.com/questions/1111276/example-convergence-in-distributions/1112243#1112243', u'body_markdown': u'Notice that if $(X_n)$ and $(Y_n)$ are weakly convergent, then the sequence $(X_n+Y_n)_{n\geqslant 1}$ is tight, hence we can extract a weakly convergent subsequence. Therefore, the problem may come from the non-uniqueness of the potential limiting distributions. 

Consider $(\xi_i)_{i\geqslant 1}$ a sequence of i.i.d. centered random variables with unit variance.

If $n$ is even, define 
$$X_n:=\frac 1{\sqrt n}\sum_{i=1}^n\xi_i\mbox{ and }Y_n:=-\frac 1{\sqrt n}\sum_{i=1}^n\xi_i,$$
and if $n$ is odd, then 
$$X_n:=\frac 1{\sqrt n}\sum_{i=1}^n\xi_i\mbox{ and }Y_n:=\frac 1{\sqrt n}\sum_{i=n+1}^{2n}\xi_i.$$
Then $X_n\to X$ and $Y_n\to Y$ where $X$ and $Y$ are standard normal, but the sequence $(X_{2n}+Y_{2n})_{n\geqslant 1}$ is null while the sequence $(X_{2n+1}+Y_{2n+1})_{n\geqslant 1}$ converges weakly to a (non-degenerated) normal distribution.', u'owner': {u'user_id': 9849, u'user_type': u'registered', u'reputation': 119936, u'link': u'https://math.stackexchange.com/users/9849/davide-giraudo', u'accept_rate': 80, u'display_name': u'Davide Giraudo', u'badge_counts': {u'bronze': 247, u'silver': 144, u'gold': 15}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/1112243', u'answer_id': 1112243}]","Give an example $X _n \rightarrow X$ in distribution, $Y _n \rightarrow Y$ in distribution, but $X_n + Y_n$ does not converge to $X+Y$ in distribution. 

I got a trivial one. $X_n$ is $\mathcal N(0,1)$ $\forall n$, $Y_n=-X_n$, $X$ and $Y$ are also $\mathcal N(0,1)$, then $X _n \rightarrow X$ and $Y _n \rightarrow Y$, but $X_n+Y_n=0$ does not converge to $X+Y$ which is $\mathcal N(0,2)$ distributed. 

Do you have a more interesting example?    ","[Notice that if $(X_n)$ and $(Y_n)$ are weakly convergent, then the sequence $(X_n+Y_n)_{n\geqslant 1}$ is tight, hence we can extract a weakly convergent subsequence. Therefore, the problem may come from the non-uniqueness of the potential limiting distributions. 

Consider $(\xi_i)_{i\geqslant 1}$ a sequence of i.i.d. centered random variables with unit variance.

If $n$ is even, define 
$$X_n:=\frac 1{\sqrt n}\sum_{i=1}^n\xi_i\mbox{ and }Y_n:=-\frac 1{\sqrt n}\sum_{i=1}^n\xi_i,$$
and if $n$ is odd, then 
$$X_n:=\frac 1{\sqrt n}\sum_{i=1}^n\xi_i\mbox{ and }Y_n:=\frac 1{\sqrt n}\sum_{i=n+1}^{2n}\xi_i.$$
Then $X_n\to X$ and $Y_n\to Y$ where $X$ and $Y$ are standard normal, but the sequence $(X_{2n}+Y_{2n})_{n\geqslant 1}$ is null while the sequence $(X_{2n+1}+Y_{2n+1})_{n\geqslant 1}$ converges weakly to a (non-degenerated) normal distribution.]",,,,,,0,,1421708601,0,1,False,1421771649,1421712045.0,https://math.stackexchange.com/questions/1111276/example-convergence-in-distributions,72.0,16.0,0.0,5.0,Sergey Zykov,https://math.stackexchange.com/users/100051/sergey-zykov,1268.0,100051.0,registered,,1111276,2,https://math.stackexchange.com/q/1111276,"[probability, probability-theory, probability-distributions, examples-counterexamples]",Example: convergence in distributions,2,136
30,,1,"[{u'up_vote_count': 2, u'title': u'Martingale $X_n \to \infty$ a.s.', u'question_id': 1040595, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1417314372, u'comments': [{u'edited': False, u'comment_id': 2120490, u'creation_date': 1417065472, u'post_id': 1040635, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 186073, u'user_type': u'registered', u'reputation': 15, u'link': u'https://math.stackexchange.com/users/186073/user186073', u'accept_rate': 50, u'display_name': u'user186073', u'badge_counts': {u'bronze': 5, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1040595/martingale-x-n-to-infty-a-s/1040635#comment2120490_1040635'}, {u'edited': False, u'reply_to_user': {u'user_id': 186073, u'user_type': u'registered', u'reputation': 15, u'link': u'https://math.stackexchange.com/users/186073/user186073', u'accept_rate': 50, u'display_name': u'user186073', u'badge_counts': {u'bronze': 5, u'silver': 0, u'gold': 0}}, u'comment_id': 2120546, u'creation_date': 1417068928, u'post_id': 1040635, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 22064, u'user_type': u'registered', u'reputation': 23324, u'link': u'https://math.stackexchange.com/users/22064/alex-r', u'accept_rate': 55, u'display_name': u'Alex R.', u'badge_counts': {u'bronze': 50, u'silver': 22, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/1040595/martingale-x-n-to-infty-a-s/1040635#comment2120546_1040635'}, {u'edited': False, u'comment_id': 2127875, u'creation_date': 1417313610, u'post_id': 1040635, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 140541, u'user_type': u'registered', u'reputation': 7276, u'link': u'https://math.stackexchange.com/users/140541/d-k-o', u'accept_rate': 100, u'display_name': u'd.k.o.', u'badge_counts': {u'bronze': 25, u'silver': 5, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1040595/martingale-x-n-to-infty-a-s/1040635#comment2127875_1040635'}, {u'edited': False, u'comment_id': 2127896, u'creation_date': 1417314496, u'post_id': 1040635, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 140541, u'user_type': u'registered', u'reputation': 7276, u'link': u'https://math.stackexchange.com/users/140541/d-k-o', u'accept_rate': 100, u'display_name': u'd.k.o.', u'badge_counts': {u'bronze': 25, u'silver': 5, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1040595/martingale-x-n-to-infty-a-s/1040635#comment2127896_1040635'}, {u'edited': False, u'comment_id': 2128327, u'creation_date': 1417331111, u'post_id': 1040635, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 140541, u'user_type': u'registered', u'reputation': 7276, u'link': u'https://math.stackexchange.com/users/140541/d-k-o', u'accept_rate': 100, u'display_name': u'd.k.o.', u'badge_counts': {u'bronze': 25, u'silver': 5, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/1040595/martingale-x-n-to-infty-a-s/1040635#comment2128327_1040635'}], u'creation_date': 1417062852, u'comment_count': 5, u'score': 2, u'link': u'https://math.stackexchange.com/questions/1040595/martingale-x-n-to-infty-a-s/1040635#1040635', u'body_markdown': u'Let $X_1:=0$, $\ X_n:=X_{n-1}-(n-1)+Y_{n}$, where $Y_n$ is independent, $\mathcal{F}_{n}$ measurable and $P(Y_n=0)=1/n$, $P(Y_n=n)=1-1/n$. Then $E[Y_n]=n-1$, so $E[X_n|\mathcal{F}_{n-1}]=X_{n-1}$. Since $X_n\rightarrow\infty$ is a 0-1 event, we just need to show that it occurs with positive probability to conclude $X_n\rightarrow\infty$ almost surely. If $Y_n=n$, then $X_n=X_{n-1}+1$, so clearly 

$$P(X_n\rightarrow\infty)\geq \prod_{n=2}^\infty (1-1/n)\geq \lim_{n\rightarrow\infty} (1-1/n)^n=e^{-1}&gt;0$$

', u'owner': {u'user_id': 22064, u'user_type': u'registered', u'reputation': 23324, u'link': u'https://math.stackexchange.com/users/22064/alex-r', u'accept_rate': 55, u'display_name': u'Alex R.', u'badge_counts': {u'bronze': 50, u'silver': 22, u'gold': 1}}, u'is_accepted': False, u'last_edit_date': 1417314372, u'share_link': u'https://math.stackexchange.com/a/1040635', u'answer_id': 1040635}]","Construct a martingale $X_n$ such that $X_n \to \infty $  a.s.

I have trouble coming up with such an example and prove it. Can someone provide an example?","[Let $X_1:=0$, $\ X_n:=X_{n-1}-(n-1)+Y_{n}$, where $Y_n$ is independent, $\mathcal{F}_{n}$ measurable and $P(Y_n=0)=1/n$, $P(Y_n=n)=1-1/n$. Then $E[Y_n]=n-1$, so $E[X_n|\mathcal{F}_{n-1}]=X_{n-1}$. Since $X_n\rightarrow\infty$ is a 0-1 event, we just need to show that it occurs with positive probability to conclude $X_n\rightarrow\infty$ almost surely. If $Y_n=n$, then $X_n=X_{n-1}+1$, so clearly 

$$P(X_n\rightarrow\infty)\geq \prod_{n=2}^\infty (1-1/n)\geq \lim_{n\rightarrow\infty} (1-1/n)^n=e^{-1}&gt;0$$

]",,,,,,0,,1417059452,0,0,True,1417314372,1417095200.0,https://math.stackexchange.com/questions/1040595/martingale-x-n-to-infty-a-s,50.0,5.0,0.0,0.0,user186073,https://math.stackexchange.com/users/186073/user186073,15.0,186073.0,registered,,1040595,0,https://math.stackexchange.com/q/1040595,"[probability, probability-theory, examples-counterexamples, martingales]",Martingale $X_n \to \infty$ a.s.,0,88
31,966841.0,1,"[{u'up_vote_count': 0, u'title': u'Seeking a possible counterexample in probability.', u'question_id': 964653, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1412955703, u'creation_date': 1412955703, u'comment_count': 0, u'score': 0, u'link': u'https://math.stackexchange.com/questions/964653/seeking-a-possible-counterexample-in-probability/966841#966841', u'body_markdown': u'I think I have figured it out.
The converse doesn&#39;t hold. A counterexample is pretty intuitive. My idea was right, but one just need to tune the parameters a little to get satisfy all the conditions. 
', u'owner': {u'user_id': 179271, u'user_type': u'registered', u'reputation': 82, u'link': u'https://math.stackexchange.com/users/179271/victor', u'accept_rate': 55, u'display_name': u'Victor', u'badge_counts': {u'bronze': 8, u'silver': 0, u'gold': 0}}, u'is_accepted': True, u'share_link': u'https://math.stackexchange.com/a/966841', u'answer_id': 966841}]","I am trying to find a counterexample or prove the following:

$\dfrac{Var\left(X_{n}\right)}{\left[EX_{n}\right]^{2}}\rightarrow0
 , then \dfrac{X_{n}}{EX_{n}}\rightarrow1$
  in probability. Assuming $EX_n\rightarrow\infty$. Note that $X_n$ doesn&#39;t have any special restrictions. 


I can show this holds no problem using L2 convergence implies convergence in probability. However, I don&#39;t know if the converse holds. I tried to give some counterexamples but they all seem to fail. I tried the form $X_n=n^k1_{[0,1-\frac{1}{n})}$  or something similar. I hope someone can point to me if I am on the right direction.","[I think I have figured it out.
The converse doesn&#39;t hold. A counterexample is pretty intuitive. My idea was right, but one just need to tune the parameters a little to get satisfy all the conditions. 
]",,,,,,0,,1412822365,0,0,True,1412955703,,https://math.stackexchange.com/questions/964653/seeking-a-possible-counterexample-in-probability,55.0,8.0,0.0,0.0,Victor,https://math.stackexchange.com/users/179271/victor,82.0,179271.0,registered,,964653,0,https://math.stackexchange.com/q/964653,"[probability, convergence, examples-counterexamples]",Seeking a possible counterexample in probability.,0,83
32,912190.0,1,"[{u'up_vote_count': 1, u'title': u'How to convert a problem to a stars and bars problem?', u'question_id': 911618, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1409240639, u'comments': [{u'edited': False, u'comment_id': 1942800, u'creation_date': 1411457667, u'post_id': 912190, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 171371, u'user_type': u'registered', u'reputation': 145, u'link': u'https://math.stackexchange.com/users/171371/partly-putrid-pile-of-pus', u'accept_rate': 75, u'display_name': u'Partly Putrid Pile of Pus', u'badge_counts': {u'bronze': 8, u'silver': 1, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/911618/how-to-convert-a-problem-to-a-stars-and-bars-problem/912190#comment1942800_912190'}], u'creation_date': 1409240639, u'comment_count': 1, u'score': 1, u'link': u'https://math.stackexchange.com/questions/911618/how-to-convert-a-problem-to-a-stars-and-bars-problem/912190#912190', u'body_markdown': u'I don&#39;t know if it can be done as a single S&amp;B calculation but here are two S&amp;B approaches:

(1) Do S&amp;B for the equation &lt;b&gt;without&lt;/b&gt; restriction. Subtract from that another S&amp;B with restriction $x_1 \geq 4$.

(2) Do a separate S&amp;B, omitting $x_1$ from the equation, for each of the four cases: $x_1 = 0,1,2,3$. Then sum the four results.

&lt;b&gt;Example&lt;/b&gt;: Take $i=4$ so we have

$$\def\x{x_}\x1+\x2+\x3+x_4 =15\qquad\mbox{with }\x1\leq3$$

(1) S&amp;B without restriction: we have $4-1 = 3$ bars and $15$ stars. #Ways= $\binom{18}{3}$.

S&amp;B with $x_1 \geq 4$: we have $4-1=3$ bars and $11$ stars. #Ways = $\binom{14}{3}$. 

TotalWays = $\binom{18}{3} - \binom{14}{3} = 452$.

(2) S&amp;B with $x_1=0$: we have $3-1=2$ bars and $15$ stars. #Ways = $\binom{17}{2}$.

(The equation we have here is: $x_2+x_3+x_4 =15$.)

S&amp;B with $x_1=1$: we have $3-1=2$ bars and $14$ stars. #Ways = $\binom{16}{2}$.

S&amp;B with $x_1=2$: we have $3-1=2$ bars and $13$ stars. #Ways = $\binom{15}{2}$.

S&amp;B with $x_1=3$: we have $3-1=2$ bars and $12$ stars. #Ways = $\binom{14}{2}$.

TotalWays = $\binom{17}{2} + \binom{16}{2} + \binom{15}{2} + \binom{14}{2} = 452$.', u'owner': {u'user_id': 153109, u'user_type': u'registered', u'reputation': 8545, u'link': u'https://math.stackexchange.com/users/153109/mick-a', u'display_name': u'Mick A', u'badge_counts': {u'bronze': 23, u'silver': 8, u'gold': 2}}, u'is_accepted': True, u'share_link': u'https://math.stackexchange.com/a/912190', u'answer_id': 912190}]","Continued question from [here][1].


----------
With certain questions I have $x_i$ being constrained by various different inequalities, I want to know how to remove these from the problem, to bring me back to a straight forward application of the stars and bars method.

How can I convert a problem like:

$$\def\x{x_}\x1+\x2+\x3+\dots+x_i =15$$ with $\x1\leq3$

Back to a simple stars and bars problem such as $$y_1+\x2+\x3+\dots+x_i=33$$

How can I convert that bad $\x1$ into a nice $y_1$

$x_i,y_i\in\mathbb{Z^{\geq0}}$


----------
I can see how to do it for $x_i \geq k$ since I can just take $y_a =x_a - k \geq 0$ and take $x_a = y_a +k$ and sub it into the original equation, which gives me some stars and some bars :).

  [1]: https://math.stackexchange.com/questions/910809/how-to-use-stars-and-barscombinatorics","[I don&#39;t know if it can be done as a single S&amp;B calculation but here are two S&amp;B approaches:

(1) Do S&amp;B for the equation &lt;b&gt;without&lt;/b&gt; restriction. Subtract from that another S&amp;B with restriction $x_1 \geq 4$.

(2) Do a separate S&amp;B, omitting $x_1$ from the equation, for each of the four cases: $x_1 = 0,1,2,3$. Then sum the four results.

&lt;b&gt;Example&lt;/b&gt;: Take $i=4$ so we have

$$\def\x{x_}\x1+\x2+\x3+x_4 =15\qquad\mbox{with }\x1\leq3$$

(1) S&amp;B without restriction: we have $4-1 = 3$ bars and $15$ stars. #Ways= $\binom{18}{3}$.

S&amp;B with $x_1 \geq 4$: we have $4-1=3$ bars and $11$ stars. #Ways = $\binom{14}{3}$. 

TotalWays = $\binom{18}{3} - \binom{14}{3} = 452$.

(2) S&amp;B with $x_1=0$: we have $3-1=2$ bars and $15$ stars. #Ways = $\binom{17}{2}$.

(The equation we have here is: $x_2+x_3+x_4 =15$.)

S&amp;B with $x_1=1$: we have $3-1=2$ bars and $14$ stars. #Ways = $\binom{16}{2}$.

S&amp;B with $x_1=2$: we have $3-1=2$ bars and $13$ stars. #Ways = $\binom{15}{2}$.

S&amp;B with $x_1=3$: we have $3-1=2$ bars and $12$ stars. #Ways = $\binom{14}{2}$.

TotalWays = $\binom{17}{2} + \binom{16}{2} + \binom{15}{2} + \binom{14}{2} = 452$.]",,,,,,6,"[{u'edited': False, u'comment_id': 1881400, u'creation_date': 1409197267, u'post_id': 911618, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 91818, u'user_type': u'registered', u'reputation': 20608, u'link': u'https://math.stackexchange.com/users/91818/rebecca-j-stones', u'accept_rate': 67, u'display_name': u'Rebecca J. Stones', u'badge_counts': {u'bronze': 78, u'silver': 23, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/911618/how-to-convert-a-problem-to-a-stars-and-bars-problem#comment1881400_911618'}, {u'edited': False, u'reply_to_user': {u'user_id': 91818, u'user_type': u'registered', u'reputation': 20608, u'link': u'https://math.stackexchange.com/users/91818/rebecca-j-stones', u'accept_rate': 67, u'display_name': u'Rebecca J. Stones', u'badge_counts': {u'bronze': 78, u'silver': 23, u'gold': 2}}, u'comment_id': 1881401, u'creation_date': 1409197315, u'post_id': 911618, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 171371, u'user_type': u'registered', u'reputation': 145, u'link': u'https://math.stackexchange.com/users/171371/partly-putrid-pile-of-pus', u'accept_rate': 75, u'display_name': u'Partly Putrid Pile of Pus', u'badge_counts': {u'bronze': 8, u'silver': 1, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/911618/how-to-convert-a-problem-to-a-stars-and-bars-problem#comment1881401_911618'}, {u'edited': False, u'comment_id': 1881812, u'creation_date': 1409216024, u'post_id': 911618, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 167226, u'user_type': u'registered', u'reputation': 8447, u'link': u'https://math.stackexchange.com/users/167226/idm', u'accept_rate': 54, u'display_name': u'idm', u'badge_counts': {u'bronze': 42, u'silver': 11, u'gold': 2}}, u'link': u'https://math.stackexchange.com/questions/911618/how-to-convert-a-problem-to-a-stars-and-bars-problem#comment1881812_911618'}, {u'edited': False, u'reply_to_user': {u'user_id': 167226, u'user_type': u'registered', u'reputation': 8447, u'link': u'https://math.stackexchange.com/users/167226/idm', u'accept_rate': 54, u'display_name': u'idm', u'badge_counts': {u'bronze': 42, u'silver': 11, u'gold': 2}}, u'comment_id': 1881818, u'creation_date': 1409216240, u'post_id': 911618, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 171371, u'user_type': u'registered', u'reputation': 145, u'link': u'https://math.stackexchange.com/users/171371/partly-putrid-pile-of-pus', u'accept_rate': 75, u'display_name': u'Partly Putrid Pile of Pus', u'badge_counts': {u'bronze': 8, u'silver': 1, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/911618/how-to-convert-a-problem-to-a-stars-and-bars-problem#comment1881818_911618'}, {u'edited': False, u'comment_id': 1881823, u'creation_date': 1409216368, u'post_id': 911618, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 622, u'user_type': u'registered', u'reputation': 287682, u'link': u'https://math.stackexchange.com/users/622/asaf-karagila', u'accept_rate': 87, u'display_name': u'Asaf Karagila', u'badge_counts': {u'bronze': 721, u'silver': 389, u'gold': 31}}, u'link': u'https://math.stackexchange.com/questions/911618/how-to-convert-a-problem-to-a-stars-and-bars-problem#comment1881823_911618'}, {u'edited': False, u'reply_to_user': {u'user_id': 622, u'user_type': u'registered', u'reputation': 287682, u'link': u'https://math.stackexchange.com/users/622/asaf-karagila', u'accept_rate': 87, u'display_name': u'Asaf Karagila', u'badge_counts': {u'bronze': 721, u'silver': 389, u'gold': 31}}, u'comment_id': 1881826, u'creation_date': 1409216454, u'post_id': 911618, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 171371, u'user_type': u'registered', u'reputation': 145, u'link': u'https://math.stackexchange.com/users/171371/partly-putrid-pile-of-pus', u'accept_rate': 75, u'display_name': u'Partly Putrid Pile of Pus', u'badge_counts': {u'bronze': 8, u'silver': 1, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/911618/how-to-convert-a-problem-to-a-stars-and-bars-problem#comment1881826_911618'}]",1409194778,0,0,True,1409240639,1492086002.0,https://math.stackexchange.com/questions/911618/how-to-convert-a-problem-to-a-stars-and-bars-problem,75.0,8.0,1.0,1.0,Partly Putrid Pile of Pus,https://math.stackexchange.com/users/171371/partly-putrid-pile-of-pus,145.0,171371.0,registered,,911618,1,https://math.stackexchange.com/q/911618,"[probability, combinatorics, statistics, examples-counterexamples]",How to convert a problem to a stars and bars problem?,1,884
33,1173180.0,1,"[{u'up_vote_count': 0, u'title': u'Parental Markov Condition Example', u'question_id': 909300, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1425372217, u'awarded_bounty_users': [{u'user_id': 86570, u'user_type': u'registered', u'reputation': 4319, u'link': u'https://math.stackexchange.com/users/86570/jameselmore', u'accept_rate': 90, u'display_name': u'jameselmore', u'badge_counts': {u'bronze': 35, u'silver': 17, u'gold': 3}}], u'awarded_bounty_amount': 50, u'comment_count': 0, u'score': 0, u'link': u'https://math.stackexchange.com/questions/909300/parental-markov-condition-example/1173180#1173180', u'body_markdown': u'I&#39;m not really an expert on the domains so I may say some stupid things. Sorry in advance.

Up to my understanding the difference with Markov chains is that in Markov chains you have a sequence of random variable $(X_i)$ where the $X_i$ can take as value a state of your Markov chain $X_i$ representing the probability distribution to be in a state at step $i$.

But here the random variables are associated to a certain state. Each random variable represent the probability that the variable take a certain  value and the graph represent the link between this variable.

For example, suppose that the sky is either sunny or cloudy, that the weather is either dry or rainy at that I&#39;m either dry or wet.

Let $S$ be the random variable associated to the sky $W$ to the weather and $M$ to me. And let P be the probability distribution such that $P(s,r,\_)=0$ $P(\_,d,w)=0$ $P(s,d,d)=1/2$ $P(c,d,d)=1/4$a and $P(c,r,w)=1/4$. (i.e there is probability 1/2 to be cloudy and if it&#39;s cloudy there is 1/2 chance that it&#39;s rainy and if it&#39;s rainy I&#39;m wet).

The graph $G:$ $S\to W\to M$ represent that the weather depend only on the sky and the fact that I&#39;m wet depend only if it&#39;s rainy or not  And thus P is Markov relative to G.

But if you consider the graph $G&#39;:$ $M\to S \to W$ P is not Markov relative to G since the probability that I&#39;m wet is not independent of $W$.

I hope it&#39;s clearer now ...', u'owner': {u'user_id': 65630, u'user_type': u'registered', u'reputation': 2192, u'link': u'https://math.stackexchange.com/users/65630/wece', u'accept_rate': 71, u'display_name': u'wece', u'badge_counts': {u'bronze': 22, u'silver': 8, u'gold': 1}}, u'is_accepted': True, u'creation_date': 1425372217, u'share_link': u'https://math.stackexchange.com/a/1173180', u'answer_id': 1173180}]","I&#39;m currently reading a text on Bayesian networks and the text is giving some very crude interpretations of what appear to be some of the most important foundations of the subject.

It states the following:

&gt; Theorem 1.2.7 (Parental Markov Condition):
&gt; A necessary and sufficient condition for a probability distribution P to be Markov relative a [directional acyclic graph] G is that every variable be independent of all it&#39;s nondescendants (in G), conditional on it&#39;s parents.

I understand the premise of what is happening here. Given some point X in the graph, if you condition over all parent nodes, it should be independent of all non-descendants. I guess the confusion for me arrises around how this makes the process Markov relative. Maybe that is the weak part of my understanding. Could someone please provide a example of graph which fails this condition and hence fails being Markov relative to this graph?

I&#39;ve done some study on Markov Chains and I feel like maybe their definitions differ in some way that&#39;s been lost on me.

Thanks","[I&#39;m not really an expert on the domains so I may say some stupid things. Sorry in advance.

Up to my understanding the difference with Markov chains is that in Markov chains you have a sequence of random variable $(X_i)$ where the $X_i$ can take as value a state of your Markov chain $X_i$ representing the probability distribution to be in a state at step $i$.

But here the random variables are associated to a certain state. Each random variable represent the probability that the variable take a certain  value and the graph represent the link between this variable.

For example, suppose that the sky is either sunny or cloudy, that the weather is either dry or rainy at that I&#39;m either dry or wet.

Let $S$ be the random variable associated to the sky $W$ to the weather and $M$ to me. And let P be the probability distribution such that $P(s,r,\_)=0$ $P(\_,d,w)=0$ $P(s,d,d)=1/2$ $P(c,d,d)=1/4$a and $P(c,r,w)=1/4$. (i.e there is probability 1/2 to be cloudy and if it&#39;s cloudy there is 1/2 chance that it&#39;s rainy and if it&#39;s rainy I&#39;m wet).

The graph $G:$ $S\to W\to M$ represent that the weather depend only on the sky and the fact that I&#39;m wet depend only if it&#39;s rainy or not  And thus P is Markov relative to G.

But if you consider the graph $G&#39;:$ $M\to S \to W$ P is not Markov relative to G since the probability that I&#39;m wet is not independent of $W$.

I hope it&#39;s clearer now ...]",,,,,,0,,1409016578,0,0,True,1425730756,1425730756.0,https://math.stackexchange.com/questions/909300/parental-markov-condition-example,90.0,35.0,3.0,17.0,jameselmore,https://math.stackexchange.com/users/86570/jameselmore,4319.0,86570.0,registered,,909300,1,https://math.stackexchange.com/q/909300,"[probability, examples-counterexamples, markov-process, bayesian]",Parental Markov Condition Example,1,182
34,664972.0,1,"[{u'up_vote_count': 3, u'title': u'Counter example for Random variable', u'question_id': 664968, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1391628781, u'creation_date': 1391626156, u'comment_count': 0, u'score': 3, u'link': u'https://math.stackexchange.com/questions/664968/counter-example-for-random-variable/664972#664972', u'body_markdown': u'Take any non-measurable subset $A\subseteq\mathbb{R}$ and define
$$
X(\omega)=\mathbf{1}_A(\omega)-\mathbf{1}_{A^c}(\omega),\quad\omega\in\mathbb{R},
$$
where $\mathbf{1}_A$ is the indicator function for the set $A$. Then $|X|=1$ is a random variable but $X$ isn&#39;t a random variable (why?).', u'owner': {u'user_id': 25632, u'user_type': u'registered', u'reputation': 20125, u'link': u'https://math.stackexchange.com/users/25632/stefan-hansen', u'accept_rate': 100, u'display_name': u'Stefan Hansen', u'badge_counts': {u'bronze': 58, u'silver': 33, u'gold': 7}}, u'is_accepted': True, u'last_edit_date': 1391628781, u'share_link': u'https://math.stackexchange.com/a/664972', u'answer_id': 664972}]","I read  the result that if $|X|$ is random variable then  $X$ need not be random variable.

So, I am looking for counter example. 

Thank you for your time.","[Take any non-measurable subset $A\subseteq\mathbb{R}$ and define
$$
X(\omega)=\mathbf{1}_A(\omega)-\mathbf{1}_{A^c}(\omega),\quad\omega\in\mathbb{R},
$$
where $\mathbf{1}_A$ is the indicator function for the set $A$. Then $|X|=1$ is a random variable but $X$ isn&#39;t a random variable (why?).]",,,,,,0,,1391625931,0,0,True,1391635787,1391635787.0,https://math.stackexchange.com/questions/664968/counter-example-for-random-variable,94.0,10.0,0.0,1.0,prasad,https://math.stackexchange.com/users/59489/prasad,272.0,59489.0,registered,,664968,0,https://math.stackexchange.com/q/664968,"[probability, random-variables, examples-counterexamples]",Counter example for Random variable,0,168
35,593718.0,2,"[{u'up_vote_count': 1, u'title': u'Probability of result', u'question_id': 593712, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1386286501, u'comments': [{u'edited': False, u'comment_id': 1252174, u'creation_date': 1386246947, u'post_id': 593718, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 111165, u'user_type': u'registered', u'reputation': 39, u'link': u'https://math.stackexchange.com/users/111165/user445714', u'accept_rate': 80, u'display_name': u'user445714', u'badge_counts': {u'bronze': 8, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/593712/probability-of-result/593718#comment1252174_593718'}, {u'edited': False, u'reply_to_user': {u'user_id': 111165, u'user_type': u'registered', u'reputation': 39, u'link': u'https://math.stackexchange.com/users/111165/user445714', u'accept_rate': 80, u'display_name': u'user445714', u'badge_counts': {u'bronze': 8, u'silver': 0, u'gold': 0}}, u'comment_id': 1253353, u'creation_date': 1386276233, u'post_id': 593718, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 113368, u'user_type': u'registered', u'reputation': 164, u'link': u'https://math.stackexchange.com/users/113368/natsu', u'accept_rate': 42, u'display_name': u'natsu', u'badge_counts': {u'bronze': 11, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/593712/probability-of-result/593718#comment1253353_593718'}], u'creation_date': 1386224897, u'comment_count': 2, u'score': 1, u'link': u'https://math.stackexchange.com/questions/593712/probability-of-result/593718#593718', u'body_markdown': u'Hint:

You can try to find by using binomial distribution which you want to find P(X=4)+P(X=5)

You have to set the number of trials n=5 and p=0.7.

$X\sim Bin (n,p)$

$P(X=4)= \binom{5}{4}0.7^4(1-0.7)^1$

$P(X=5)= \binom{5}{5}0.7^5(1-0.7)^0$

Hope this helps', u'owner': {u'user_id': 113368, u'user_type': u'registered', u'reputation': 164, u'link': u'https://math.stackexchange.com/users/113368/natsu', u'accept_rate': 42, u'display_name': u'natsu', u'badge_counts': {u'bronze': 11, u'silver': 0, u'gold': 0}}, u'is_accepted': True, u'last_edit_date': 1386286501, u'share_link': u'https://math.stackexchange.com/a/593718', u'answer_id': 593718}, {u'up_vote_count': 1, u'title': u'Probability of result', u'question_id': 593712, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1386225112, u'comments': [{u'edited': False, u'comment_id': 1251747, u'creation_date': 1386226067, u'post_id': 593721, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 111165, u'user_type': u'registered', u'reputation': 39, u'link': u'https://math.stackexchange.com/users/111165/user445714', u'accept_rate': 80, u'display_name': u'user445714', u'badge_counts': {u'bronze': 8, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/593712/probability-of-result/593721#comment1251747_593721'}, {u'edited': False, u'comment_id': 1252381, u'creation_date': 1386254791, u'post_id': 593721, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 111165, u'user_type': u'registered', u'reputation': 39, u'link': u'https://math.stackexchange.com/users/111165/user445714', u'accept_rate': 80, u'display_name': u'user445714', u'badge_counts': {u'bronze': 8, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/593712/probability-of-result/593721#comment1252381_593721'}, {u'edited': False, u'reply_to_user': {u'user_id': 111165, u'user_type': u'registered', u'reputation': 39, u'link': u'https://math.stackexchange.com/users/111165/user445714', u'accept_rate': 80, u'display_name': u'user445714', u'badge_counts': {u'bronze': 8, u'silver': 0, u'gold': 0}}, u'comment_id': 1254445, u'creation_date': 1386306940, u'post_id': 593721, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 112790, u'user_type': u'registered', u'reputation': 6105, u'link': u'https://math.stackexchange.com/users/112790/laars-helenius', u'accept_rate': 84, u'display_name': u'Laars Helenius', u'badge_counts': {u'bronze': 21, u'silver': 12, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/593712/probability-of-result/593721#comment1254445_593721'}], u'creation_date': 1386225112, u'comment_count': 3, u'score': 1, u'link': u'https://math.stackexchange.com/questions/593712/probability-of-result/593721#593721', u'body_markdown': u'Suppose you have a spinner and 70% of the spinner is colored red and the other 30% is colored blue. Let&#39;s say you spin the spinner and you &quot;win&quot; when it is red. 

   0.) What is the probability of winning one spin?

Now suppose I spin the spinner 5 times in a row and each time it comes up red, I win.

   1.) Are each of the 5 spins dependent or independent events?

   2.) Can you calculate the probability of winning 5 times in a row?

How is this game like making calls and getting your call answered in 3 minutes or less.

Good luck!', u'owner': {u'user_id': 112790, u'user_type': u'registered', u'reputation': 6105, u'link': u'https://math.stackexchange.com/users/112790/laars-helenius', u'accept_rate': 84, u'display_name': u'Laars Helenius', u'badge_counts': {u'bronze': 21, u'silver': 12, u'gold': 0}}, u'is_accepted': False, u'share_link': u'https://math.stackexchange.com/a/593721', u'answer_id': 593721}]","Morning,

A inbound contact centre says they will answer calls within 3 mins 70% of the time, if I ring the call centre 5 times over a week what is the probability I get my calls answered in under 3 mins more than 3 times?

P(a) = 0.7
P(b) = 0.3
P(X &gt;3)
Could someone walk me through how to do this?","[Hint:

You can try to find by using binomial distribution which you want to find P(X=4)+P(X=5)

You have to set the number of trials n=5 and p=0.7.

$X\sim Bin (n,p)$

$P(X=4)= \binom{5}{4}0.7^4(1-0.7)^1$

$P(X=5)= \binom{5}{5}0.7^5(1-0.7)^0$

Hope this helps, Suppose you have a spinner and 70% of the spinner is colored red and the other 30% is colored blue. Let&#39;s say you spin the spinner and you &quot;win&quot; when it is red. 

   0.) What is the probability of winning one spin?

Now suppose I spin the spinner 5 times in a row and each time it comes up red, I win.

   1.) Are each of the 5 spins dependent or independent events?

   2.) Can you calculate the probability of winning 5 times in a row?

How is this game like making calls and getting your call answered in 3 minutes or less.

Good luck!]",,,,,,2,"[{u'edited': False, u'comment_id': 1251701, u'creation_date': 1386224644, u'post_id': 593712, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 6312, u'user_type': u'registered', u'reputation': 444311, u'link': u'https://math.stackexchange.com/users/6312/andr%c3%a9-nicolas', u'display_name': u'Andr&#233; Nicolas', u'badge_counts': {u'bronze': 786, u'silver': 411, u'gold': 36}}, u'link': u'https://math.stackexchange.com/questions/593712/probability-of-result#comment1251701_593712'}, {u'edited': False, u'reply_to_user': {u'user_id': 6312, u'user_type': u'registered', u'reputation': 444311, u'link': u'https://math.stackexchange.com/users/6312/andr%c3%a9-nicolas', u'display_name': u'Andr&#233; Nicolas', u'badge_counts': {u'bronze': 786, u'silver': 411, u'gold': 36}}, u'comment_id': 1251707, u'creation_date': 1386224855, u'post_id': 593712, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 111165, u'user_type': u'registered', u'reputation': 39, u'link': u'https://math.stackexchange.com/users/111165/user445714', u'accept_rate': 80, u'display_name': u'user445714', u'badge_counts': {u'bronze': 8, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/593712/probability-of-result#comment1251707_593712'}]",1386224256,0,0,True,1386286501,1386224814.0,https://math.stackexchange.com/questions/593712/probability-of-result,80.0,8.0,0.0,0.0,user445714,https://math.stackexchange.com/users/111165/user445714,39.0,111165.0,registered,,593712,1,https://math.stackexchange.com/q/593712,"[probability, examples-counterexamples]",Probability of result,1,66
36,543178.0,1,"[{u'up_vote_count': 3, u'title': u'A counter example about fraction of 2 sets', u'question_id': 543168, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1382987690, u'comments': [{u'edited': False, u'comment_id': 1156967, u'creation_date': 1382987947, u'post_id': 543178, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 102357, u'user_type': u'registered', u'reputation': 166, u'link': u'https://math.stackexchange.com/users/102357/kiddo', u'accept_rate': 67, u'display_name': u'Kiddo', u'badge_counts': {u'bronze': 7, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/543168/a-counter-example-about-fraction-of-2-sets/543178#comment1156967_543178'}], u'creation_date': 1382986903, u'comment_count': 1, u'score': 3, u'link': u'https://math.stackexchange.com/questions/543168/a-counter-example-about-fraction-of-2-sets/543178#543178', u'body_markdown': u'This is a question demonstrating [Simpson&#39;s Paradox][1].

Yes, it is possible. Counter example: suppose that in department A, 81% (81 out of 100) of senior programmers finish their jobs and 80.5% (161/200) of the interns do. Suppose that in department B, 60% (120/200) of senior programmers finish their jobs and 59.5% (59/100) of interns do. 

Overall, this means that only 67% (201/300) of senior programmers finish their jobs, while 73.3% (220/300) of interns do, even though within each department, a greater fraction of senior programmers finish their jobs than interns.

This effect seems paradoxical. The reason it is true is because taking the &quot;overall&quot; average (combining the two departments) hides the true efficiency of the senior programmers. In departments A and B, the senior programmers are more efficient than the interns. Notably, both groups were much less efficient in department B. Most importantly, there are way more interns in department A than B, and vice-versa for the seniors. This means that the excess of seniors in department B (with lower efficiency) brings down the overall senior efficiency, while the surplus of interns in department A (with higher efficiency) brings up the interns&#39; overall efficiency. This makes it appear that the interns are more efficient, while in fact, they are not.

  [1]: http://en.wikipedia.org/wiki/Simpson%27s_paradox', u'owner': {u'user_id': 103877, u'user_type': u'registered', u'reputation': 206, u'link': u'https://math.stackexchange.com/users/103877/asaini007', u'display_name': u'asaini007', u'badge_counts': {u'bronze': 5, u'silver': 2, u'gold': 0}}, u'is_accepted': True, u'last_edit_date': 1382987690, u'share_link': u'https://math.stackexchange.com/a/543178', u'answer_id': 543178}]","In a software company there are 2 departments, called A and B. In department A, the fraction of senior programmers (of out the junior programmers in this department) finishing the jobs in time is higher than the fraction of intern finishing the job in time (of out the interns in this apartment). 

Same thing happens at department B, the fraction of senior programmers finishing the jobs in time is higher than the fraction of intern finishing the job in time. 

is it necessary true that the fraction of senior programmers in either department A or B (out of all senior programmers in either department) is higher than the fraction of intern in either department A or B (out all of interns in either department)?

Provide a counter example (number of senior programmers and interns in each department, and the fraction that finishes the job in time)

REMARK: I don&#39;t really think this problem is true or cannot be solved by providing a counter example, but I may be wrong. Please give me some ideas on this problem. Thank you.","[This is a question demonstrating [Simpson&#39;s Paradox][1].

Yes, it is possible. Counter example: suppose that in department A, 81% (81 out of 100) of senior programmers finish their jobs and 80.5% (161/200) of the interns do. Suppose that in department B, 60% (120/200) of senior programmers finish their jobs and 59.5% (59/100) of interns do. 

Overall, this means that only 67% (201/300) of senior programmers finish their jobs, while 73.3% (220/300) of interns do, even though within each department, a greater fraction of senior programmers finish their jobs than interns.

This effect seems paradoxical. The reason it is true is because taking the &quot;overall&quot; average (combining the two departments) hides the true efficiency of the senior programmers. In departments A and B, the senior programmers are more efficient than the interns. Notably, both groups were much less efficient in department B. Most importantly, there are way more interns in department A than B, and vice-versa for the seniors. This means that the excess of seniors in department B (with lower efficiency) brings down the overall senior efficiency, while the surplus of interns in department A (with higher efficiency) brings up the interns&#39; overall efficiency. This makes it appear that the interns are more efficient, while in fact, they are not.

  [1]: http://en.wikipedia.org/wiki/Simpson%27s_paradox]",,,,,,1,"[{u'edited': False, u'comment_id': 1156917, u'creation_date': 1382986878, u'post_id': 543168, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 83702, u'user_type': u'moderator', u'reputation': 168997, u'link': u'https://math.stackexchange.com/users/83702/daniel-fischer', u'display_name': u'Daniel Fischer', u'badge_counts': {u'bronze': 271, u'silver': 149, u'gold': 16}}, u'link': u'https://math.stackexchange.com/questions/543168/a-counter-example-about-fraction-of-2-sets#comment1156917_543168'}]",1382986460,0,0,True,1382987690,,https://math.stackexchange.com/questions/543168/a-counter-example-about-fraction-of-2-sets,67.0,7.0,0.0,0.0,Kiddo,https://math.stackexchange.com/users/102357/kiddo,166.0,102357.0,registered,,543168,1,https://math.stackexchange.com/q/543168,"[probability, examples-counterexamples, conditional-probability]",A counter example about fraction of 2 sets,1,254
37,443283.0,1,"[{u'up_vote_count': 2, u'title': u'Counterexample for finite dimensional weak convergence', u'question_id': 443245, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1374268451, u'comments': [{u'edited': False, u'comment_id': 961382, u'creation_date': 1374267702, u'post_id': 443283, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 39778, u'user_type': u'registered', u'reputation': 986, u'link': u'https://math.stackexchange.com/users/39778/salih-ucan', u'accept_rate': 74, u'display_name': u'Salih Ucan', u'badge_counts': {u'bronze': 21, u'silver': 9, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/443245/counterexample-for-finite-dimensional-weak-convergence/443283#comment961382_443283'}, {u'edited': False, u'reply_to_user': {u'user_id': 39778, u'user_type': u'registered', u'reputation': 986, u'link': u'https://math.stackexchange.com/users/39778/salih-ucan', u'accept_rate': 74, u'display_name': u'Salih Ucan', u'badge_counts': {u'bronze': 21, u'silver': 9, u'gold': 1}}, u'comment_id': 961393, u'creation_date': 1374268460, u'post_id': 443283, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 9849, u'user_type': u'registered', u'reputation': 119936, u'link': u'https://math.stackexchange.com/users/9849/davide-giraudo', u'accept_rate': 80, u'display_name': u'Davide Giraudo', u'badge_counts': {u'bronze': 247, u'silver': 144, u'gold': 15}}, u'link': u'https://math.stackexchange.com/questions/443245/counterexample-for-finite-dimensional-weak-convergence/443283#comment961393_443283'}], u'creation_date': 1373790570, u'comment_count': 2, u'score': 2, u'link': u'https://math.stackexchange.com/questions/443245/counterexample-for-finite-dimensional-weak-convergence/443283#443283', u'body_markdown': u'Take $x_n\in&#160;C[0,\infty)$ piecewise linear, with $x_n(n^{-1})=1$, $x_n(0)=0$, $x_n(t)=0$ for $t\geqslant 2n^{-1}$. Take $\mu_n:=\delta_{x_n}$. The finite-dimensional distributions converge weakly to those of $\delta_{\mathbf 0}$.

Indeed, let $t_1,\dots,t_d\in (0,+\infty)$. Then $\mu_n\pi_{t_1,\dots,t_d}^{‚Äî1}=\delta_0$ when $n$ is large enough. Gluing $0$ to $t_1,\dots,t_d$ is not a problem.

But these is not weak convergence (because $(x_n,n\geqslant 1)$ doesn&#39;t converge uniformly to $0$). Indeed, one can show that if $(X,d)$ is a metric space and $(x_n,n\geqslant 1)$ is a sequence in $X$ and $x\in X$, then $\delta_{x_n}\to \delta_x$ in distribution if and only if $d(x_n,x)\to 0$.

However, for general $\mu_n$ and $\mu$, if $\mu_n\to \mu$ weakly, since the finite-dimensional projection are continuous, we have $\mu_n\pi^{-1}_{t_1,\dots,t_d}\to \mu\pi^{-1}_{t_1,\dots,t_d}$ for all integer $d$ and $t_1,\dots,t_d\in [0,\infty)$.

What was missing in the first example is _tightness_. ', u'owner': {u'user_id': 9849, u'user_type': u'registered', u'reputation': 119936, u'link': u'https://math.stackexchange.com/users/9849/davide-giraudo', u'accept_rate': 80, u'display_name': u'Davide Giraudo', u'badge_counts': {u'bronze': 247, u'silver': 144, u'gold': 15}}, u'is_accepted': True, u'last_edit_date': 1374268451, u'share_link': u'https://math.stackexchange.com/a/443283', u'answer_id': 443283}]","Could you give an explicit construction of a sequence $\mathbb P_n$ of probability measures on $C[0,\infty]$ which converges in the sense of finite dimensional distributions BUT
does not converge weakly?


Also why is the converse always true how to show it?

Thanks a lot!","[Take $x_n\in&#160;C[0,\infty)$ piecewise linear, with $x_n(n^{-1})=1$, $x_n(0)=0$, $x_n(t)=0$ for $t\geqslant 2n^{-1}$. Take $\mu_n:=\delta_{x_n}$. The finite-dimensional distributions converge weakly to those of $\delta_{\mathbf 0}$.

Indeed, let $t_1,\dots,t_d\in (0,+\infty)$. Then $\mu_n\pi_{t_1,\dots,t_d}^{‚Äî1}=\delta_0$ when $n$ is large enough. Gluing $0$ to $t_1,\dots,t_d$ is not a problem.

But these is not weak convergence (because $(x_n,n\geqslant 1)$ doesn&#39;t converge uniformly to $0$). Indeed, one can show that if $(X,d)$ is a metric space and $(x_n,n\geqslant 1)$ is a sequence in $X$ and $x\in X$, then $\delta_{x_n}\to \delta_x$ in distribution if and only if $d(x_n,x)\to 0$.

However, for general $\mu_n$ and $\mu$, if $\mu_n\to \mu$ weakly, since the finite-dimensional projection are continuous, we have $\mu_n\pi^{-1}_{t_1,\dots,t_d}\to \mu\pi^{-1}_{t_1,\dots,t_d}$ for all integer $d$ and $t_1,\dots,t_d\in [0,\infty)$.

What was missing in the first example is _tightness_. ]",,,,,,0,,1373784818,0,0,True,1374268451,1373795158.0,https://math.stackexchange.com/questions/443245/counterexample-for-finite-dimensional-weak-convergence,74.0,21.0,1.0,9.0,Salih Ucan,https://math.stackexchange.com/users/39778/salih-ucan,986.0,39778.0,registered,,443245,1,https://math.stackexchange.com/q/443245,"[probability, probability-theory, examples-counterexamples, weak-convergence]",Counterexample for finite dimensional weak convergence,1,343
38,426102.0,1,"[{u'up_vote_count': 1, u'title': u'Where is the fallacy in this coupling argument of two Bernoulli variables?', u'question_id': 425481, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1371816420, u'comments': [{u'edited': False, u'comment_id': 910669, u'creation_date': 1371815784, u'post_id': 426102, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 79684, u'user_type': u'registered', u'reputation': 97, u'link': u'https://math.stackexchange.com/users/79684/burton0', u'accept_rate': 60, u'display_name': u'burton0', u'badge_counts': {u'bronze': 9, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/425481/where-is-the-fallacy-in-this-coupling-argument-of-two-bernoulli-variables/426102#comment910669_426102'}, {u'edited': False, u'reply_to_user': {u'user_id': 79684, u'user_type': u'registered', u'reputation': 97, u'link': u'https://math.stackexchange.com/users/79684/burton0', u'accept_rate': 60, u'display_name': u'burton0', u'badge_counts': {u'bronze': 9, u'silver': 0, u'gold': 0}}, u'comment_id': 910677, u'creation_date': 1371816432, u'post_id': 426102, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 6179, u'user_type': u'registered', u'reputation': 240775, u'link': u'https://math.stackexchange.com/users/6179/did', u'accept_rate': 78, u'display_name': u'Did', u'badge_counts': {u'bronze': 437, u'silver': 204, u'gold': 23}}, u'link': u'https://math.stackexchange.com/questions/425481/where-is-the-fallacy-in-this-coupling-argument-of-two-bernoulli-variables/426102#comment910677_426102'}, {u'edited': False, u'comment_id': 910732, u'creation_date': 1371820087, u'post_id': 426102, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 79684, u'user_type': u'registered', u'reputation': 97, u'link': u'https://math.stackexchange.com/users/79684/burton0', u'accept_rate': 60, u'display_name': u'burton0', u'badge_counts': {u'bronze': 9, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/425481/where-is-the-fallacy-in-this-coupling-argument-of-two-bernoulli-variables/426102#comment910732_426102'}, {u'edited': False, u'reply_to_user': {u'user_id': 79684, u'user_type': u'registered', u'reputation': 97, u'link': u'https://math.stackexchange.com/users/79684/burton0', u'accept_rate': 60, u'display_name': u'burton0', u'badge_counts': {u'bronze': 9, u'silver': 0, u'gold': 0}}, u'comment_id': 911048, u'creation_date': 1371832336, u'post_id': 426102, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 6179, u'user_type': u'registered', u'reputation': 240775, u'link': u'https://math.stackexchange.com/users/6179/did', u'accept_rate': 78, u'display_name': u'Did', u'badge_counts': {u'bronze': 437, u'silver': 204, u'gold': 23}}, u'link': u'https://math.stackexchange.com/questions/425481/where-is-the-fallacy-in-this-coupling-argument-of-two-bernoulli-variables/426102#comment911048_426102'}, {u'edited': False, u'comment_id': 912225, u'creation_date': 1371890957, u'post_id': 426102, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 79684, u'user_type': u'registered', u'reputation': 97, u'link': u'https://math.stackexchange.com/users/79684/burton0', u'accept_rate': 60, u'display_name': u'burton0', u'badge_counts': {u'bronze': 9, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/425481/where-is-the-fallacy-in-this-coupling-argument-of-two-bernoulli-variables/426102#comment912225_426102'}, {u'edited': False, u'reply_to_user': {u'user_id': 79684, u'user_type': u'registered', u'reputation': 97, u'link': u'https://math.stackexchange.com/users/79684/burton0', u'accept_rate': 60, u'display_name': u'burton0', u'badge_counts': {u'bronze': 9, u'silver': 0, u'gold': 0}}, u'comment_id': 912226, u'creation_date': 1371890977, u'post_id': 426102, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 6179, u'user_type': u'registered', u'reputation': 240775, u'link': u'https://math.stackexchange.com/users/6179/did', u'accept_rate': 78, u'display_name': u'Did', u'badge_counts': {u'bronze': 437, u'silver': 204, u'gold': 23}}, u'link': u'https://math.stackexchange.com/questions/425481/where-is-the-fallacy-in-this-coupling-argument-of-two-bernoulli-variables/426102#comment912226_426102'}, {u'edited': False, u'comment_id': 922540, u'creation_date': 1372404386, u'post_id': 426102, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 79684, u'user_type': u'registered', u'reputation': 97, u'link': u'https://math.stackexchange.com/users/79684/burton0', u'accept_rate': 60, u'display_name': u'burton0', u'badge_counts': {u'bronze': 9, u'silver': 0, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/425481/where-is-the-fallacy-in-this-coupling-argument-of-two-bernoulli-variables/426102#comment922540_426102'}, {u'edited': False, u'reply_to_user': {u'user_id': 79684, u'user_type': u'registered', u'reputation': 97, u'link': u'https://math.stackexchange.com/users/79684/burton0', u'accept_rate': 60, u'display_name': u'burton0', u'badge_counts': {u'bronze': 9, u'silver': 0, u'gold': 0}}, u'comment_id': 922549, u'creation_date': 1372404754, u'post_id': 426102, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 6179, u'user_type': u'registered', u'reputation': 240775, u'link': u'https://math.stackexchange.com/users/6179/did', u'accept_rate': 78, u'display_name': u'Did', u'badge_counts': {u'bronze': 437, u'silver': 204, u'gold': 23}}, u'link': u'https://math.stackexchange.com/questions/425481/where-is-the-fallacy-in-this-coupling-argument-of-two-bernoulli-variables/426102#comment922549_426102'}], u'creation_date': 1371814731, u'comment_count': 8, u'score': 1, u'link': u'https://math.stackexchange.com/questions/425481/where-is-the-fallacy-in-this-coupling-argument-of-two-bernoulli-variables/426102#426102', u'body_markdown': u'&gt; Identical distributions are not the same as pointwise almost sure identity.

A mistake is that $-Y_j$ is not what you write but rather $-Y^j = 2\mathbf{1}_{U^j \gt p^j} - 1$. Of course, $-Y^j$ has the same *distribution* as $2\mathbf{1}_{U^j \leqslant1-p^j} - 1$ since $U^j$ is uniform on $\{-1,1\}$ hence the *distributions* of $-U^j$ and $U_j$ coincide, but the *pointwise* identity in your post fails.

More generally, note that $-X\leqslant X$ almost surely is logically equivalent to $X\geqslant0$ almost surely. And in your setting, $[X\lt0]$ has positive probability...

What happens here is that, simply because $P(Y^j=+1)\geqslant\frac12$ for every $j$, each random variable $-Y^j$ is stochastically dominated by $Y^j$ hence (possibly enlarging the sample space) there exists some independent random variables $(Y&#39;_j)$ such that each $Y&#39;_j$ is distributed like $-Y^j$ and $Y&#39;_j\leqslant Y^j$ almost surely. Then, every $\text{logit}(p^j)$ being nonnegative, $X&#39;=\sum\limits_j\text{logit}(p^j)Y&#39;_j$ is such that $X&#39;$ is distributed like $-X$ and $X&#39;\leqslant X$ almost surely. Thus, $[X\lt0]$ has the same probability as $[X&#39;\gt0]$ and $[X&#39;\gt 0]\subseteq[X\gt0]$. Together, these two assertions imply that $P(X\lt0)\lt P(X\gt0)$.', u'owner': {u'user_id': 6179, u'user_type': u'registered', u'reputation': 240775, u'link': u'https://math.stackexchange.com/users/6179/did', u'accept_rate': 78, u'display_name': u'Did', u'badge_counts': {u'bronze': 437, u'silver': 204, u'gold': 23}}, u'is_accepted': True, u'last_edit_date': 1371816420, u'share_link': u'https://math.stackexchange.com/a/426102', u'answer_id': 426102}]","With respect to the scenario introduced in https://math.stackexchange.com/questions/403795/prove-the-monotonicity-of-the-expectation-of-a-binary-random-variable-function, let us now suppose that the function:

$$\begin{align*}
f(\mathcal{J}) = E\left(| \sum_{j \in \mathcal{J}} y^j  |\right)
\end{align*}$$ 
is altered so that $f(\mathcal{J}) = E\left(| \sum_{j \in \mathcal{J}} \text{logit}(p^j) y^j  |\right)$, where $\text{logit}(p^j) = \log(\frac{p^j}{1 - p^j})$.  Moreover, let us now alter the definition of $X$ from $X = Y^1 + \ldots + Y^N$ to $X = \text{logit}(p^1)Y^1 + \ldots + \text{logit}(p^N)Y^N$.

Hence, the proof provided in the best answer for the previous question needs to be adapted to the new definitions.

Specifically, the coupling argument introduced in the final step of the proof does not hold anymore, since $\text{logit}(0.5) = 0$ and $X^0$ reduces to a deterministic value. Thus, a different way of prooving that $P(X &gt; 0) &gt; P(X &lt; 0)$ needs to be devised.

I will now introduce a tentative proof. Although the proof seems correct from a formal point of view, it does not look correct from an intuitive view point.

To this end, let us rewrite $P(X &lt; 0)$ as $P(-X &gt; 0)$. The random variable $-X$ can be expressed as:

$$\begin{align*}
-X = \text{logit}(p^1)(-Y^1) + \ldots + \text{logit}(p^N)(-Y^N)
\end{align*}$$

Similarly to the proof for the previous question, let us now express $Y^j$ as $Y^j = 2\mathbf{1}_{U^j \leq p^j}&#160;-1$ where $U^j \sim U(0,1)$ . Since $Y^j$ is a symmetric Bernoulli random variable taking value in {-1,1}, we can express $-Y^j$ as $-Y^j = 2\mathbf{1}_{U^j \leq (1-p^j)} - 1$. Since $p^j \geq 0.5$, $\forall j = 1, \ldots, R$ we have that $-Y^j \leq Y^j$ almost surely. Consequently $-X \leq X$ almost surely and the claim is verified. 

The afore-mentioned proof does not look correct. It is sufficient to notice that according to the definition of $Y^j$ and $-Y^{j}$ it is possible to have $Y^j = 1$ and $-Y^j = 1$ at the same time.

What am I doing wrong? Moreover, how to correctly verify the claim? thanks. ","[&gt; Identical distributions are not the same as pointwise almost sure identity.

A mistake is that $-Y_j$ is not what you write but rather $-Y^j = 2\mathbf{1}_{U^j \gt p^j} - 1$. Of course, $-Y^j$ has the same *distribution* as $2\mathbf{1}_{U^j \leqslant1-p^j} - 1$ since $U^j$ is uniform on $\{-1,1\}$ hence the *distributions* of $-U^j$ and $U_j$ coincide, but the *pointwise* identity in your post fails.

More generally, note that $-X\leqslant X$ almost surely is logically equivalent to $X\geqslant0$ almost surely. And in your setting, $[X\lt0]$ has positive probability...

What happens here is that, simply because $P(Y^j=+1)\geqslant\frac12$ for every $j$, each random variable $-Y^j$ is stochastically dominated by $Y^j$ hence (possibly enlarging the sample space) there exists some independent random variables $(Y&#39;_j)$ such that each $Y&#39;_j$ is distributed like $-Y^j$ and $Y&#39;_j\leqslant Y^j$ almost surely. Then, every $\text{logit}(p^j)$ being nonnegative, $X&#39;=\sum\limits_j\text{logit}(p^j)Y&#39;_j$ is such that $X&#39;$ is distributed like $-X$ and $X&#39;\leqslant X$ almost surely. Thus, $[X\lt0]$ has the same probability as $[X&#39;\gt0]$ and $[X&#39;\gt 0]\subseteq[X\gt0]$. Together, these two assertions imply that $P(X\lt0)\lt P(X\gt0)$.]",,,,,,0,,1371739988,0,1,True,1371816420,1492086043.0,https://math.stackexchange.com/questions/425481/where-is-the-fallacy-in-this-coupling-argument-of-two-bernoulli-variables,60.0,9.0,0.0,0.0,burton0,https://math.stackexchange.com/users/79684/burton0,97.0,79684.0,registered,,425481,2,https://math.stackexchange.com/q/425481,"[probability, proof-writing, examples-counterexamples, random-variables]",Where is the fallacy in this coupling argument of two Bernoulli variables?,2,201
39,300809.0,1,"[{u'up_vote_count': 2, u'title': u'Examples of universal constructions in probability theory', u'question_id': 295254, u'tags': [], u'down_vote_count': 0, u'last_activity_date': 1360702062, u'comments': [{u'edited': False, u'comment_id': 653619, u'creation_date': 1360659781, u'post_id': 300809, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 59239, u'user_type': u'registered', u'reputation': 267, u'link': u'https://math.stackexchange.com/users/59239/uwf', u'display_name': u'UwF', u'badge_counts': {u'bronze': 18, u'silver': 3, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/295254/examples-of-universal-constructions-in-probability-theory/300809#comment653619_300809'}, {u'edited': False, u'comment_id': 1246279, u'creation_date': 1386057297, u'post_id': 300809, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 8346, u'user_type': u'registered', u'reputation': 6173, u'link': u'https://math.stackexchange.com/users/8346/ehsan-m-kermani', u'accept_rate': 78, u'display_name': u'Ehsan M. Kermani', u'badge_counts': {u'bronze': 44, u'silver': 21, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/295254/examples-of-universal-constructions-in-probability-theory/300809#comment1246279_300809'}, {u'edited': False, u'comment_id': 1247318, u'creation_date': 1386092636, u'post_id': 300809, u'score': 0, u'post_type': u'answer', u'owner': {u'user_id': 59239, u'user_type': u'registered', u'reputation': 267, u'link': u'https://math.stackexchange.com/users/59239/uwf', u'display_name': u'UwF', u'badge_counts': {u'bronze': 18, u'silver': 3, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/295254/examples-of-universal-constructions-in-probability-theory/300809#comment1247318_300809'}], u'awarded_bounty_users': [{u'user_id': 59239, u'user_type': u'registered', u'reputation': 267, u'link': u'https://math.stackexchange.com/users/59239/uwf', u'display_name': u'UwF', u'badge_counts': {u'bronze': 18, u'silver': 3, u'gold': 0}}], u'awarded_bounty_amount': 100, u'comment_count': 3, u'score': 2, u'link': u'https://math.stackexchange.com/questions/295254/examples-of-universal-constructions-in-probability-theory/300809#300809', u'body_markdown': u'The category of measurable spaces is [topological](http://ncatlab.org/nlab/show/topological+concrete+category) this means that they have initial &amp; final structures analogously to those in [topology](). These can be universally expressed as noted on the wikipedia page.

[Cylinder set measures](http://en.wikipedia.org/wiki/Cylinder_set_measure) are defined categorically if not universally, and are used to define measures on infinite-dimensional spaces such as the [abstract wiener space](http://en.wikipedia.org/wiki/Abstract_Wiener_space) construction.

Lebesgue measure and the integral can be defined [universally](http://www.maths.gla.ac.uk/~tl/glasgowpssl/banach.pdf) as shown by Tom Leinster.', u'owner': {u'user_id': 26254, u'user_type': u'registered', u'reputation': 2560, u'link': u'https://math.stackexchange.com/users/26254/mozibur-ullah', u'accept_rate': 63, u'display_name': u'Mozibur Ullah', u'badge_counts': {u'bronze': 27, u'silver': 8, u'gold': 0}}, u'is_accepted': True, u'last_edit_date': 1360702062, u'creation_date': 1360634243, u'share_link': u'https://math.stackexchange.com/a/300809', u'answer_id': 300809}]","I am looking for more examples of universal constructions in probability theory. Like the construction a of Gaussian space from a real Hilbert space, or a Poisson jump process from a measurable space with a $\sigma$-finite measure. There must be tons of examples, even though their universality (in the sense of category theory) is probably not commonly emphasized.","[The category of measurable spaces is [topological](http://ncatlab.org/nlab/show/topological+concrete+category) this means that they have initial &amp; final structures analogously to those in [topology](). These can be universally expressed as noted on the wikipedia page.

[Cylinder set measures](http://en.wikipedia.org/wiki/Cylinder_set_measure) are defined categorically if not universally, and are used to define measures on infinite-dimensional spaces such as the [abstract wiener space](http://en.wikipedia.org/wiki/Abstract_Wiener_space) construction.

Lebesgue measure and the integral can be defined [universally](http://www.maths.gla.ac.uk/~tl/glasgowpssl/banach.pdf) as shown by Tom Leinster.]",,,,,,6,"[{u'edited': False, u'comment_id': 642977, u'creation_date': 1360091175, u'post_id': 295254, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 1650, u'user_type': u'registered', u'reputation': 104440, u'link': u'https://math.stackexchange.com/users/1650/martin-brandenburg', u'accept_rate': 71, u'display_name': u'Martin Brandenburg', u'badge_counts': {u'bronze': 313, u'silver': 149, u'gold': 13}}, u'link': u'https://math.stackexchange.com/questions/295254/examples-of-universal-constructions-in-probability-theory#comment642977_295254'}, {u'edited': False, u'reply_to_user': {u'user_id': 1650, u'user_type': u'registered', u'reputation': 104440, u'link': u'https://math.stackexchange.com/users/1650/martin-brandenburg', u'accept_rate': 71, u'display_name': u'Martin Brandenburg', u'badge_counts': {u'bronze': 313, u'silver': 149, u'gold': 13}}, u'comment_id': 644034, u'creation_date': 1360140203, u'post_id': 295254, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 59239, u'user_type': u'registered', u'reputation': 267, u'link': u'https://math.stackexchange.com/users/59239/uwf', u'display_name': u'UwF', u'badge_counts': {u'bronze': 18, u'silver': 3, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/295254/examples-of-universal-constructions-in-probability-theory#comment644034_295254'}, {u'edited': False, u'comment_id': 644291, u'creation_date': 1360160446, u'post_id': 295254, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 21674, u'user_type': u'moderator', u'reputation': 23668, u'link': u'https://math.stackexchange.com/users/21674/michael-greinecker', u'accept_rate': 75, u'display_name': u'Michael Greinecker', u'badge_counts': {u'bronze': 100, u'silver': 50, u'gold': 4}}, u'link': u'https://math.stackexchange.com/questions/295254/examples-of-universal-constructions-in-probability-theory#comment644291_295254'}, {u'edited': False, u'comment_id': 644401, u'creation_date': 1360165158, u'post_id': 295254, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 59239, u'user_type': u'registered', u'reputation': 267, u'link': u'https://math.stackexchange.com/users/59239/uwf', u'display_name': u'UwF', u'badge_counts': {u'bronze': 18, u'silver': 3, u'gold': 0}}, u'link': u'https://math.stackexchange.com/questions/295254/examples-of-universal-constructions-in-probability-theory#comment644401_295254'}, {u'edited': False, u'comment_id': 1089379, u'creation_date': 1380358910, u'post_id': 295254, u'score': 0, u'post_type': u'question', u'owner': {u'user_id': 6179, u'user_type': u'registered', u'reputation': 240775, u'link': u'https://math.stackexchange.com/users/6179/did', u'accept_rate': 78, u'display_name': u'Did', u'badge_counts': {u'bronze': 437, u'silver': 204, u'gold': 23}}, u'link': u'https://math.stackexchange.com/questions/295254/examples-of-universal-constructions-in-probability-theory#comment1089379_295254'}, {u'edited': False, u'comment_id': 1257739, u'creation_date': 1386427236, u'post_id': 295254, u'score': 1, u'post_type': u'question', u'owner': {u'user_id': 73610, u'user_type': u'registered', u'reputation': 7393, u'link': u'https://math.stackexchange.com/users/73610/pece', u'accept_rate': 55, u'display_name': u'Pece', u'badge_counts': {u'bronze': 37, u'silver': 10, u'gold': 1}}, u'link': u'https://math.stackexchange.com/questions/295254/examples-of-universal-constructions-in-probability-theory#comment1257739_295254'}]",1360049940,0,6,True,1386057236,1386057047.0,https://math.stackexchange.com/questions/295254/examples-of-universal-constructions-in-probability-theory,,18.0,0.0,3.0,UwF,https://math.stackexchange.com/users/59239/uwf,267.0,59239.0,registered,,295254,16,https://math.stackexchange.com/q/295254,"[probability, category-theory, examples-counterexamples]",Examples of universal constructions in probability theory,16,448
